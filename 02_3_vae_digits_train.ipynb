{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from models import VariationalAutoEncoder\n",
    "from utils import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = \"vae\"\n",
    "RUN_ID = \"0002\"\n",
    "DATA_NAME = \"digits\"\n",
    "RUN_FOLDER = \"run/{}/\".format(SECTION)\n",
    "RUN_FOLDER += \"_\".join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, \"viz\"))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, \"images\"))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, \"weights\"))\n",
    "\n",
    "mode =  \"build\" # \"load\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(\n",
    "    input_dim=(28, 28, 1),\n",
    "    encoder_conv_filters=[32, 64, 64, 64],\n",
    "    encoder_conv_kernel_size=[3, 3, 3, 3],\n",
    "    encoder_conv_strides=[1, 2, 2, 1],\n",
    "    decoder_conv_t_filters=[64, 64, 32, 1],\n",
    "    decoder_conv_t_kernel_size=[3, 3, 3, 3],\n",
    "    decoder_conv_t_strides=[1, 2, 2, 1],\n",
    "    z_dim=2\n",
    ")\n",
    "\n",
    "if mode == \"build\":\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, \"weights/weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 28, 28, 32)   0           encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 14, 14, 64)   18496       leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 64)   0           encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            6274        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            6274        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105,220\n",
      "Trainable params: 105,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/200\n",
      "   32/60000 [..............................] - ETA: 5:40:13 - loss: 231.1615 - vae_r_loss: 231.1602 - vae_kl_loss: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  128/60000 [..............................] - ETA: 1:25:26 - loss: 230.3483 - vae_r_loss: 230.3458 - vae_kl_loss: 0.0025WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0205s vs `on_train_batch_end` time: 0.0273s). Check your callbacks.\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 58.7106 - vae_r_loss: 55.4776 - vae_kl_loss: 3.2330\n",
      "Epoch 00001: saving model to run/vae/0002_digits\\weights\\weights-001-58.70.h5\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 51s 844us/sample - loss: 58.7039 - vae_r_loss: 55.4709 - vae_kl_loss: 3.2331\n",
      "Epoch 2/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 51.9660 - vae_r_loss: 48.0901 - vae_kl_loss: 3.8759\n",
      "Epoch 00002: saving model to run/vae/0002_digits\\weights\\weights-002-51.96.h5\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 41s 679us/sample - loss: 51.9614 - vae_r_loss: 48.0855 - vae_kl_loss: 3.8759\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 50.4261 - vae_r_loss: 46.2354 - vae_kl_loss: 4.1906\n",
      "Epoch 00003: saving model to run/vae/0002_digits\\weights\\weights-003-50.43.h5\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 41s 684us/sample - loss: 50.4261 - vae_r_loss: 46.2354 - vae_kl_loss: 4.1906\n",
      "Epoch 4/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 49.4533 - vae_r_loss: 45.0511 - vae_kl_loss: 4.4022\n",
      "Epoch 00004: saving model to run/vae/0002_digits\\weights\\weights-004-49.46.h5\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 41s 688us/sample - loss: 49.4567 - vae_r_loss: 45.0545 - vae_kl_loss: 4.4022\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 48.7784 - vae_r_loss: 44.2507 - vae_kl_loss: 4.5276\n",
      "Epoch 00005: saving model to run/vae/0002_digits\\weights\\weights-005-48.78.h5\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 48.7784 - vae_r_loss: 44.2507 - vae_kl_loss: 4.5276\n",
      "Epoch 6/200\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 48.2150 - vae_r_loss: 43.5801 - vae_kl_loss: 4.6349\n",
      "Epoch 00006: saving model to run/vae/0002_digits\\weights\\weights-006-48.22.h5\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 39s 654us/sample - loss: 48.2155 - vae_r_loss: 43.5807 - vae_kl_loss: 4.6349\n",
      "Epoch 7/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 47.8639 - vae_r_loss: 43.1592 - vae_kl_loss: 4.7047\n",
      "Epoch 00007: saving model to run/vae/0002_digits\\weights\\weights-007-47.86.h5\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 40s 671us/sample - loss: 47.8627 - vae_r_loss: 43.1580 - vae_kl_loss: 4.7047\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 47.4943 - vae_r_loss: 42.7397 - vae_kl_loss: 4.7546 ETA: 0s - loss: 47.5060 - vae_r_loss: 42.7507 - vae_kl_ - ETA: 0s - loss: 47.4914 - vae_r_loss: 42.7368 - vae_kl_loss: 4.7546\n",
      "Epoch 00008: saving model to run/vae/0002_digits\\weights\\weights-008-47.49.h5\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0002_digits\\weights\\weights.h5\n",
      "60000/60000 [==============================] - 40s 667us/sample - loss: 47.4914 - vae_r_loss: 42.7368 - vae_kl_loss: 4.7546\n",
      "Epoch 9/200\n",
      "52096/60000 [=========================>....] - ETA: 5s - loss: 47.2771 - vae_r_loss: 42.4683 - vae_kl_loss: 4.8088"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a985e4450bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR_LOSS_FACTOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m vae.train(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86153\\Desktop\\jupyter\\generative-deep-learning\\models\\VAE.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch, lr_decay)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mcallback_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_sched\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         self.model.fit(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 1000\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "\n",
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)\n",
    "\n",
    "vae.train(\n",
    "    x_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    run_folder=RUN_FOLDER,\n",
    "    print_every_n_batches=PRINT_EVERY_N_BATCHES,\n",
    "    initial_epoch=INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2c3f6bbb24c7fc4eda595b7be3f8dd6bbd084eb592ad3a47549926ebe803f66"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('TensorFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
