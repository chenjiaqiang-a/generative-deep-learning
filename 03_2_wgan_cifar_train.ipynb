{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN训练\n",
    "## 引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import WGAN\n",
    "from utils import load_cifar\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = \"gan\"\n",
    "RUN_ID = \"0002\"\n",
    "DATA_NAME = \"horses\"\n",
    "RUN_FOLDER = \"run/{}/\".format(SECTION)\n",
    "RUN_FOLDER += \"_\".join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, \"viz\"))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, \"images\"))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, \"weights\"))\n",
    "\n",
    "MODE = \"build\" # \"load\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NAME == \"cars\":\n",
    "    label = 1\n",
    "elif DATA_NAME == \"horses\":\n",
    "    label = 7\n",
    "(x_train, y_train) = load_cifar(label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b9ff81b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((x_train[150, :, :, :] + 1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /environment/miniconda3/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "wgan = WGAN(\n",
    "    input_dim=(32, 32, 3),\n",
    "    critic_conv_filters=[32, 64, 128, 128],\n",
    "    critic_conv_kernel_size=[5, 5, 5, 5],\n",
    "    critic_conv_strides=[2, 2, 2, 1],\n",
    "    critic_batch_norm_momentum=None,\n",
    "    critic_activation=\"leaky_relu\",\n",
    "    critic_dropout_rate=None,\n",
    "    critic_learning_rate=0.00005,\n",
    "    generator_initial_dense_layer_size=(4, 4, 128),\n",
    "    generator_upsample=[2, 2, 2, 1],\n",
    "    generator_conv_filters=[128, 64, 32, 3],\n",
    "    generator_conv_kernel_size=[5, 5, 5, 5],\n",
    "    generator_conv_strides=[1, 1, 1, 1],\n",
    "    generator_batch_norm_momentum=0.8,\n",
    "    generator_activation=\"leaky_relu\",\n",
    "    generator_dropout_rate=None,\n",
    "    generator_learning_rate=0.00005,\n",
    "    optimizer=\"rmsprop\",\n",
    "    z_dim=100\n",
    ")\n",
    "\n",
    "if MODE == \"build\":\n",
    "    wgan.save(RUN_FOLDER)\n",
    "else:\n",
    "    wgan.load_weights(os.path.join(RUN_FOLDER, \"weights/weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " critic_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " critic_conv_0 (Conv2D)      (None, 16, 16, 32)        2432      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " critic_conv_1 (Conv2D)      (None, 8, 8, 64)          51264     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " critic_conv_2 (Conv2D)      (None, 4, 4, 128)         204928    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " critic_conv_3 (Conv2D)      (None, 4, 4, 128)         409728    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 670,401\n",
      "Trainable params: 670,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wgan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " generator_input (InputLayer  [(None, 100)]            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              206848    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2048)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 8, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " generator_conv_0 (Conv2D)   (None, 8, 8, 128)         409728    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " generator_conv_1 (Conv2D)   (None, 16, 16, 64)        204864    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " generator_conv_2 (Conv2D)   (None, 32, 32, 32)        51232     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " generator_conv_3 (Conv2DTra  (None, 32, 32, 3)        2403      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 884,163\n",
      "Trainable params: 879,619\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wgan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.7/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Epoch 001 -- [D loss: -0.000(R -0.001, F 0.000)] [G loss: -0.000]\n",
      "Epoch 002 -- [D loss: -0.000(R -0.001, F 0.000)] [G loss: -0.001]\n",
      "Epoch 003 -- [D loss: -0.002(R -0.005, F 0.001)] [G loss: -0.003]\n",
      "Epoch 004 -- [D loss: -0.007(R -0.018, F 0.003)] [G loss: -0.011]\n",
      "Epoch 005 -- [D loss: -0.017(R -0.046, F 0.013)] [G loss: -0.038]\n",
      "Epoch 006 -- [D loss: -0.021(R -0.079, F 0.037)] [G loss: -0.081]\n",
      "Epoch 007 -- [D loss: -0.018(R -0.103, F 0.066)] [G loss: -0.124]\n",
      "Epoch 008 -- [D loss: -0.012(R -0.115, F 0.092)] [G loss: -0.159]\n",
      "Epoch 009 -- [D loss: -0.018(R -0.140, F 0.104)] [G loss: -0.188]\n",
      "Epoch 010 -- [D loss: -0.013(R -0.143, F 0.118)] [G loss: -0.210]\n",
      "Epoch 011 -- [D loss: -0.022(R -0.163, F 0.118)] [G loss: -0.236]\n",
      "Epoch 012 -- [D loss: -0.018(R -0.173, F 0.136)] [G loss: -0.254]\n",
      "Epoch 013 -- [D loss: -0.024(R -0.191, F 0.144)] [G loss: -0.266]\n",
      "Epoch 014 -- [D loss: -0.015(R -0.191, F 0.162)] [G loss: -0.260]\n",
      "Epoch 015 -- [D loss: -0.012(R -0.180, F 0.156)] [G loss: -0.238]\n",
      "Epoch 016 -- [D loss: -0.015(R -0.173, F 0.144)] [G loss: -0.208]\n",
      "Epoch 017 -- [D loss: -0.014(R -0.148, F 0.119)] [G loss: -0.179]\n",
      "Epoch 018 -- [D loss: -0.026(R -0.150, F 0.098)] [G loss: -0.146]\n",
      "Epoch 019 -- [D loss: -0.035(R -0.145, F 0.074)] [G loss: -0.125]\n",
      "Epoch 020 -- [D loss: -0.038(R -0.142, F 0.067)] [G loss: -0.114]\n",
      "Epoch 021 -- [D loss: -0.054(R -0.159, F 0.051)] [G loss: -0.145]\n",
      "Epoch 022 -- [D loss: -0.079(R -0.215, F 0.058)] [G loss: -0.233]\n",
      "Epoch 023 -- [D loss: -0.108(R -0.304, F 0.088)] [G loss: -0.402]\n",
      "Epoch 024 -- [D loss: -0.110(R -0.346, F 0.126)] [G loss: -0.631]\n",
      "Epoch 025 -- [D loss: -0.145(R -0.522, F 0.233)] [G loss: -0.871]\n",
      "Epoch 026 -- [D loss: -0.131(R -0.614, F 0.351)] [G loss: -1.102]\n",
      "Epoch 027 -- [D loss: -0.117(R -0.633, F 0.400)] [G loss: -1.261]\n",
      "Epoch 028 -- [D loss: -0.115(R -0.690, F 0.460)] [G loss: -1.369]\n",
      "Epoch 029 -- [D loss: -0.156(R -0.857, F 0.544)] [G loss: -1.441]\n",
      "Epoch 030 -- [D loss: -0.080(R -0.759, F 0.598)] [G loss: -1.396]\n",
      "Epoch 031 -- [D loss: -0.024(R -0.701, F 0.652)] [G loss: -1.183]\n",
      "Epoch 032 -- [D loss: -0.047(R -0.697, F 0.603)] [G loss: -0.960]\n",
      "Epoch 033 -- [D loss: -0.056(R -0.646, F 0.534)] [G loss: -0.742]\n",
      "Epoch 034 -- [D loss: -0.091(R -0.624, F 0.442)] [G loss: -0.558]\n",
      "Epoch 035 -- [D loss: -0.112(R -0.574, F 0.349)] [G loss: -0.360]\n",
      "Epoch 036 -- [D loss: -0.160(R -0.560, F 0.241)] [G loss: -0.189]\n",
      "Epoch 037 -- [D loss: -0.183(R -0.512, F 0.145)] [G loss: -0.082]\n",
      "Epoch 038 -- [D loss: -0.255(R -0.582, F 0.072)] [G loss: -0.062]\n",
      "Epoch 039 -- [D loss: -0.290(R -0.614, F 0.034)] [G loss: -0.092]\n",
      "Epoch 040 -- [D loss: -0.424(R -0.867, F 0.019)] [G loss: -0.139]\n",
      "Epoch 041 -- [D loss: -0.525(R -1.045, F -0.005)] [G loss: -0.159]\n",
      "Epoch 042 -- [D loss: -0.562(R -1.057, F -0.066)] [G loss: -0.117]\n",
      "Epoch 043 -- [D loss: -0.687(R -1.168, F -0.206)] [G loss: 0.063]\n",
      "Epoch 044 -- [D loss: -0.927(R -1.418, F -0.436)] [G loss: 0.411]\n",
      "Epoch 045 -- [D loss: -1.111(R -1.497, F -0.725)] [G loss: 0.985]\n",
      "Epoch 046 -- [D loss: -1.407(R -1.387, F -1.426)] [G loss: 1.719]\n",
      "Epoch 047 -- [D loss: -1.693(R -1.176, F -2.211)] [G loss: 2.354]\n",
      "Epoch 048 -- [D loss: -2.277(R -1.683, F -2.872)] [G loss: 2.523]\n",
      "Epoch 049 -- [D loss: -2.309(R -1.674, F -2.945)] [G loss: 2.214]\n",
      "Epoch 050 -- [D loss: -1.919(R -1.377, F -2.460)] [G loss: 1.467]\n",
      "Epoch 051 -- [D loss: -1.687(R -1.716, F -1.658)] [G loss: 0.711]\n",
      "Epoch 052 -- [D loss: -1.520(R -2.067, F -0.973)] [G loss: 0.361]\n",
      "Epoch 053 -- [D loss: -1.801(R -3.153, F -0.449)] [G loss: 0.203]\n",
      "Epoch 054 -- [D loss: -1.868(R -3.708, F -0.028)] [G loss: 0.083]\n",
      "Epoch 055 -- [D loss: -2.303(R -4.861, F 0.255)] [G loss: -0.097]\n",
      "Epoch 056 -- [D loss: -2.872(R -6.852, F 1.109)] [G loss: -0.300]\n",
      "Epoch 057 -- [D loss: -2.408(R -7.715, F 2.899)] [G loss: -0.942]\n",
      "Epoch 058 -- [D loss: -0.238(R -6.573, F 6.098)] [G loss: -2.781]\n",
      "Epoch 059 -- [D loss: 1.451(R -7.864, F 10.766)] [G loss: -5.416]\n",
      "Epoch 060 -- [D loss: 3.470(R -5.714, F 12.655)] [G loss: -6.811]\n",
      "Epoch 061 -- [D loss: 3.251(R -5.199, F 11.702)] [G loss: -7.048]\n",
      "Epoch 062 -- [D loss: 2.824(R -4.377, F 10.026)] [G loss: -6.369]\n",
      "Epoch 063 -- [D loss: 2.069(R -3.721, F 7.859)] [G loss: -5.487]\n",
      "Epoch 064 -- [D loss: 1.262(R -3.596, F 6.121)] [G loss: -4.438]\n",
      "Epoch 065 -- [D loss: 0.866(R -2.763, F 4.495)] [G loss: -3.341]\n",
      "Epoch 066 -- [D loss: 0.150(R -2.711, F 3.011)] [G loss: -2.096]\n",
      "Epoch 067 -- [D loss: -0.430(R -2.285, F 1.425)] [G loss: -0.689]\n",
      "Epoch 068 -- [D loss: -1.182(R -2.104, F -0.259)] [G loss: 1.045]\n",
      "Epoch 069 -- [D loss: -1.928(R -1.584, F -2.272)] [G loss: 3.049]\n",
      "Epoch 070 -- [D loss: -2.979(R -1.428, F -4.530)] [G loss: 5.371]\n",
      "Epoch 071 -- [D loss: -3.843(R -0.881, F -6.804)] [G loss: 7.845]\n",
      "Epoch 072 -- [D loss: -4.977(R -1.084, F -8.871)] [G loss: 10.359]\n",
      "Epoch 073 -- [D loss: -5.760(R -0.283, F -11.238)] [G loss: 12.599]\n",
      "Epoch 074 -- [D loss: -5.741(R 0.933, F -12.414)] [G loss: 14.220]\n",
      "Epoch 075 -- [D loss: -6.162(R 1.675, F -13.998)] [G loss: 15.672]\n",
      "Epoch 076 -- [D loss: -6.388(R 1.587, F -14.363)] [G loss: 16.127]\n",
      "Epoch 077 -- [D loss: -5.120(R 3.473, F -13.713)] [G loss: 15.403]\n",
      "Epoch 078 -- [D loss: -3.513(R 4.364, F -11.390)] [G loss: 13.875]\n",
      "Epoch 079 -- [D loss: -2.747(R 4.733, F -10.227)] [G loss: 11.806]\n",
      "Epoch 080 -- [D loss: -0.661(R 5.803, F -7.125)] [G loss: 9.888]\n",
      "Epoch 081 -- [D loss: 0.612(R 5.369, F -4.145)] [G loss: 7.955]\n",
      "Epoch 082 -- [D loss: 0.137(R 4.202, F -3.927)] [G loss: 6.656]\n",
      "Epoch 083 -- [D loss: 0.934(R 4.522, F -2.655)] [G loss: 5.970]\n",
      "Epoch 084 -- [D loss: 0.112(R 2.775, F -2.551)] [G loss: 5.526]\n",
      "Epoch 085 -- [D loss: -0.367(R 1.942, F -2.675)] [G loss: 5.301]\n",
      "Epoch 086 -- [D loss: -0.797(R 1.292, F -2.887)] [G loss: 5.112]\n",
      "Epoch 087 -- [D loss: -1.405(R 0.071, F -2.881)] [G loss: 5.008]\n",
      "Epoch 088 -- [D loss: -2.546(R -1.992, F -3.099)] [G loss: 4.749]\n",
      "Epoch 089 -- [D loss: -2.714(R -2.834, F -2.593)] [G loss: 3.854]\n",
      "Epoch 090 -- [D loss: -3.965(R -5.748, F -2.182)] [G loss: 2.213]\n",
      "Epoch 091 -- [D loss: -3.323(R -6.067, F -0.580)] [G loss: -0.495]\n",
      "Epoch 092 -- [D loss: -3.667(R -9.398, F 2.064)] [G loss: -3.307]\n",
      "Epoch 093 -- [D loss: -2.962(R -11.286, F 5.362)] [G loss: -6.107]\n",
      "Epoch 094 -- [D loss: -2.522(R -12.440, F 7.396)] [G loss: -7.894]\n",
      "Epoch 095 -- [D loss: -1.636(R -12.300, F 9.028)] [G loss: -8.571]\n",
      "Epoch 096 -- [D loss: -1.890(R -13.440, F 9.659)] [G loss: -8.620]\n",
      "Epoch 097 -- [D loss: -0.404(R -11.746, F 10.937)] [G loss: -7.762]\n",
      "Epoch 098 -- [D loss: 1.559(R -9.766, F 12.884)] [G loss: -7.335]\n",
      "Epoch 099 -- [D loss: 1.497(R -9.317, F 12.311)] [G loss: -6.826]\n",
      "Epoch 100 -- [D loss: 2.975(R -5.864, F 11.815)] [G loss: -6.215]\n",
      "INFO:tensorflow:Assets written to: ram://1f1102bf-cd7a-40e0-81df-9bb04f73ef46/assets\n",
      "INFO:tensorflow:Assets written to: ram://5244eeef-6a9b-4e27-b2fe-b7bd0eeeaa10/assets\n",
      "INFO:tensorflow:Assets written to: ram://67451216-fc8e-4f8b-9965-eb8efb6599bb/assets\n",
      "Epoch 101 -- [D loss: 2.247(R -5.871, F 10.364)] [G loss: -5.297]\n",
      "Epoch 102 -- [D loss: 2.118(R -3.994, F 8.231)] [G loss: -4.091]\n",
      "Epoch 103 -- [D loss: 1.411(R -2.754, F 5.576)] [G loss: -2.933]\n",
      "Epoch 104 -- [D loss: 0.470(R -2.312, F 3.253)] [G loss: -1.825]\n",
      "Epoch 105 -- [D loss: 0.141(R -1.195, F 1.476)] [G loss: -0.775]\n",
      "Epoch 106 -- [D loss: -0.322(R -0.736, F 0.092)] [G loss: -0.212]\n",
      "Epoch 107 -- [D loss: -0.526(R -0.122, F -0.930)] [G loss: 0.576]\n",
      "Epoch 108 -- [D loss: -0.587(R 0.454, F -1.628)] [G loss: 1.237]\n",
      "Epoch 109 -- [D loss: -0.618(R 1.303, F -2.538)] [G loss: 1.495]\n",
      "Epoch 110 -- [D loss: -0.845(R 1.043, F -2.734)] [G loss: 1.736]\n",
      "Epoch 111 -- [D loss: -0.300(R 2.164, F -2.765)] [G loss: 1.948]\n",
      "Epoch 112 -- [D loss: -0.315(R 1.764, F -2.394)] [G loss: 2.251]\n",
      "Epoch 113 -- [D loss: -0.124(R 2.220, F -2.469)] [G loss: 2.611]\n",
      "Epoch 114 -- [D loss: -0.134(R 2.502, F -2.770)] [G loss: 3.061]\n",
      "Epoch 115 -- [D loss: -0.173(R 2.572, F -2.918)] [G loss: 3.402]\n",
      "Epoch 116 -- [D loss: -0.397(R 2.400, F -3.194)] [G loss: 3.688]\n",
      "Epoch 117 -- [D loss: -0.294(R 2.490, F -3.078)] [G loss: 3.947]\n",
      "Epoch 118 -- [D loss: -0.314(R 2.677, F -3.304)] [G loss: 4.208]\n",
      "Epoch 119 -- [D loss: -0.282(R 2.484, F -3.049)] [G loss: 4.261]\n",
      "Epoch 120 -- [D loss: -0.323(R 2.395, F -3.042)] [G loss: 4.211]\n",
      "Epoch 121 -- [D loss: -0.257(R 2.223, F -2.737)] [G loss: 4.136]\n",
      "Epoch 122 -- [D loss: -0.172(R 2.083, F -2.426)] [G loss: 3.828]\n",
      "Epoch 123 -- [D loss: -0.047(R 1.824, F -1.918)] [G loss: 3.337]\n",
      "Epoch 124 -- [D loss: 0.059(R 1.724, F -1.607)] [G loss: 2.767]\n",
      "Epoch 125 -- [D loss: 0.125(R 1.279, F -1.029)] [G loss: 2.100]\n",
      "Epoch 126 -- [D loss: 0.037(R 0.836, F -0.763)] [G loss: 1.434]\n",
      "Epoch 127 -- [D loss: 0.142(R 0.680, F -0.396)] [G loss: 0.849]\n",
      "Epoch 128 -- [D loss: 0.113(R 0.352, F -0.125)] [G loss: 0.412]\n",
      "Epoch 129 -- [D loss: 0.072(R 0.060, F 0.085)] [G loss: 0.111]\n",
      "Epoch 130 -- [D loss: -0.035(R -0.175, F 0.106)] [G loss: -0.054]\n",
      "Epoch 131 -- [D loss: -0.052(R -0.257, F 0.153)] [G loss: -0.100]\n",
      "Epoch 132 -- [D loss: -0.100(R -0.316, F 0.117)] [G loss: -0.068]\n",
      "Epoch 133 -- [D loss: -0.190(R -0.435, F 0.055)] [G loss: -0.008]\n",
      "Epoch 134 -- [D loss: -0.333(R -0.659, F -0.007)] [G loss: 0.094]\n",
      "Epoch 135 -- [D loss: -0.390(R -0.712, F -0.069)] [G loss: 0.255]\n",
      "Epoch 136 -- [D loss: -0.498(R -0.783, F -0.212)] [G loss: 0.440]\n",
      "Epoch 137 -- [D loss: -0.555(R -0.802, F -0.309)] [G loss: 0.615]\n",
      "Epoch 138 -- [D loss: -0.566(R -0.712, F -0.421)] [G loss: 0.663]\n",
      "Epoch 139 -- [D loss: -0.527(R -0.609, F -0.445)] [G loss: 0.688]\n",
      "Epoch 140 -- [D loss: -0.477(R -0.569, F -0.385)] [G loss: 0.519]\n",
      "Epoch 141 -- [D loss: -0.230(R -0.200, F -0.259)] [G loss: 0.353]\n",
      "Epoch 142 -- [D loss: -0.201(R -0.113, F -0.289)] [G loss: 0.293]\n",
      "Epoch 143 -- [D loss: -0.222(R 0.092, F -0.536)] [G loss: 0.543]\n",
      "Epoch 144 -- [D loss: -0.352(R 0.192, F -0.895)] [G loss: 0.857]\n",
      "Epoch 145 -- [D loss: -0.321(R 0.427, F -1.068)] [G loss: 1.143]\n",
      "Epoch 146 -- [D loss: -0.452(R 0.405, F -1.310)] [G loss: 1.312]\n",
      "Epoch 147 -- [D loss: -0.274(R 0.711, F -1.259)] [G loss: 1.322]\n",
      "Epoch 148 -- [D loss: -0.111(R 0.516, F -0.737)] [G loss: 1.159]\n",
      "Epoch 149 -- [D loss: 0.042(R 0.477, F -0.393)] [G loss: 0.727]\n",
      "Epoch 150 -- [D loss: 0.049(R 0.362, F -0.265)] [G loss: 0.425]\n",
      "Epoch 151 -- [D loss: 0.131(R 0.314, F -0.052)] [G loss: 0.256]\n",
      "Epoch 152 -- [D loss: 0.069(R 0.181, F -0.044)] [G loss: 0.248]\n",
      "Epoch 153 -- [D loss: 0.004(R 0.101, F -0.093)] [G loss: 0.280]\n",
      "Epoch 154 -- [D loss: -0.137(R -0.008, F -0.266)] [G loss: 0.318]\n",
      "Epoch 155 -- [D loss: -0.089(R 0.038, F -0.216)] [G loss: 0.332]\n",
      "Epoch 156 -- [D loss: -0.409(R -0.597, F -0.222)] [G loss: 0.379]\n",
      "Epoch 157 -- [D loss: -0.186(R -0.243, F -0.129)] [G loss: 0.341]\n",
      "Epoch 158 -- [D loss: -0.075(R -0.164, F 0.014)] [G loss: 0.227]\n",
      "Epoch 159 -- [D loss: -0.211(R -0.486, F 0.065)] [G loss: 0.085]\n",
      "Epoch 160 -- [D loss: -0.108(R -0.503, F 0.287)] [G loss: 0.021]\n",
      "Epoch 161 -- [D loss: -0.097(R -0.430, F 0.236)] [G loss: -0.201]\n",
      "Epoch 162 -- [D loss: -0.048(R -0.408, F 0.311)] [G loss: -0.197]\n",
      "Epoch 163 -- [D loss: 0.051(R -0.319, F 0.422)] [G loss: -0.350]\n",
      "Epoch 164 -- [D loss: 0.059(R -0.455, F 0.574)] [G loss: -0.461]\n",
      "Epoch 165 -- [D loss: 0.211(R -0.294, F 0.717)] [G loss: -0.488]\n",
      "Epoch 166 -- [D loss: 0.249(R -0.119, F 0.616)] [G loss: -0.487]\n",
      "Epoch 167 -- [D loss: 0.187(R -0.206, F 0.579)] [G loss: -0.393]\n",
      "Epoch 168 -- [D loss: 0.202(R -0.031, F 0.436)] [G loss: -0.262]\n",
      "Epoch 169 -- [D loss: 0.146(R -0.022, F 0.315)] [G loss: -0.139]\n",
      "Epoch 170 -- [D loss: 0.053(R 0.019, F 0.087)] [G loss: -0.035]\n",
      "Epoch 171 -- [D loss: 0.018(R 0.016, F 0.021)] [G loss: 0.039]\n",
      "Epoch 172 -- [D loss: -0.023(R 0.082, F -0.128)] [G loss: 0.167]\n",
      "Epoch 173 -- [D loss: -0.065(R 0.088, F -0.217)] [G loss: 0.241]\n",
      "Epoch 174 -- [D loss: -0.088(R 0.133, F -0.309)] [G loss: 0.335]\n",
      "Epoch 175 -- [D loss: -0.073(R 0.231, F -0.377)] [G loss: 0.446]\n",
      "Epoch 176 -- [D loss: -0.099(R 0.202, F -0.400)] [G loss: 0.509]\n",
      "Epoch 177 -- [D loss: -0.216(R 0.159, F -0.591)] [G loss: 0.560]\n",
      "Epoch 178 -- [D loss: -0.155(R 0.201, F -0.511)] [G loss: 0.645]\n",
      "Epoch 179 -- [D loss: -0.084(R 0.351, F -0.520)] [G loss: 0.645]\n",
      "Epoch 180 -- [D loss: -0.180(R 0.239, F -0.599)] [G loss: 0.663]\n",
      "Epoch 181 -- [D loss: -0.137(R 0.208, F -0.481)] [G loss: 0.709]\n",
      "Epoch 182 -- [D loss: -0.203(R 0.162, F -0.567)] [G loss: 0.764]\n",
      "Epoch 183 -- [D loss: -0.236(R 0.159, F -0.630)] [G loss: 0.790]\n",
      "Epoch 184 -- [D loss: -0.287(R 0.079, F -0.653)] [G loss: 0.815]\n",
      "Epoch 185 -- [D loss: -0.417(R -0.227, F -0.606)] [G loss: 0.717]\n",
      "Epoch 186 -- [D loss: -0.256(R -0.162, F -0.351)] [G loss: 0.541]\n",
      "Epoch 187 -- [D loss: -0.255(R -0.467, F -0.043)] [G loss: 0.190]\n",
      "Epoch 188 -- [D loss: 0.039(R -0.238, F 0.317)] [G loss: -0.170]\n",
      "Epoch 189 -- [D loss: 0.038(R -0.541, F 0.616)] [G loss: -0.432]\n",
      "Epoch 190 -- [D loss: 0.075(R -0.675, F 0.824)] [G loss: -0.677]\n",
      "Epoch 191 -- [D loss: 0.139(R -0.569, F 0.848)] [G loss: -0.704]\n",
      "Epoch 192 -- [D loss: 0.035(R -0.680, F 0.750)] [G loss: -0.568]\n",
      "Epoch 193 -- [D loss: -0.066(R -0.690, F 0.557)] [G loss: -0.491]\n",
      "Epoch 194 -- [D loss: -0.101(R -0.732, F 0.530)] [G loss: -0.407]\n",
      "Epoch 195 -- [D loss: -0.104(R -0.753, F 0.544)] [G loss: -0.488]\n",
      "Epoch 196 -- [D loss: -0.075(R -0.712, F 0.562)] [G loss: -0.457]\n",
      "Epoch 197 -- [D loss: -0.122(R -0.751, F 0.507)] [G loss: -0.434]\n",
      "Epoch 198 -- [D loss: -0.095(R -0.834, F 0.644)] [G loss: -0.369]\n",
      "Epoch 199 -- [D loss: -0.090(R -0.921, F 0.741)] [G loss: -0.495]\n",
      "Epoch 200 -- [D loss: -0.036(R -0.956, F 0.883)] [G loss: -0.684]\n",
      "INFO:tensorflow:Assets written to: ram://38ea93f3-179a-4feb-85a1-2cce9cd2b450/assets\n",
      "INFO:tensorflow:Assets written to: ram://e2b55c65-f1e8-443f-a339-34edfa53ae7d/assets\n",
      "INFO:tensorflow:Assets written to: ram://14514ea3-5feb-4c49-92ce-c1ea20f1f956/assets\n",
      "Epoch 201 -- [D loss: 0.106(R -0.834, F 1.047)] [G loss: -0.935]\n",
      "Epoch 202 -- [D loss: 0.081(R -0.839, F 1.002)] [G loss: -0.861]\n",
      "Epoch 203 -- [D loss: 0.090(R -0.779, F 0.958)] [G loss: -0.722]\n",
      "Epoch 204 -- [D loss: 0.161(R -0.585, F 0.907)] [G loss: -0.682]\n",
      "Epoch 205 -- [D loss: 0.173(R -0.513, F 0.859)] [G loss: -0.721]\n",
      "Epoch 206 -- [D loss: 0.142(R -0.527, F 0.811)] [G loss: -0.637]\n",
      "Epoch 207 -- [D loss: 0.079(R -0.469, F 0.628)] [G loss: -0.573]\n",
      "Epoch 208 -- [D loss: 0.059(R -0.478, F 0.595)] [G loss: -0.508]\n",
      "Epoch 209 -- [D loss: -0.012(R -0.490, F 0.466)] [G loss: -0.413]\n",
      "Epoch 210 -- [D loss: 0.007(R -0.430, F 0.444)] [G loss: -0.414]\n",
      "Epoch 211 -- [D loss: -0.020(R -0.398, F 0.359)] [G loss: -0.353]\n",
      "Epoch 212 -- [D loss: -0.004(R -0.405, F 0.396)] [G loss: -0.283]\n",
      "Epoch 213 -- [D loss: 0.019(R -0.337, F 0.375)] [G loss: -0.258]\n",
      "Epoch 214 -- [D loss: -0.055(R -0.350, F 0.241)] [G loss: -0.150]\n",
      "Epoch 215 -- [D loss: -0.017(R -0.218, F 0.185)] [G loss: -0.141]\n",
      "Epoch 216 -- [D loss: -0.002(R -0.152, F 0.149)] [G loss: -0.154]\n",
      "Epoch 217 -- [D loss: 0.008(R -0.111, F 0.127)] [G loss: -0.146]\n",
      "Epoch 218 -- [D loss: 0.023(R -0.100, F 0.146)] [G loss: -0.037]\n",
      "Epoch 219 -- [D loss: -0.057(R -0.160, F 0.046)] [G loss: 0.014]\n",
      "Epoch 220 -- [D loss: -0.078(R -0.141, F -0.015)] [G loss: 0.084]\n",
      "Epoch 221 -- [D loss: -0.041(R -0.020, F -0.063)] [G loss: 0.177]\n",
      "Epoch 222 -- [D loss: -0.096(R -0.089, F -0.102)] [G loss: 0.201]\n",
      "Epoch 223 -- [D loss: -0.060(R 0.027, F -0.147)] [G loss: 0.314]\n",
      "Epoch 224 -- [D loss: -0.086(R 0.110, F -0.283)] [G loss: 0.320]\n",
      "Epoch 225 -- [D loss: -0.094(R 0.151, F -0.339)] [G loss: 0.331]\n",
      "Epoch 226 -- [D loss: -0.088(R 0.131, F -0.306)] [G loss: 0.397]\n",
      "Epoch 227 -- [D loss: -0.029(R 0.206, F -0.265)] [G loss: 0.372]\n",
      "Epoch 228 -- [D loss: -0.009(R 0.242, F -0.260)] [G loss: 0.356]\n",
      "Epoch 229 -- [D loss: -0.072(R 0.177, F -0.322)] [G loss: 0.355]\n",
      "Epoch 230 -- [D loss: -0.089(R 0.114, F -0.292)] [G loss: 0.310]\n",
      "Epoch 231 -- [D loss: -0.026(R 0.118, F -0.170)] [G loss: 0.237]\n",
      "Epoch 232 -- [D loss: -0.049(R 0.058, F -0.155)] [G loss: 0.188]\n",
      "Epoch 233 -- [D loss: -0.041(R 0.091, F -0.173)] [G loss: 0.243]\n",
      "Epoch 234 -- [D loss: -0.073(R 0.071, F -0.217)] [G loss: 0.300]\n",
      "Epoch 235 -- [D loss: -0.082(R 0.047, F -0.212)] [G loss: 0.153]\n",
      "Epoch 236 -- [D loss: -0.060(R -0.043, F -0.076)] [G loss: 0.048]\n",
      "Epoch 237 -- [D loss: -0.084(R -0.197, F 0.028)] [G loss: -0.187]\n",
      "Epoch 238 -- [D loss: -0.018(R -0.154, F 0.118)] [G loss: -0.324]\n",
      "Epoch 239 -- [D loss: 0.030(R -0.302, F 0.362)] [G loss: -0.466]\n",
      "Epoch 240 -- [D loss: 0.056(R -0.359, F 0.472)] [G loss: -0.540]\n",
      "Epoch 241 -- [D loss: 0.027(R -0.451, F 0.505)] [G loss: -0.562]\n",
      "Epoch 242 -- [D loss: 0.049(R -0.414, F 0.512)] [G loss: -0.522]\n",
      "Epoch 243 -- [D loss: 0.057(R -0.399, F 0.512)] [G loss: -0.416]\n",
      "Epoch 244 -- [D loss: 0.012(R -0.360, F 0.384)] [G loss: -0.327]\n",
      "Epoch 245 -- [D loss: -0.015(R -0.360, F 0.330)] [G loss: -0.283]\n",
      "Epoch 246 -- [D loss: -0.054(R -0.419, F 0.310)] [G loss: -0.280]\n",
      "Epoch 247 -- [D loss: -0.020(R -0.457, F 0.416)] [G loss: -0.322]\n",
      "Epoch 248 -- [D loss: -0.011(R -0.503, F 0.481)] [G loss: -0.379]\n",
      "Epoch 249 -- [D loss: 0.006(R -0.478, F 0.490)] [G loss: -0.509]\n",
      "Epoch 250 -- [D loss: -0.043(R -0.593, F 0.507)] [G loss: -0.542]\n",
      "Epoch 251 -- [D loss: 0.052(R -0.514, F 0.617)] [G loss: -0.558]\n",
      "Epoch 252 -- [D loss: 0.053(R -0.487, F 0.594)] [G loss: -0.513]\n",
      "Epoch 253 -- [D loss: -0.004(R -0.497, F 0.489)] [G loss: -0.419]\n",
      "Epoch 254 -- [D loss: -0.048(R -0.447, F 0.351)] [G loss: -0.395]\n",
      "Epoch 255 -- [D loss: 0.012(R -0.583, F 0.608)] [G loss: -0.398]\n",
      "Epoch 256 -- [D loss: 0.108(R -0.428, F 0.644)] [G loss: -0.470]\n",
      "Epoch 257 -- [D loss: 0.086(R -0.359, F 0.530)] [G loss: -0.417]\n",
      "Epoch 258 -- [D loss: 0.064(R -0.324, F 0.452)] [G loss: -0.258]\n",
      "Epoch 259 -- [D loss: -0.036(R -0.280, F 0.209)] [G loss: -0.169]\n",
      "Epoch 260 -- [D loss: -0.051(R -0.250, F 0.149)] [G loss: -0.189]\n",
      "Epoch 261 -- [D loss: -0.063(R -0.274, F 0.147)] [G loss: -0.217]\n",
      "Epoch 262 -- [D loss: -0.058(R -0.139, F 0.024)] [G loss: -0.196]\n",
      "Epoch 263 -- [D loss: -0.167(R -0.232, F -0.101)] [G loss: -0.059]\n",
      "Epoch 264 -- [D loss: -0.015(R -0.105, F 0.074)] [G loss: 0.019]\n",
      "Epoch 265 -- [D loss: 0.050(R -0.010, F 0.109)] [G loss: 0.078]\n",
      "Epoch 266 -- [D loss: 0.006(R 0.039, F -0.027)] [G loss: 0.191]\n",
      "Epoch 267 -- [D loss: -0.057(R 0.140, F -0.255)] [G loss: 0.327]\n",
      "Epoch 268 -- [D loss: -0.047(R 0.215, F -0.309)] [G loss: 0.384]\n",
      "Epoch 269 -- [D loss: -0.037(R 0.211, F -0.286)] [G loss: 0.300]\n",
      "Epoch 270 -- [D loss: -0.026(R 0.274, F -0.326)] [G loss: 0.348]\n",
      "Epoch 271 -- [D loss: -0.035(R 0.231, F -0.302)] [G loss: 0.398]\n",
      "Epoch 272 -- [D loss: 0.062(R 0.336, F -0.211)] [G loss: 0.332]\n",
      "Epoch 273 -- [D loss: 0.018(R 0.251, F -0.214)] [G loss: 0.286]\n",
      "Epoch 274 -- [D loss: 0.052(R 0.257, F -0.154)] [G loss: 0.269]\n",
      "Epoch 275 -- [D loss: 0.008(R 0.242, F -0.227)] [G loss: 0.269]\n",
      "Epoch 276 -- [D loss: 0.022(R 0.232, F -0.188)] [G loss: 0.251]\n",
      "Epoch 277 -- [D loss: 0.024(R 0.220, F -0.172)] [G loss: 0.243]\n",
      "Epoch 278 -- [D loss: -0.000(R 0.169, F -0.170)] [G loss: 0.239]\n",
      "Epoch 279 -- [D loss: -0.007(R 0.157, F -0.171)] [G loss: 0.224]\n",
      "Epoch 280 -- [D loss: -0.024(R 0.106, F -0.154)] [G loss: 0.191]\n",
      "Epoch 281 -- [D loss: -0.027(R 0.066, F -0.120)] [G loss: 0.171]\n",
      "Epoch 282 -- [D loss: -0.048(R 0.036, F -0.132)] [G loss: 0.150]\n",
      "Epoch 283 -- [D loss: -0.029(R 0.027, F -0.085)] [G loss: 0.120]\n",
      "Epoch 284 -- [D loss: 0.034(R 0.088, F -0.021)] [G loss: 0.061]\n",
      "Epoch 285 -- [D loss: 0.008(R -0.011, F 0.027)] [G loss: 0.027]\n",
      "Epoch 286 -- [D loss: -0.000(R -0.057, F 0.057)] [G loss: -0.039]\n",
      "Epoch 287 -- [D loss: -0.031(R -0.114, F 0.051)] [G loss: -0.124]\n",
      "Epoch 288 -- [D loss: -0.056(R -0.230, F 0.118)] [G loss: -0.199]\n",
      "Epoch 289 -- [D loss: 0.003(R -0.210, F 0.215)] [G loss: -0.210]\n",
      "Epoch 290 -- [D loss: 0.034(R -0.233, F 0.302)] [G loss: -0.219]\n",
      "Epoch 291 -- [D loss: 0.071(R -0.131, F 0.272)] [G loss: -0.177]\n",
      "Epoch 292 -- [D loss: 0.031(R -0.128, F 0.190)] [G loss: -0.086]\n",
      "Epoch 293 -- [D loss: -0.005(R -0.104, F 0.095)] [G loss: -0.046]\n",
      "Epoch 294 -- [D loss: -0.012(R -0.113, F 0.089)] [G loss: -0.021]\n",
      "Epoch 295 -- [D loss: -0.022(R -0.090, F 0.047)] [G loss: 0.001]\n",
      "Epoch 296 -- [D loss: -0.040(R -0.111, F 0.030)] [G loss: 0.028]\n",
      "Epoch 297 -- [D loss: -0.062(R -0.176, F 0.052)] [G loss: 0.007]\n",
      "Epoch 298 -- [D loss: -0.059(R -0.172, F 0.054)] [G loss: 0.001]\n",
      "Epoch 299 -- [D loss: -0.048(R -0.160, F 0.064)] [G loss: 0.004]\n",
      "Epoch 300 -- [D loss: -0.037(R -0.123, F 0.049)] [G loss: -0.004]\n",
      "INFO:tensorflow:Assets written to: ram://84487811-8fa5-44a9-9dc5-7ff643d0d6d6/assets\n",
      "INFO:tensorflow:Assets written to: ram://7c1eb36c-a870-4dc0-94ec-de47da45d07e/assets\n",
      "INFO:tensorflow:Assets written to: ram://60d01eb4-d716-4d87-9014-a8453582f6c6/assets\n",
      "Epoch 301 -- [D loss: -0.013(R -0.143, F 0.117)] [G loss: -0.013]\n",
      "Epoch 302 -- [D loss: 0.049(R -0.166, F 0.263)] [G loss: -0.065]\n",
      "Epoch 303 -- [D loss: 0.061(R -0.152, F 0.274)] [G loss: -0.089]\n",
      "Epoch 304 -- [D loss: 0.042(R -0.161, F 0.246)] [G loss: -0.096]\n",
      "Epoch 305 -- [D loss: -0.009(R -0.200, F 0.182)] [G loss: -0.120]\n",
      "Epoch 306 -- [D loss: 0.002(R -0.184, F 0.188)] [G loss: -0.112]\n",
      "Epoch 307 -- [D loss: -0.020(R -0.154, F 0.114)] [G loss: -0.081]\n",
      "Epoch 308 -- [D loss: -0.043(R -0.132, F 0.045)] [G loss: -0.006]\n",
      "Epoch 309 -- [D loss: -0.085(R -0.133, F -0.037)] [G loss: 0.019]\n",
      "Epoch 310 -- [D loss: -0.007(R -0.089, F 0.075)] [G loss: -0.004]\n",
      "Epoch 311 -- [D loss: 0.016(R -0.088, F 0.120)] [G loss: -0.012]\n",
      "Epoch 312 -- [D loss: -0.047(R -0.159, F 0.064)] [G loss: 0.036]\n",
      "Epoch 313 -- [D loss: -0.074(R -0.160, F 0.012)] [G loss: 0.027]\n",
      "Epoch 314 -- [D loss: -0.019(R -0.124, F 0.086)] [G loss: -0.028]\n",
      "Epoch 315 -- [D loss: -0.024(R -0.091, F 0.044)] [G loss: 0.021]\n",
      "Epoch 316 -- [D loss: -0.029(R -0.031, F -0.027)] [G loss: 0.050]\n",
      "Epoch 317 -- [D loss: -0.028(R -0.002, F -0.053)] [G loss: 0.086]\n",
      "Epoch 318 -- [D loss: 0.003(R 0.075, F -0.069)] [G loss: 0.081]\n",
      "Epoch 319 -- [D loss: 0.005(R 0.056, F -0.047)] [G loss: 0.073]\n",
      "Epoch 320 -- [D loss: 0.003(R 0.062, F -0.056)] [G loss: 0.077]\n",
      "Epoch 321 -- [D loss: -0.021(R 0.046, F -0.088)] [G loss: 0.100]\n",
      "Epoch 322 -- [D loss: 0.012(R 0.079, F -0.056)] [G loss: 0.137]\n",
      "Epoch 323 -- [D loss: -0.001(R 0.086, F -0.088)] [G loss: 0.128]\n",
      "Epoch 324 -- [D loss: -0.003(R 0.081, F -0.088)] [G loss: 0.139]\n",
      "Epoch 325 -- [D loss: -0.010(R 0.092, F -0.112)] [G loss: 0.156]\n",
      "Epoch 326 -- [D loss: -0.018(R 0.082, F -0.118)] [G loss: 0.149]\n",
      "Epoch 327 -- [D loss: -0.014(R 0.102, F -0.130)] [G loss: 0.151]\n",
      "Epoch 328 -- [D loss: 0.000(R 0.098, F -0.097)] [G loss: 0.150]\n",
      "Epoch 329 -- [D loss: -0.016(R 0.068, F -0.100)] [G loss: 0.134]\n",
      "Epoch 330 -- [D loss: -0.001(R 0.064, F -0.065)] [G loss: 0.111]\n",
      "Epoch 331 -- [D loss: -0.007(R 0.058, F -0.071)] [G loss: 0.089]\n",
      "Epoch 332 -- [D loss: 0.001(R 0.021, F -0.020)] [G loss: 0.060]\n",
      "Epoch 333 -- [D loss: -0.019(R -0.000, F -0.037)] [G loss: 0.050]\n",
      "Epoch 334 -- [D loss: 0.004(R -0.009, F 0.018)] [G loss: 0.029]\n",
      "Epoch 335 -- [D loss: -0.003(R -0.056, F 0.049)] [G loss: -0.016]\n",
      "Epoch 336 -- [D loss: -0.009(R -0.088, F 0.070)] [G loss: -0.062]\n",
      "Epoch 337 -- [D loss: -0.000(R -0.092, F 0.092)] [G loss: -0.103]\n",
      "Epoch 338 -- [D loss: -0.026(R -0.149, F 0.098)] [G loss: -0.143]\n",
      "Epoch 339 -- [D loss: 0.033(R -0.117, F 0.182)] [G loss: -0.172]\n",
      "Epoch 340 -- [D loss: 0.015(R -0.146, F 0.176)] [G loss: -0.165]\n",
      "Epoch 341 -- [D loss: 0.025(R -0.141, F 0.191)] [G loss: -0.151]\n",
      "Epoch 342 -- [D loss: 0.018(R -0.136, F 0.172)] [G loss: -0.136]\n",
      "Epoch 343 -- [D loss: 0.005(R -0.129, F 0.140)] [G loss: -0.112]\n",
      "Epoch 344 -- [D loss: 0.005(R -0.126, F 0.135)] [G loss: -0.114]\n",
      "Epoch 345 -- [D loss: 0.003(R -0.122, F 0.129)] [G loss: -0.118]\n",
      "Epoch 346 -- [D loss: 0.001(R -0.119, F 0.121)] [G loss: -0.111]\n",
      "Epoch 347 -- [D loss: -0.005(R -0.118, F 0.108)] [G loss: -0.096]\n",
      "Epoch 348 -- [D loss: -0.002(R -0.114, F 0.109)] [G loss: -0.085]\n",
      "Epoch 349 -- [D loss: -0.004(R -0.106, F 0.099)] [G loss: -0.075]\n",
      "Epoch 350 -- [D loss: -0.003(R -0.083, F 0.077)] [G loss: -0.043]\n",
      "Epoch 351 -- [D loss: 0.001(R -0.075, F 0.077)] [G loss: -0.046]\n",
      "Epoch 352 -- [D loss: -0.010(R -0.069, F 0.049)] [G loss: -0.045]\n",
      "Epoch 353 -- [D loss: -0.005(R -0.070, F 0.061)] [G loss: -0.027]\n",
      "Epoch 354 -- [D loss: -0.002(R -0.063, F 0.060)] [G loss: -0.022]\n",
      "Epoch 355 -- [D loss: -0.009(R -0.068, F 0.050)] [G loss: -0.022]\n",
      "Epoch 356 -- [D loss: -0.008(R -0.059, F 0.043)] [G loss: -0.017]\n",
      "Epoch 357 -- [D loss: -0.008(R -0.063, F 0.047)] [G loss: -0.018]\n",
      "Epoch 358 -- [D loss: -0.019(R -0.065, F 0.026)] [G loss: -0.029]\n",
      "Epoch 359 -- [D loss: -0.016(R -0.062, F 0.031)] [G loss: -0.033]\n",
      "Epoch 360 -- [D loss: -0.014(R -0.048, F 0.020)] [G loss: -0.027]\n",
      "Epoch 361 -- [D loss: 0.004(R -0.052, F 0.060)] [G loss: -0.022]\n",
      "Epoch 362 -- [D loss: -0.019(R -0.044, F 0.006)] [G loss: -0.012]\n",
      "Epoch 363 -- [D loss: -0.016(R -0.034, F 0.002)] [G loss: -0.001]\n",
      "Epoch 364 -- [D loss: -0.029(R -0.023, F -0.035)] [G loss: 0.013]\n",
      "Epoch 365 -- [D loss: -0.024(R -0.011, F -0.036)] [G loss: 0.029]\n",
      "Epoch 366 -- [D loss: -0.018(R 0.011, F -0.047)] [G loss: 0.040]\n",
      "Epoch 367 -- [D loss: -0.013(R 0.002, F -0.029)] [G loss: 0.041]\n",
      "Epoch 368 -- [D loss: 0.002(R 0.040, F -0.037)] [G loss: 0.050]\n",
      "Epoch 369 -- [D loss: 0.001(R 0.019, F -0.018)] [G loss: 0.047]\n",
      "Epoch 370 -- [D loss: 0.009(R 0.038, F -0.020)] [G loss: 0.048]\n",
      "Epoch 371 -- [D loss: 0.013(R 0.043, F -0.017)] [G loss: 0.050]\n",
      "Epoch 372 -- [D loss: 0.006(R 0.043, F -0.031)] [G loss: 0.044]\n",
      "Epoch 373 -- [D loss: 0.014(R 0.041, F -0.013)] [G loss: 0.036]\n",
      "Epoch 374 -- [D loss: 0.018(R 0.042, F -0.006)] [G loss: 0.029]\n",
      "Epoch 375 -- [D loss: 0.009(R 0.022, F -0.005)] [G loss: 0.026]\n",
      "Epoch 376 -- [D loss: 0.001(R 0.010, F -0.008)] [G loss: 0.031]\n",
      "Epoch 377 -- [D loss: -0.008(R 0.002, F -0.019)] [G loss: 0.026]\n",
      "Epoch 378 -- [D loss: -0.012(R -0.022, F -0.003)] [G loss: 0.020]\n",
      "Epoch 379 -- [D loss: -0.027(R -0.053, F -0.001)] [G loss: 0.001]\n",
      "Epoch 380 -- [D loss: -0.029(R -0.082, F 0.024)] [G loss: -0.011]\n",
      "Epoch 381 -- [D loss: -0.036(R -0.094, F 0.023)] [G loss: -0.031]\n",
      "Epoch 382 -- [D loss: -0.033(R -0.113, F 0.046)] [G loss: -0.048]\n",
      "Epoch 383 -- [D loss: -0.010(R -0.114, F 0.094)] [G loss: -0.049]\n",
      "Epoch 384 -- [D loss: -0.001(R -0.087, F 0.084)] [G loss: -0.046]\n",
      "Epoch 385 -- [D loss: -0.023(R -0.112, F 0.065)] [G loss: -0.030]\n",
      "Epoch 386 -- [D loss: -0.027(R -0.097, F 0.042)] [G loss: -0.021]\n",
      "Epoch 387 -- [D loss: -0.025(R -0.104, F 0.055)] [G loss: -0.034]\n",
      "Epoch 388 -- [D loss: -0.022(R -0.123, F 0.078)] [G loss: -0.056]\n",
      "Epoch 389 -- [D loss: 0.011(R -0.093, F 0.115)] [G loss: -0.081]\n",
      "Epoch 390 -- [D loss: 0.010(R -0.094, F 0.115)] [G loss: -0.084]\n",
      "Epoch 391 -- [D loss: 0.022(R -0.077, F 0.121)] [G loss: -0.085]\n",
      "Epoch 392 -- [D loss: 0.013(R -0.085, F 0.111)] [G loss: -0.090]\n",
      "Epoch 393 -- [D loss: 0.023(R -0.078, F 0.125)] [G loss: -0.091]\n",
      "Epoch 394 -- [D loss: 0.011(R -0.084, F 0.106)] [G loss: -0.088]\n",
      "Epoch 395 -- [D loss: -0.004(R -0.098, F 0.090)] [G loss: -0.071]\n",
      "Epoch 396 -- [D loss: -0.001(R -0.089, F 0.087)] [G loss: -0.074]\n",
      "Epoch 397 -- [D loss: -0.003(R -0.098, F 0.093)] [G loss: -0.066]\n",
      "Epoch 398 -- [D loss: -0.002(R -0.092, F 0.087)] [G loss: -0.073]\n",
      "Epoch 399 -- [D loss: -0.002(R -0.094, F 0.089)] [G loss: -0.060]\n",
      "Epoch 400 -- [D loss: -0.013(R -0.092, F 0.067)] [G loss: -0.051]\n",
      "INFO:tensorflow:Assets written to: ram://eb679515-0c4a-4aa8-a970-13ee8ba408ff/assets\n",
      "INFO:tensorflow:Assets written to: ram://bb4670d1-6f1f-4e20-9b3c-db3e86ca6630/assets\n",
      "INFO:tensorflow:Assets written to: ram://505939de-3029-4f87-a75b-bd43ef2f5174/assets\n",
      "Epoch 401 -- [D loss: -0.011(R -0.075, F 0.053)] [G loss: -0.043]\n",
      "Epoch 402 -- [D loss: -0.009(R -0.065, F 0.047)] [G loss: -0.035]\n",
      "Epoch 403 -- [D loss: -0.001(R -0.057, F 0.055)] [G loss: -0.027]\n",
      "Epoch 404 -- [D loss: -0.005(R -0.052, F 0.042)] [G loss: -0.031]\n",
      "Epoch 405 -- [D loss: -0.005(R -0.049, F 0.039)] [G loss: -0.012]\n",
      "Epoch 406 -- [D loss: 0.001(R -0.031, F 0.032)] [G loss: -0.005]\n",
      "Epoch 407 -- [D loss: -0.009(R -0.035, F 0.017)] [G loss: 0.004]\n",
      "Epoch 408 -- [D loss: 0.000(R -0.017, F 0.018)] [G loss: 0.006]\n",
      "Epoch 409 -- [D loss: -0.000(R -0.019, F 0.018)] [G loss: 0.021]\n",
      "Epoch 410 -- [D loss: -0.001(R 0.002, F -0.003)] [G loss: 0.028]\n",
      "Epoch 411 -- [D loss: -0.003(R 0.009, F -0.014)] [G loss: 0.038]\n",
      "Epoch 412 -- [D loss: -0.007(R 0.009, F -0.023)] [G loss: 0.041]\n",
      "Epoch 413 -- [D loss: -0.003(R 0.013, F -0.019)] [G loss: 0.040]\n",
      "Epoch 414 -- [D loss: -0.012(R 0.012, F -0.036)] [G loss: 0.049]\n",
      "Epoch 415 -- [D loss: -0.013(R 0.028, F -0.053)] [G loss: 0.055]\n",
      "Epoch 416 -- [D loss: -0.004(R 0.030, F -0.038)] [G loss: 0.053]\n",
      "Epoch 417 -- [D loss: 0.000(R 0.031, F -0.030)] [G loss: 0.049]\n",
      "Epoch 418 -- [D loss: -0.005(R 0.028, F -0.037)] [G loss: 0.044]\n",
      "Epoch 419 -- [D loss: -0.009(R 0.027, F -0.045)] [G loss: 0.046]\n",
      "Epoch 420 -- [D loss: -0.005(R 0.026, F -0.037)] [G loss: 0.048]\n",
      "Epoch 421 -- [D loss: 0.004(R 0.037, F -0.028)] [G loss: 0.043]\n",
      "Epoch 422 -- [D loss: 0.003(R 0.034, F -0.029)] [G loss: 0.043]\n",
      "Epoch 423 -- [D loss: -0.003(R 0.024, F -0.029)] [G loss: 0.041]\n",
      "Epoch 424 -- [D loss: -0.000(R 0.028, F -0.029)] [G loss: 0.042]\n",
      "Epoch 425 -- [D loss: -0.007(R 0.016, F -0.030)] [G loss: 0.045]\n",
      "Epoch 426 -- [D loss: -0.011(R 0.008, F -0.030)] [G loss: 0.044]\n",
      "Epoch 427 -- [D loss: -0.011(R 0.004, F -0.026)] [G loss: 0.040]\n",
      "Epoch 428 -- [D loss: -0.028(R -0.021, F -0.034)] [G loss: 0.030]\n",
      "Epoch 429 -- [D loss: -0.013(R -0.013, F -0.014)] [G loss: 0.013]\n",
      "Epoch 430 -- [D loss: -0.003(R -0.022, F 0.016)] [G loss: 0.003]\n",
      "Epoch 431 -- [D loss: 0.007(R -0.015, F 0.030)] [G loss: -0.006]\n",
      "Epoch 432 -- [D loss: -0.004(R -0.017, F 0.008)] [G loss: -0.014]\n",
      "Epoch 433 -- [D loss: -0.005(R -0.028, F 0.018)] [G loss: -0.023]\n",
      "Epoch 434 -- [D loss: -0.006(R -0.035, F 0.023)] [G loss: -0.021]\n",
      "Epoch 435 -- [D loss: 0.010(R -0.017, F 0.036)] [G loss: -0.035]\n",
      "Epoch 436 -- [D loss: 0.006(R -0.029, F 0.040)] [G loss: -0.022]\n",
      "Epoch 437 -- [D loss: -0.004(R -0.041, F 0.033)] [G loss: -0.030]\n",
      "Epoch 438 -- [D loss: -0.008(R -0.041, F 0.025)] [G loss: -0.026]\n",
      "Epoch 439 -- [D loss: -0.004(R -0.044, F 0.036)] [G loss: -0.030]\n",
      "Epoch 440 -- [D loss: -0.004(R -0.046, F 0.037)] [G loss: -0.023]\n",
      "Epoch 441 -- [D loss: -0.012(R -0.052, F 0.027)] [G loss: -0.016]\n",
      "Epoch 442 -- [D loss: -0.014(R -0.051, F 0.024)] [G loss: -0.012]\n",
      "Epoch 443 -- [D loss: -0.003(R -0.049, F 0.042)] [G loss: -0.023]\n",
      "Epoch 444 -- [D loss: -0.014(R -0.055, F 0.028)] [G loss: -0.011]\n",
      "Epoch 445 -- [D loss: -0.002(R -0.057, F 0.053)] [G loss: -0.020]\n",
      "Epoch 446 -- [D loss: -0.004(R -0.069, F 0.062)] [G loss: -0.030]\n",
      "Epoch 447 -- [D loss: -0.002(R -0.058, F 0.054)] [G loss: -0.029]\n",
      "Epoch 448 -- [D loss: -0.010(R -0.062, F 0.041)] [G loss: -0.033]\n",
      "Epoch 449 -- [D loss: -0.002(R -0.058, F 0.055)] [G loss: -0.030]\n",
      "Epoch 450 -- [D loss: -0.002(R -0.059, F 0.054)] [G loss: -0.027]\n",
      "Epoch 451 -- [D loss: -0.004(R -0.052, F 0.043)] [G loss: -0.029]\n",
      "Epoch 452 -- [D loss: -0.000(R -0.040, F 0.039)] [G loss: -0.027]\n",
      "Epoch 453 -- [D loss: -0.004(R -0.041, F 0.033)] [G loss: -0.026]\n",
      "Epoch 454 -- [D loss: -0.005(R -0.049, F 0.040)] [G loss: -0.024]\n",
      "Epoch 455 -- [D loss: -0.001(R -0.048, F 0.046)] [G loss: -0.034]\n",
      "Epoch 456 -- [D loss: -0.005(R -0.051, F 0.040)] [G loss: -0.025]\n",
      "Epoch 457 -- [D loss: -0.002(R -0.046, F 0.042)] [G loss: -0.028]\n",
      "Epoch 458 -- [D loss: 0.003(R -0.041, F 0.048)] [G loss: -0.029]\n",
      "Epoch 459 -- [D loss: -0.001(R -0.044, F 0.042)] [G loss: -0.029]\n",
      "Epoch 460 -- [D loss: -0.008(R -0.042, F 0.027)] [G loss: -0.013]\n",
      "Epoch 461 -- [D loss: -0.004(R -0.040, F 0.032)] [G loss: -0.011]\n",
      "Epoch 462 -- [D loss: -0.000(R -0.031, F 0.030)] [G loss: -0.010]\n",
      "Epoch 463 -- [D loss: -0.005(R -0.035, F 0.026)] [G loss: -0.009]\n",
      "Epoch 464 -- [D loss: -0.005(R -0.033, F 0.023)] [G loss: -0.010]\n",
      "Epoch 465 -- [D loss: -0.010(R -0.032, F 0.013)] [G loss: 0.002]\n",
      "Epoch 466 -- [D loss: -0.003(R -0.031, F 0.025)] [G loss: -0.006]\n",
      "Epoch 467 -- [D loss: -0.005(R -0.038, F 0.027)] [G loss: -0.014]\n",
      "Epoch 468 -- [D loss: -0.003(R -0.024, F 0.019)] [G loss: -0.008]\n",
      "Epoch 469 -- [D loss: -0.006(R -0.027, F 0.015)] [G loss: -0.005]\n",
      "Epoch 470 -- [D loss: -0.012(R -0.034, F 0.011)] [G loss: -0.015]\n",
      "Epoch 471 -- [D loss: -0.004(R -0.031, F 0.023)] [G loss: -0.022]\n",
      "Epoch 472 -- [D loss: -0.004(R -0.032, F 0.024)] [G loss: -0.017]\n",
      "Epoch 473 -- [D loss: -0.007(R -0.034, F 0.021)] [G loss: -0.020]\n",
      "Epoch 474 -- [D loss: -0.009(R -0.035, F 0.016)] [G loss: -0.014]\n",
      "Epoch 475 -- [D loss: -0.002(R -0.028, F 0.024)] [G loss: -0.014]\n",
      "Epoch 476 -- [D loss: -0.007(R -0.033, F 0.020)] [G loss: -0.018]\n",
      "Epoch 477 -- [D loss: -0.000(R -0.030, F 0.029)] [G loss: -0.019]\n",
      "Epoch 478 -- [D loss: -0.004(R -0.038, F 0.029)] [G loss: -0.011]\n",
      "Epoch 479 -- [D loss: -0.003(R -0.035, F 0.028)] [G loss: -0.010]\n",
      "Epoch 480 -- [D loss: -0.004(R -0.028, F 0.021)] [G loss: -0.007]\n",
      "Epoch 481 -- [D loss: -0.005(R -0.037, F 0.027)] [G loss: -0.007]\n",
      "Epoch 482 -- [D loss: -0.002(R -0.031, F 0.028)] [G loss: -0.015]\n",
      "Epoch 483 -- [D loss: -0.003(R -0.034, F 0.028)] [G loss: -0.014]\n",
      "Epoch 484 -- [D loss: -0.005(R -0.030, F 0.020)] [G loss: -0.006]\n",
      "Epoch 485 -- [D loss: -0.009(R -0.038, F 0.020)] [G loss: -0.008]\n",
      "Epoch 486 -- [D loss: -0.007(R -0.037, F 0.023)] [G loss: -0.012]\n",
      "Epoch 487 -- [D loss: -0.004(R -0.037, F 0.030)] [G loss: -0.016]\n",
      "Epoch 488 -- [D loss: 0.001(R -0.040, F 0.042)] [G loss: -0.020]\n",
      "Epoch 489 -- [D loss: -0.012(R -0.054, F 0.031)] [G loss: -0.019]\n",
      "Epoch 490 -- [D loss: -0.014(R -0.066, F 0.038)] [G loss: -0.024]\n",
      "Epoch 491 -- [D loss: -0.014(R -0.074, F 0.045)] [G loss: -0.027]\n",
      "Epoch 492 -- [D loss: -0.015(R -0.083, F 0.052)] [G loss: -0.042]\n",
      "Epoch 493 -- [D loss: -0.009(R -0.083, F 0.064)] [G loss: -0.051]\n",
      "Epoch 494 -- [D loss: -0.001(R -0.080, F 0.077)] [G loss: -0.058]\n",
      "Epoch 495 -- [D loss: -0.003(R -0.082, F 0.077)] [G loss: -0.059]\n",
      "Epoch 496 -- [D loss: -0.008(R -0.079, F 0.062)] [G loss: -0.057]\n",
      "Epoch 497 -- [D loss: 0.004(R -0.073, F 0.081)] [G loss: -0.066]\n",
      "Epoch 498 -- [D loss: -0.007(R -0.079, F 0.065)] [G loss: -0.071]\n",
      "Epoch 499 -- [D loss: -0.013(R -0.073, F 0.047)] [G loss: -0.069]\n",
      "Epoch 500 -- [D loss: -0.016(R -0.096, F 0.063)] [G loss: -0.092]\n",
      "INFO:tensorflow:Assets written to: ram://0a3e20c0-32a0-469a-93d5-20c561d512dd/assets\n",
      "INFO:tensorflow:Assets written to: ram://ee59af7c-07a0-4374-8070-e02d7e324c62/assets\n",
      "INFO:tensorflow:Assets written to: ram://5dc91a77-ce46-4de3-90f4-31c61fd8d325/assets\n",
      "Epoch 501 -- [D loss: -0.002(R -0.073, F 0.069)] [G loss: -0.091]\n",
      "Epoch 502 -- [D loss: 0.005(R -0.073, F 0.083)] [G loss: -0.091]\n",
      "Epoch 503 -- [D loss: 0.007(R -0.078, F 0.091)] [G loss: -0.088]\n",
      "Epoch 504 -- [D loss: 0.006(R -0.062, F 0.074)] [G loss: -0.073]\n",
      "Epoch 505 -- [D loss: -0.005(R -0.071, F 0.062)] [G loss: -0.048]\n",
      "Epoch 506 -- [D loss: -0.006(R -0.062, F 0.049)] [G loss: -0.034]\n",
      "Epoch 507 -- [D loss: -0.014(R -0.073, F 0.045)] [G loss: -0.027]\n",
      "Epoch 508 -- [D loss: -0.014(R -0.068, F 0.040)] [G loss: -0.013]\n",
      "Epoch 509 -- [D loss: -0.017(R -0.073, F 0.040)] [G loss: -0.003]\n",
      "Epoch 510 -- [D loss: -0.014(R -0.061, F 0.034)] [G loss: 0.001]\n",
      "Epoch 511 -- [D loss: -0.017(R -0.058, F 0.024)] [G loss: -0.012]\n",
      "Epoch 512 -- [D loss: -0.014(R -0.058, F 0.030)] [G loss: -0.010]\n",
      "Epoch 513 -- [D loss: -0.000(R -0.055, F 0.055)] [G loss: -0.016]\n",
      "Epoch 514 -- [D loss: 0.003(R -0.046, F 0.052)] [G loss: -0.011]\n",
      "Epoch 515 -- [D loss: -0.010(R -0.061, F 0.040)] [G loss: -0.009]\n",
      "Epoch 516 -- [D loss: -0.024(R -0.053, F 0.005)] [G loss: -0.012]\n",
      "Epoch 517 -- [D loss: -0.007(R -0.046, F 0.032)] [G loss: -0.020]\n",
      "Epoch 518 -- [D loss: -0.007(R -0.064, F 0.049)] [G loss: -0.023]\n",
      "Epoch 519 -- [D loss: -0.004(R -0.057, F 0.049)] [G loss: -0.025]\n",
      "Epoch 520 -- [D loss: 0.002(R -0.051, F 0.054)] [G loss: -0.021]\n",
      "Epoch 521 -- [D loss: -0.003(R -0.051, F 0.045)] [G loss: -0.019]\n",
      "Epoch 522 -- [D loss: -0.010(R -0.053, F 0.034)] [G loss: -0.015]\n",
      "Epoch 523 -- [D loss: -0.012(R -0.054, F 0.031)] [G loss: -0.014]\n",
      "Epoch 524 -- [D loss: -0.018(R -0.062, F 0.027)] [G loss: -0.013]\n",
      "Epoch 525 -- [D loss: -0.029(R -0.071, F 0.013)] [G loss: -0.015]\n",
      "Epoch 526 -- [D loss: -0.023(R -0.072, F 0.026)] [G loss: -0.016]\n",
      "Epoch 527 -- [D loss: -0.016(R -0.058, F 0.026)] [G loss: -0.031]\n",
      "Epoch 528 -- [D loss: -0.000(R -0.057, F 0.057)] [G loss: -0.028]\n",
      "Epoch 529 -- [D loss: 0.001(R -0.042, F 0.045)] [G loss: -0.017]\n",
      "Epoch 530 -- [D loss: -0.005(R -0.035, F 0.024)] [G loss: -0.020]\n",
      "Epoch 531 -- [D loss: -0.002(R -0.035, F 0.032)] [G loss: -0.003]\n",
      "Epoch 532 -- [D loss: 0.001(R -0.018, F 0.020)] [G loss: -0.006]\n",
      "Epoch 533 -- [D loss: -0.007(R -0.032, F 0.018)] [G loss: -0.008]\n",
      "Epoch 534 -- [D loss: -0.010(R -0.029, F 0.008)] [G loss: -0.010]\n",
      "Epoch 535 -- [D loss: -0.003(R -0.024, F 0.019)] [G loss: -0.019]\n",
      "Epoch 536 -- [D loss: 0.001(R -0.023, F 0.024)] [G loss: -0.015]\n",
      "Epoch 537 -- [D loss: 0.000(R -0.026, F 0.026)] [G loss: -0.019]\n",
      "Epoch 538 -- [D loss: -0.002(R -0.026, F 0.022)] [G loss: -0.008]\n",
      "Epoch 539 -- [D loss: -0.012(R -0.037, F 0.013)] [G loss: -0.007]\n",
      "Epoch 540 -- [D loss: -0.007(R -0.036, F 0.021)] [G loss: -0.007]\n",
      "Epoch 541 -- [D loss: -0.009(R -0.043, F 0.025)] [G loss: -0.009]\n",
      "Epoch 542 -- [D loss: -0.008(R -0.044, F 0.029)] [G loss: -0.005]\n",
      "Epoch 543 -- [D loss: -0.005(R -0.042, F 0.031)] [G loss: -0.006]\n",
      "Epoch 544 -- [D loss: -0.014(R -0.045, F 0.016)] [G loss: 0.002]\n",
      "Epoch 545 -- [D loss: -0.017(R -0.049, F 0.016)] [G loss: 0.008]\n",
      "Epoch 546 -- [D loss: -0.020(R -0.054, F 0.014)] [G loss: 0.006]\n",
      "Epoch 547 -- [D loss: -0.013(R -0.054, F 0.027)] [G loss: -0.002]\n",
      "Epoch 548 -- [D loss: -0.011(R -0.072, F 0.049)] [G loss: -0.006]\n",
      "Epoch 549 -- [D loss: -0.016(R -0.070, F 0.038)] [G loss: -0.007]\n",
      "Epoch 550 -- [D loss: -0.015(R -0.057, F 0.027)] [G loss: -0.006]\n",
      "Epoch 551 -- [D loss: -0.006(R -0.060, F 0.049)] [G loss: -0.014]\n",
      "Epoch 552 -- [D loss: -0.011(R -0.060, F 0.038)] [G loss: -0.016]\n",
      "Epoch 553 -- [D loss: -0.007(R -0.054, F 0.041)] [G loss: -0.025]\n",
      "Epoch 554 -- [D loss: -0.006(R -0.065, F 0.053)] [G loss: -0.040]\n",
      "Epoch 555 -- [D loss: -0.003(R -0.057, F 0.052)] [G loss: -0.027]\n",
      "Epoch 556 -- [D loss: -0.004(R -0.066, F 0.058)] [G loss: -0.039]\n",
      "Epoch 557 -- [D loss: 0.002(R -0.064, F 0.067)] [G loss: -0.048]\n",
      "Epoch 558 -- [D loss: -0.007(R -0.084, F 0.070)] [G loss: -0.060]\n",
      "Epoch 559 -- [D loss: 0.001(R -0.079, F 0.080)] [G loss: -0.064]\n",
      "Epoch 560 -- [D loss: -0.009(R -0.087, F 0.069)] [G loss: -0.071]\n",
      "Epoch 561 -- [D loss: -0.012(R -0.088, F 0.064)] [G loss: -0.080]\n",
      "Epoch 562 -- [D loss: -0.009(R -0.084, F 0.065)] [G loss: -0.084]\n",
      "Epoch 563 -- [D loss: -0.002(R -0.083, F 0.078)] [G loss: -0.073]\n",
      "Epoch 564 -- [D loss: -0.004(R -0.096, F 0.088)] [G loss: -0.062]\n",
      "Epoch 565 -- [D loss: -0.009(R -0.090, F 0.072)] [G loss: -0.060]\n",
      "Epoch 566 -- [D loss: -0.003(R -0.086, F 0.079)] [G loss: -0.061]\n",
      "Epoch 567 -- [D loss: -0.011(R -0.096, F 0.074)] [G loss: -0.059]\n",
      "Epoch 568 -- [D loss: -0.014(R -0.096, F 0.068)] [G loss: -0.058]\n",
      "Epoch 569 -- [D loss: -0.004(R -0.100, F 0.093)] [G loss: -0.068]\n",
      "Epoch 570 -- [D loss: -0.010(R -0.120, F 0.101)] [G loss: -0.065]\n",
      "Epoch 571 -- [D loss: -0.022(R -0.123, F 0.079)] [G loss: -0.059]\n",
      "Epoch 572 -- [D loss: -0.024(R -0.137, F 0.089)] [G loss: -0.071]\n",
      "Epoch 573 -- [D loss: -0.006(R -0.145, F 0.134)] [G loss: -0.093]\n",
      "Epoch 574 -- [D loss: 0.010(R -0.144, F 0.163)] [G loss: -0.099]\n",
      "Epoch 575 -- [D loss: 0.001(R -0.134, F 0.137)] [G loss: -0.094]\n",
      "Epoch 576 -- [D loss: -0.001(R -0.119, F 0.118)] [G loss: -0.091]\n",
      "Epoch 577 -- [D loss: -0.006(R -0.120, F 0.108)] [G loss: -0.083]\n",
      "Epoch 578 -- [D loss: -0.009(R -0.125, F 0.107)] [G loss: -0.086]\n",
      "Epoch 579 -- [D loss: -0.001(R -0.117, F 0.116)] [G loss: -0.082]\n",
      "Epoch 580 -- [D loss: -0.006(R -0.117, F 0.106)] [G loss: -0.091]\n",
      "Epoch 581 -- [D loss: -0.001(R -0.109, F 0.106)] [G loss: -0.089]\n",
      "Epoch 582 -- [D loss: -0.004(R -0.112, F 0.103)] [G loss: -0.090]\n",
      "Epoch 583 -- [D loss: -0.004(R -0.112, F 0.104)] [G loss: -0.086]\n",
      "Epoch 584 -- [D loss: 0.002(R -0.097, F 0.101)] [G loss: -0.079]\n",
      "Epoch 585 -- [D loss: -0.011(R -0.105, F 0.082)] [G loss: -0.067]\n",
      "Epoch 586 -- [D loss: -0.008(R -0.104, F 0.088)] [G loss: -0.058]\n",
      "Epoch 587 -- [D loss: -0.019(R -0.102, F 0.063)] [G loss: -0.050]\n",
      "Epoch 588 -- [D loss: -0.003(R -0.080, F 0.074)] [G loss: -0.056]\n",
      "Epoch 589 -- [D loss: 0.001(R -0.085, F 0.087)] [G loss: -0.061]\n",
      "Epoch 590 -- [D loss: 0.004(R -0.081, F 0.089)] [G loss: -0.056]\n",
      "Epoch 591 -- [D loss: -0.006(R -0.076, F 0.063)] [G loss: -0.044]\n",
      "Epoch 592 -- [D loss: -0.015(R -0.080, F 0.051)] [G loss: -0.028]\n",
      "Epoch 593 -- [D loss: -0.021(R -0.076, F 0.034)] [G loss: -0.021]\n",
      "Epoch 594 -- [D loss: -0.021(R -0.077, F 0.034)] [G loss: -0.025]\n",
      "Epoch 595 -- [D loss: -0.017(R -0.086, F 0.052)] [G loss: -0.038]\n",
      "Epoch 596 -- [D loss: 0.001(R -0.076, F 0.078)] [G loss: -0.055]\n",
      "Epoch 597 -- [D loss: 0.005(R -0.078, F 0.087)] [G loss: -0.065]\n",
      "Epoch 598 -- [D loss: 0.006(R -0.070, F 0.082)] [G loss: -0.064]\n",
      "Epoch 599 -- [D loss: 0.001(R -0.080, F 0.082)] [G loss: -0.069]\n",
      "Epoch 600 -- [D loss: -0.008(R -0.083, F 0.067)] [G loss: -0.068]\n",
      "INFO:tensorflow:Assets written to: ram://4775db7a-2d25-4e81-b49a-1a37cd7d5d37/assets\n",
      "INFO:tensorflow:Assets written to: ram://8155bd49-16e0-4b27-85f1-ca98e2a19cc4/assets\n",
      "INFO:tensorflow:Assets written to: ram://b27f0375-7f77-4631-bc74-40658962b615/assets\n",
      "Epoch 601 -- [D loss: -0.008(R -0.092, F 0.076)] [G loss: -0.066]\n",
      "Epoch 602 -- [D loss: -0.010(R -0.096, F 0.076)] [G loss: -0.051]\n",
      "Epoch 603 -- [D loss: -0.012(R -0.090, F 0.067)] [G loss: -0.047]\n",
      "Epoch 604 -- [D loss: -0.013(R -0.095, F 0.069)] [G loss: -0.055]\n",
      "Epoch 605 -- [D loss: -0.009(R -0.087, F 0.070)] [G loss: -0.060]\n",
      "Epoch 606 -- [D loss: 0.002(R -0.075, F 0.078)] [G loss: -0.069]\n",
      "Epoch 607 -- [D loss: 0.007(R -0.080, F 0.093)] [G loss: -0.072]\n",
      "Epoch 608 -- [D loss: 0.006(R -0.071, F 0.084)] [G loss: -0.072]\n",
      "Epoch 609 -- [D loss: 0.004(R -0.068, F 0.075)] [G loss: -0.057]\n",
      "Epoch 610 -- [D loss: 0.001(R -0.059, F 0.061)] [G loss: -0.040]\n",
      "Epoch 611 -- [D loss: -0.013(R -0.074, F 0.048)] [G loss: -0.036]\n",
      "Epoch 612 -- [D loss: -0.020(R -0.077, F 0.038)] [G loss: -0.035]\n",
      "Epoch 613 -- [D loss: -0.006(R -0.057, F 0.045)] [G loss: -0.035]\n",
      "Epoch 614 -- [D loss: -0.008(R -0.065, F 0.049)] [G loss: -0.033]\n",
      "Epoch 615 -- [D loss: -0.003(R -0.059, F 0.053)] [G loss: -0.039]\n",
      "Epoch 616 -- [D loss: -0.004(R -0.068, F 0.060)] [G loss: -0.044]\n",
      "Epoch 617 -- [D loss: -0.005(R -0.075, F 0.065)] [G loss: -0.049]\n",
      "Epoch 618 -- [D loss: -0.009(R -0.085, F 0.068)] [G loss: -0.048]\n",
      "Epoch 619 -- [D loss: -0.014(R -0.090, F 0.061)] [G loss: -0.039]\n",
      "Epoch 620 -- [D loss: -0.028(R -0.099, F 0.043)] [G loss: -0.036]\n",
      "Epoch 621 -- [D loss: -0.017(R -0.092, F 0.059)] [G loss: -0.052]\n",
      "Epoch 622 -- [D loss: -0.018(R -0.100, F 0.064)] [G loss: -0.074]\n",
      "Epoch 623 -- [D loss: -0.010(R -0.103, F 0.083)] [G loss: -0.073]\n",
      "Epoch 624 -- [D loss: 0.005(R -0.082, F 0.093)] [G loss: -0.070]\n",
      "Epoch 625 -- [D loss: -0.013(R -0.100, F 0.075)] [G loss: -0.080]\n",
      "Epoch 626 -- [D loss: -0.012(R -0.091, F 0.066)] [G loss: -0.094]\n",
      "Epoch 627 -- [D loss: -0.003(R -0.097, F 0.091)] [G loss: -0.100]\n",
      "Epoch 628 -- [D loss: -0.006(R -0.114, F 0.102)] [G loss: -0.093]\n",
      "Epoch 629 -- [D loss: -0.005(R -0.104, F 0.095)] [G loss: -0.084]\n",
      "Epoch 630 -- [D loss: 0.011(R -0.084, F 0.106)] [G loss: -0.076]\n",
      "Epoch 631 -- [D loss: 0.013(R -0.078, F 0.104)] [G loss: -0.078]\n",
      "Epoch 632 -- [D loss: 0.007(R -0.085, F 0.099)] [G loss: -0.079]\n",
      "Epoch 633 -- [D loss: -0.002(R -0.089, F 0.085)] [G loss: -0.072]\n",
      "Epoch 634 -- [D loss: -0.005(R -0.091, F 0.081)] [G loss: -0.066]\n",
      "Epoch 635 -- [D loss: -0.008(R -0.094, F 0.077)] [G loss: -0.054]\n",
      "Epoch 636 -- [D loss: -0.012(R -0.091, F 0.067)] [G loss: -0.043]\n",
      "Epoch 637 -- [D loss: -0.013(R -0.086, F 0.060)] [G loss: -0.035]\n",
      "Epoch 638 -- [D loss: -0.022(R -0.099, F 0.055)] [G loss: -0.026]\n",
      "Epoch 639 -- [D loss: -0.029(R -0.096, F 0.038)] [G loss: -0.018]\n",
      "Epoch 640 -- [D loss: -0.035(R -0.106, F 0.036)] [G loss: -0.028]\n",
      "Epoch 641 -- [D loss: -0.019(R -0.093, F 0.055)] [G loss: -0.038]\n",
      "Epoch 642 -- [D loss: -0.015(R -0.093, F 0.063)] [G loss: -0.054]\n",
      "Epoch 643 -- [D loss: -0.009(R -0.088, F 0.069)] [G loss: -0.066]\n",
      "Epoch 644 -- [D loss: -0.005(R -0.091, F 0.081)] [G loss: -0.072]\n",
      "Epoch 645 -- [D loss: 0.001(R -0.095, F 0.097)] [G loss: -0.087]\n",
      "Epoch 646 -- [D loss: 0.002(R -0.095, F 0.099)] [G loss: -0.082]\n",
      "Epoch 647 -- [D loss: 0.002(R -0.095, F 0.098)] [G loss: -0.092]\n",
      "Epoch 648 -- [D loss: 0.020(R -0.078, F 0.118)] [G loss: -0.085]\n",
      "Epoch 649 -- [D loss: 0.010(R -0.095, F 0.115)] [G loss: -0.080]\n",
      "Epoch 650 -- [D loss: -0.006(R -0.100, F 0.087)] [G loss: -0.080]\n",
      "Epoch 651 -- [D loss: 0.001(R -0.084, F 0.086)] [G loss: -0.074]\n",
      "Epoch 652 -- [D loss: -0.004(R -0.087, F 0.080)] [G loss: -0.066]\n",
      "Epoch 653 -- [D loss: -0.010(R -0.085, F 0.065)] [G loss: -0.050]\n",
      "Epoch 654 -- [D loss: -0.016(R -0.084, F 0.052)] [G loss: -0.037]\n",
      "Epoch 655 -- [D loss: -0.020(R -0.085, F 0.044)] [G loss: -0.031]\n",
      "Epoch 656 -- [D loss: -0.021(R -0.085, F 0.043)] [G loss: -0.021]\n",
      "Epoch 657 -- [D loss: -0.026(R -0.097, F 0.045)] [G loss: -0.024]\n",
      "Epoch 658 -- [D loss: -0.021(R -0.098, F 0.055)] [G loss: -0.030]\n",
      "Epoch 659 -- [D loss: -0.012(R -0.094, F 0.070)] [G loss: -0.052]\n",
      "Epoch 660 -- [D loss: -0.014(R -0.104, F 0.075)] [G loss: -0.065]\n",
      "Epoch 661 -- [D loss: -0.016(R -0.120, F 0.088)] [G loss: -0.087]\n",
      "Epoch 662 -- [D loss: -0.012(R -0.115, F 0.091)] [G loss: -0.093]\n",
      "Epoch 663 -- [D loss: 0.001(R -0.118, F 0.121)] [G loss: -0.087]\n",
      "Epoch 664 -- [D loss: -0.002(R -0.108, F 0.105)] [G loss: -0.077]\n",
      "Epoch 665 -- [D loss: -0.003(R -0.106, F 0.100)] [G loss: -0.088]\n",
      "Epoch 666 -- [D loss: -0.006(R -0.116, F 0.105)] [G loss: -0.098]\n",
      "Epoch 667 -- [D loss: -0.000(R -0.123, F 0.122)] [G loss: -0.099]\n",
      "Epoch 668 -- [D loss: -0.004(R -0.126, F 0.118)] [G loss: -0.103]\n",
      "Epoch 669 -- [D loss: -0.003(R -0.126, F 0.119)] [G loss: -0.101]\n",
      "Epoch 670 -- [D loss: 0.000(R -0.121, F 0.122)] [G loss: -0.092]\n",
      "Epoch 671 -- [D loss: -0.006(R -0.127, F 0.115)] [G loss: -0.095]\n",
      "Epoch 672 -- [D loss: -0.008(R -0.130, F 0.114)] [G loss: -0.092]\n",
      "Epoch 673 -- [D loss: -0.004(R -0.119, F 0.111)] [G loss: -0.094]\n",
      "Epoch 674 -- [D loss: -0.002(R -0.122, F 0.118)] [G loss: -0.100]\n",
      "Epoch 675 -- [D loss: -0.004(R -0.125, F 0.118)] [G loss: -0.103]\n",
      "Epoch 676 -- [D loss: -0.003(R -0.126, F 0.120)] [G loss: -0.097]\n",
      "Epoch 677 -- [D loss: 0.001(R -0.114, F 0.115)] [G loss: -0.092]\n",
      "Epoch 678 -- [D loss: -0.005(R -0.115, F 0.105)] [G loss: -0.087]\n",
      "Epoch 679 -- [D loss: -0.006(R -0.125, F 0.112)] [G loss: -0.089]\n",
      "Epoch 680 -- [D loss: -0.007(R -0.126, F 0.112)] [G loss: -0.097]\n",
      "Epoch 681 -- [D loss: -0.007(R -0.128, F 0.114)] [G loss: -0.095]\n",
      "Epoch 682 -- [D loss: -0.005(R -0.122, F 0.112)] [G loss: -0.092]\n",
      "Epoch 683 -- [D loss: -0.008(R -0.120, F 0.104)] [G loss: -0.093]\n",
      "Epoch 684 -- [D loss: -0.011(R -0.120, F 0.097)] [G loss: -0.089]\n",
      "Epoch 685 -- [D loss: -0.006(R -0.121, F 0.109)] [G loss: -0.092]\n",
      "Epoch 686 -- [D loss: -0.004(R -0.117, F 0.108)] [G loss: -0.091]\n",
      "Epoch 687 -- [D loss: -0.004(R -0.116, F 0.109)] [G loss: -0.089]\n",
      "Epoch 688 -- [D loss: 0.000(R -0.114, F 0.115)] [G loss: -0.088]\n",
      "Epoch 689 -- [D loss: -0.004(R -0.114, F 0.106)] [G loss: -0.089]\n",
      "Epoch 690 -- [D loss: -0.004(R -0.110, F 0.103)] [G loss: -0.088]\n",
      "Epoch 691 -- [D loss: -0.007(R -0.113, F 0.099)] [G loss: -0.083]\n",
      "Epoch 692 -- [D loss: -0.009(R -0.117, F 0.099)] [G loss: -0.080]\n",
      "Epoch 693 -- [D loss: -0.009(R -0.116, F 0.097)] [G loss: -0.081]\n",
      "Epoch 694 -- [D loss: -0.011(R -0.117, F 0.095)] [G loss: -0.081]\n",
      "Epoch 695 -- [D loss: -0.015(R -0.128, F 0.099)] [G loss: -0.084]\n",
      "Epoch 696 -- [D loss: -0.004(R -0.112, F 0.103)] [G loss: -0.088]\n",
      "Epoch 697 -- [D loss: -0.003(R -0.116, F 0.110)] [G loss: -0.092]\n",
      "Epoch 698 -- [D loss: -0.007(R -0.124, F 0.111)] [G loss: -0.093]\n",
      "Epoch 699 -- [D loss: -0.008(R -0.123, F 0.108)] [G loss: -0.097]\n",
      "Epoch 700 -- [D loss: -0.004(R -0.118, F 0.110)] [G loss: -0.090]\n",
      "INFO:tensorflow:Assets written to: ram://7d0b6779-35c6-4b45-b06e-656aafc9e593/assets\n",
      "INFO:tensorflow:Assets written to: ram://b534c0f2-7dba-494f-bd67-c74d6b061e80/assets\n",
      "INFO:tensorflow:Assets written to: ram://6ca96f67-0ec7-4797-9796-617bca2a67bd/assets\n",
      "Epoch 701 -- [D loss: 0.001(R -0.118, F 0.119)] [G loss: -0.096]\n",
      "Epoch 702 -- [D loss: -0.009(R -0.125, F 0.107)] [G loss: -0.094]\n",
      "Epoch 703 -- [D loss: -0.004(R -0.121, F 0.113)] [G loss: -0.093]\n",
      "Epoch 704 -- [D loss: -0.008(R -0.125, F 0.109)] [G loss: -0.095]\n",
      "Epoch 705 -- [D loss: -0.004(R -0.118, F 0.110)] [G loss: -0.094]\n",
      "Epoch 706 -- [D loss: -0.006(R -0.124, F 0.113)] [G loss: -0.101]\n",
      "Epoch 707 -- [D loss: -0.005(R -0.127, F 0.117)] [G loss: -0.107]\n",
      "Epoch 708 -- [D loss: 0.000(R -0.129, F 0.129)] [G loss: -0.114]\n",
      "Epoch 709 -- [D loss: 0.001(R -0.128, F 0.130)] [G loss: -0.117]\n",
      "Epoch 710 -- [D loss: 0.001(R -0.122, F 0.125)] [G loss: -0.115]\n",
      "Epoch 711 -- [D loss: 0.000(R -0.128, F 0.129)] [G loss: -0.118]\n",
      "Epoch 712 -- [D loss: 0.001(R -0.120, F 0.123)] [G loss: -0.110]\n",
      "Epoch 713 -- [D loss: -0.001(R -0.125, F 0.123)] [G loss: -0.106]\n",
      "Epoch 714 -- [D loss: 0.003(R -0.115, F 0.121)] [G loss: -0.102]\n",
      "Epoch 715 -- [D loss: 0.000(R -0.116, F 0.117)] [G loss: -0.096]\n",
      "Epoch 716 -- [D loss: -0.003(R -0.110, F 0.105)] [G loss: -0.091]\n",
      "Epoch 717 -- [D loss: -0.006(R -0.113, F 0.101)] [G loss: -0.090]\n",
      "Epoch 718 -- [D loss: -0.008(R -0.111, F 0.095)] [G loss: -0.081]\n",
      "Epoch 719 -- [D loss: -0.007(R -0.108, F 0.093)] [G loss: -0.080]\n",
      "Epoch 720 -- [D loss: -0.008(R -0.109, F 0.092)] [G loss: -0.073]\n",
      "Epoch 721 -- [D loss: -0.005(R -0.104, F 0.093)] [G loss: -0.071]\n",
      "Epoch 722 -- [D loss: -0.014(R -0.103, F 0.076)] [G loss: -0.070]\n",
      "Epoch 723 -- [D loss: -0.014(R -0.108, F 0.080)] [G loss: -0.073]\n",
      "Epoch 724 -- [D loss: -0.006(R -0.098, F 0.085)] [G loss: -0.074]\n",
      "Epoch 725 -- [D loss: -0.004(R -0.095, F 0.087)] [G loss: -0.077]\n",
      "Epoch 726 -- [D loss: -0.004(R -0.100, F 0.092)] [G loss: -0.082]\n",
      "Epoch 727 -- [D loss: 0.002(R -0.095, F 0.099)] [G loss: -0.087]\n",
      "Epoch 728 -- [D loss: 0.009(R -0.085, F 0.102)] [G loss: -0.094]\n",
      "Epoch 729 -- [D loss: 0.010(R -0.086, F 0.106)] [G loss: -0.094]\n",
      "Epoch 730 -- [D loss: 0.005(R -0.090, F 0.099)] [G loss: -0.095]\n",
      "Epoch 731 -- [D loss: 0.005(R -0.086, F 0.096)] [G loss: -0.089]\n",
      "Epoch 732 -- [D loss: 0.003(R -0.086, F 0.092)] [G loss: -0.080]\n",
      "Epoch 733 -- [D loss: -0.004(R -0.088, F 0.081)] [G loss: -0.071]\n",
      "Epoch 734 -- [D loss: -0.006(R -0.087, F 0.074)] [G loss: -0.066]\n",
      "Epoch 735 -- [D loss: -0.007(R -0.090, F 0.076)] [G loss: -0.060]\n",
      "Epoch 736 -- [D loss: -0.008(R -0.092, F 0.076)] [G loss: -0.059]\n",
      "Epoch 737 -- [D loss: -0.009(R -0.092, F 0.073)] [G loss: -0.059]\n",
      "Epoch 738 -- [D loss: -0.013(R -0.099, F 0.074)] [G loss: -0.060]\n",
      "Epoch 739 -- [D loss: -0.014(R -0.101, F 0.073)] [G loss: -0.063]\n",
      "Epoch 740 -- [D loss: -0.015(R -0.100, F 0.070)] [G loss: -0.066]\n",
      "Epoch 741 -- [D loss: -0.010(R -0.103, F 0.082)] [G loss: -0.069]\n",
      "Epoch 742 -- [D loss: -0.005(R -0.104, F 0.094)] [G loss: -0.075]\n",
      "Epoch 743 -- [D loss: -0.008(R -0.101, F 0.086)] [G loss: -0.073]\n",
      "Epoch 744 -- [D loss: -0.003(R -0.108, F 0.102)] [G loss: -0.081]\n",
      "Epoch 745 -- [D loss: 0.002(R -0.097, F 0.102)] [G loss: -0.081]\n",
      "Epoch 746 -- [D loss: -0.001(R -0.098, F 0.095)] [G loss: -0.088]\n",
      "Epoch 747 -- [D loss: 0.000(R -0.100, F 0.100)] [G loss: -0.089]\n",
      "Epoch 748 -- [D loss: -0.002(R -0.100, F 0.096)] [G loss: -0.092]\n",
      "Epoch 749 -- [D loss: -0.003(R -0.106, F 0.099)] [G loss: -0.089]\n",
      "Epoch 750 -- [D loss: -0.005(R -0.105, F 0.096)] [G loss: -0.088]\n",
      "Epoch 751 -- [D loss: -0.004(R -0.107, F 0.099)] [G loss: -0.086]\n",
      "Epoch 752 -- [D loss: -0.005(R -0.107, F 0.097)] [G loss: -0.079]\n",
      "Epoch 753 -- [D loss: -0.004(R -0.101, F 0.092)] [G loss: -0.075]\n",
      "Epoch 754 -- [D loss: -0.007(R -0.104, F 0.089)] [G loss: -0.077]\n",
      "Epoch 755 -- [D loss: -0.004(R -0.102, F 0.093)] [G loss: -0.075]\n",
      "Epoch 756 -- [D loss: -0.009(R -0.106, F 0.087)] [G loss: -0.073]\n",
      "Epoch 757 -- [D loss: -0.005(R -0.098, F 0.088)] [G loss: -0.073]\n",
      "Epoch 758 -- [D loss: -0.005(R -0.088, F 0.079)] [G loss: -0.062]\n",
      "Epoch 759 -- [D loss: -0.006(R -0.086, F 0.074)] [G loss: -0.064]\n",
      "Epoch 760 -- [D loss: -0.008(R -0.087, F 0.071)] [G loss: -0.063]\n",
      "Epoch 761 -- [D loss: -0.008(R -0.086, F 0.071)] [G loss: -0.061]\n",
      "Epoch 762 -- [D loss: -0.010(R -0.090, F 0.070)] [G loss: -0.058]\n",
      "Epoch 763 -- [D loss: -0.014(R -0.091, F 0.064)] [G loss: -0.061]\n",
      "Epoch 764 -- [D loss: -0.011(R -0.091, F 0.069)] [G loss: -0.063]\n",
      "Epoch 765 -- [D loss: -0.007(R -0.086, F 0.071)] [G loss: -0.069]\n",
      "Epoch 766 -- [D loss: -0.012(R -0.096, F 0.072)] [G loss: -0.068]\n",
      "Epoch 767 -- [D loss: -0.007(R -0.098, F 0.084)] [G loss: -0.074]\n",
      "Epoch 768 -- [D loss: -0.001(R -0.098, F 0.097)] [G loss: -0.087]\n",
      "Epoch 769 -- [D loss: -0.003(R -0.100, F 0.094)] [G loss: -0.086]\n",
      "Epoch 770 -- [D loss: -0.005(R -0.100, F 0.090)] [G loss: -0.083]\n",
      "Epoch 771 -- [D loss: -0.002(R -0.107, F 0.104)] [G loss: -0.091]\n",
      "Epoch 772 -- [D loss: -0.006(R -0.113, F 0.101)] [G loss: -0.094]\n",
      "Epoch 773 -- [D loss: -0.006(R -0.118, F 0.106)] [G loss: -0.093]\n",
      "Epoch 774 -- [D loss: -0.008(R -0.118, F 0.103)] [G loss: -0.093]\n",
      "Epoch 775 -- [D loss: -0.008(R -0.113, F 0.097)] [G loss: -0.083]\n",
      "Epoch 776 -- [D loss: -0.011(R -0.112, F 0.090)] [G loss: -0.087]\n",
      "Epoch 777 -- [D loss: -0.007(R -0.108, F 0.094)] [G loss: -0.093]\n",
      "Epoch 778 -- [D loss: -0.012(R -0.118, F 0.094)] [G loss: -0.091]\n",
      "Epoch 779 -- [D loss: -0.010(R -0.114, F 0.095)] [G loss: -0.098]\n",
      "Epoch 780 -- [D loss: -0.002(R -0.117, F 0.112)] [G loss: -0.100]\n",
      "Epoch 781 -- [D loss: 0.003(R -0.117, F 0.122)] [G loss: -0.104]\n",
      "Epoch 782 -- [D loss: 0.004(R -0.120, F 0.127)] [G loss: -0.103]\n",
      "Epoch 783 -- [D loss: -0.004(R -0.121, F 0.114)] [G loss: -0.098]\n",
      "Epoch 784 -- [D loss: -0.007(R -0.119, F 0.105)] [G loss: -0.094]\n",
      "Epoch 785 -- [D loss: -0.007(R -0.121, F 0.107)] [G loss: -0.091]\n",
      "Epoch 786 -- [D loss: -0.001(R -0.121, F 0.120)] [G loss: -0.095]\n",
      "Epoch 787 -- [D loss: -0.002(R -0.114, F 0.110)] [G loss: -0.082]\n",
      "Epoch 788 -- [D loss: -0.008(R -0.108, F 0.091)] [G loss: -0.078]\n",
      "Epoch 789 -- [D loss: -0.008(R -0.110, F 0.093)] [G loss: -0.078]\n",
      "Epoch 790 -- [D loss: -0.011(R -0.109, F 0.088)] [G loss: -0.078]\n",
      "Epoch 791 -- [D loss: -0.010(R -0.106, F 0.086)] [G loss: -0.073]\n",
      "Epoch 792 -- [D loss: -0.009(R -0.108, F 0.090)] [G loss: -0.075]\n",
      "Epoch 793 -- [D loss: -0.010(R -0.106, F 0.087)] [G loss: -0.078]\n",
      "Epoch 794 -- [D loss: -0.009(R -0.100, F 0.083)] [G loss: -0.078]\n",
      "Epoch 795 -- [D loss: -0.004(R -0.101, F 0.093)] [G loss: -0.078]\n",
      "Epoch 796 -- [D loss: -0.006(R -0.110, F 0.097)] [G loss: -0.084]\n",
      "Epoch 797 -- [D loss: -0.001(R -0.105, F 0.103)] [G loss: -0.086]\n",
      "Epoch 798 -- [D loss: -0.003(R -0.108, F 0.102)] [G loss: -0.081]\n",
      "Epoch 799 -- [D loss: -0.007(R -0.107, F 0.093)] [G loss: -0.078]\n",
      "Epoch 800 -- [D loss: -0.004(R -0.106, F 0.099)] [G loss: -0.090]\n",
      "INFO:tensorflow:Assets written to: ram://1754e7e7-85fb-45f6-8c0e-c23e776ac6a1/assets\n",
      "INFO:tensorflow:Assets written to: ram://e6077244-4a67-4b1d-a137-a6367bb6d703/assets\n",
      "INFO:tensorflow:Assets written to: ram://de879de5-382a-4011-9b66-dfc28105ac81/assets\n",
      "Epoch 801 -- [D loss: -0.012(R -0.116, F 0.092)] [G loss: -0.089]\n",
      "Epoch 802 -- [D loss: -0.014(R -0.116, F 0.089)] [G loss: -0.090]\n",
      "Epoch 803 -- [D loss: -0.011(R -0.122, F 0.099)] [G loss: -0.091]\n",
      "Epoch 804 -- [D loss: -0.002(R -0.122, F 0.117)] [G loss: -0.101]\n",
      "Epoch 805 -- [D loss: -0.014(R -0.130, F 0.102)] [G loss: -0.098]\n",
      "Epoch 806 -- [D loss: -0.014(R -0.130, F 0.101)] [G loss: -0.092]\n",
      "Epoch 807 -- [D loss: -0.012(R -0.131, F 0.107)] [G loss: -0.093]\n",
      "Epoch 808 -- [D loss: -0.008(R -0.136, F 0.121)] [G loss: -0.107]\n",
      "Epoch 809 -- [D loss: -0.006(R -0.138, F 0.127)] [G loss: -0.105]\n",
      "Epoch 810 -- [D loss: -0.011(R -0.140, F 0.119)] [G loss: -0.108]\n",
      "Epoch 811 -- [D loss: -0.011(R -0.146, F 0.124)] [G loss: -0.114]\n",
      "Epoch 812 -- [D loss: -0.005(R -0.133, F 0.124)] [G loss: -0.110]\n",
      "Epoch 813 -- [D loss: -0.008(R -0.136, F 0.120)] [G loss: -0.101]\n",
      "Epoch 814 -- [D loss: -0.001(R -0.130, F 0.128)] [G loss: -0.103]\n",
      "Epoch 815 -- [D loss: -0.007(R -0.137, F 0.123)] [G loss: -0.106]\n",
      "Epoch 816 -- [D loss: -0.015(R -0.143, F 0.112)] [G loss: -0.112]\n",
      "Epoch 817 -- [D loss: -0.011(R -0.143, F 0.121)] [G loss: -0.114]\n",
      "Epoch 818 -- [D loss: -0.003(R -0.135, F 0.129)] [G loss: -0.109]\n",
      "Epoch 819 -- [D loss: -0.007(R -0.141, F 0.126)] [G loss: -0.101]\n",
      "Epoch 820 -- [D loss: -0.012(R -0.145, F 0.120)] [G loss: -0.104]\n",
      "Epoch 821 -- [D loss: -0.010(R -0.141, F 0.122)] [G loss: -0.112]\n",
      "Epoch 822 -- [D loss: -0.017(R -0.150, F 0.117)] [G loss: -0.113]\n",
      "Epoch 823 -- [D loss: -0.009(R -0.144, F 0.125)] [G loss: -0.112]\n",
      "Epoch 824 -- [D loss: -0.008(R -0.144, F 0.129)] [G loss: -0.112]\n",
      "Epoch 825 -- [D loss: -0.009(R -0.135, F 0.116)] [G loss: -0.108]\n",
      "Epoch 826 -- [D loss: -0.016(R -0.140, F 0.109)] [G loss: -0.102]\n",
      "Epoch 827 -- [D loss: -0.016(R -0.136, F 0.104)] [G loss: -0.099]\n",
      "Epoch 828 -- [D loss: -0.006(R -0.132, F 0.119)] [G loss: -0.105]\n",
      "Epoch 829 -- [D loss: -0.008(R -0.145, F 0.130)] [G loss: -0.108]\n",
      "Epoch 830 -- [D loss: -0.009(R -0.140, F 0.123)] [G loss: -0.115]\n",
      "Epoch 831 -- [D loss: -0.006(R -0.141, F 0.129)] [G loss: -0.122]\n",
      "Epoch 832 -- [D loss: -0.017(R -0.147, F 0.113)] [G loss: -0.131]\n",
      "Epoch 833 -- [D loss: -0.004(R -0.147, F 0.138)] [G loss: -0.128]\n",
      "Epoch 834 -- [D loss: 0.001(R -0.142, F 0.143)] [G loss: -0.118]\n",
      "Epoch 835 -- [D loss: -0.004(R -0.154, F 0.146)] [G loss: -0.122]\n",
      "Epoch 836 -- [D loss: -0.007(R -0.155, F 0.142)] [G loss: -0.129]\n",
      "Epoch 837 -- [D loss: -0.011(R -0.166, F 0.143)] [G loss: -0.130]\n",
      "Epoch 838 -- [D loss: -0.010(R -0.167, F 0.147)] [G loss: -0.124]\n",
      "Epoch 839 -- [D loss: -0.008(R -0.167, F 0.151)] [G loss: -0.128]\n",
      "Epoch 840 -- [D loss: -0.010(R -0.175, F 0.155)] [G loss: -0.136]\n",
      "Epoch 841 -- [D loss: -0.010(R -0.175, F 0.154)] [G loss: -0.131]\n",
      "Epoch 842 -- [D loss: -0.013(R -0.178, F 0.153)] [G loss: -0.129]\n",
      "Epoch 843 -- [D loss: -0.019(R -0.174, F 0.135)] [G loss: -0.134]\n",
      "Epoch 844 -- [D loss: -0.008(R -0.177, F 0.161)] [G loss: -0.145]\n",
      "Epoch 845 -- [D loss: -0.003(R -0.169, F 0.163)] [G loss: -0.151]\n",
      "Epoch 846 -- [D loss: -0.006(R -0.170, F 0.159)] [G loss: -0.144]\n",
      "Epoch 847 -- [D loss: -0.011(R -0.172, F 0.150)] [G loss: -0.133]\n",
      "Epoch 848 -- [D loss: -0.014(R -0.170, F 0.142)] [G loss: -0.126]\n",
      "Epoch 849 -- [D loss: -0.009(R -0.170, F 0.152)] [G loss: -0.138]\n",
      "Epoch 850 -- [D loss: -0.016(R -0.165, F 0.133)] [G loss: -0.136]\n",
      "Epoch 851 -- [D loss: -0.021(R -0.182, F 0.141)] [G loss: -0.139]\n",
      "Epoch 852 -- [D loss: 0.001(R -0.163, F 0.164)] [G loss: -0.140]\n",
      "Epoch 853 -- [D loss: 0.001(R -0.160, F 0.162)] [G loss: -0.134]\n",
      "Epoch 854 -- [D loss: -0.006(R -0.159, F 0.147)] [G loss: -0.133]\n",
      "Epoch 855 -- [D loss: -0.010(R -0.150, F 0.129)] [G loss: -0.120]\n",
      "Epoch 856 -- [D loss: -0.018(R -0.157, F 0.121)] [G loss: -0.107]\n",
      "Epoch 857 -- [D loss: -0.019(R -0.150, F 0.112)] [G loss: -0.098]\n",
      "Epoch 858 -- [D loss: -0.018(R -0.163, F 0.126)] [G loss: -0.103]\n",
      "Epoch 859 -- [D loss: -0.018(R -0.159, F 0.122)] [G loss: -0.109]\n",
      "Epoch 860 -- [D loss: -0.021(R -0.165, F 0.124)] [G loss: -0.120]\n",
      "Epoch 861 -- [D loss: -0.018(R -0.172, F 0.137)] [G loss: -0.121]\n",
      "Epoch 862 -- [D loss: -0.011(R -0.167, F 0.145)] [G loss: -0.130]\n",
      "Epoch 863 -- [D loss: -0.005(R -0.159, F 0.148)] [G loss: -0.126]\n",
      "Epoch 864 -- [D loss: -0.016(R -0.167, F 0.136)] [G loss: -0.132]\n",
      "Epoch 865 -- [D loss: -0.013(R -0.165, F 0.139)] [G loss: -0.143]\n",
      "Epoch 866 -- [D loss: -0.025(R -0.188, F 0.139)] [G loss: -0.156]\n",
      "Epoch 867 -- [D loss: -0.015(R -0.193, F 0.163)] [G loss: -0.168]\n",
      "Epoch 868 -- [D loss: 0.005(R -0.183, F 0.192)] [G loss: -0.170]\n",
      "Epoch 869 -- [D loss: 0.007(R -0.173, F 0.187)] [G loss: -0.153]\n",
      "Epoch 870 -- [D loss: -0.009(R -0.171, F 0.152)] [G loss: -0.135]\n",
      "Epoch 871 -- [D loss: -0.028(R -0.185, F 0.128)] [G loss: -0.118]\n",
      "Epoch 872 -- [D loss: -0.027(R -0.178, F 0.124)] [G loss: -0.109]\n",
      "Epoch 873 -- [D loss: -0.022(R -0.175, F 0.131)] [G loss: -0.115]\n",
      "Epoch 874 -- [D loss: -0.015(R -0.179, F 0.149)] [G loss: -0.131]\n",
      "Epoch 875 -- [D loss: -0.013(R -0.185, F 0.159)] [G loss: -0.133]\n",
      "Epoch 876 -- [D loss: -0.014(R -0.182, F 0.154)] [G loss: -0.133]\n",
      "Epoch 877 -- [D loss: -0.028(R -0.197, F 0.141)] [G loss: -0.140]\n",
      "Epoch 878 -- [D loss: -0.025(R -0.191, F 0.140)] [G loss: -0.157]\n",
      "Epoch 879 -- [D loss: -0.044(R -0.217, F 0.128)] [G loss: -0.164]\n",
      "Epoch 880 -- [D loss: -0.018(R -0.226, F 0.189)] [G loss: -0.179]\n",
      "Epoch 881 -- [D loss: 0.015(R -0.222, F 0.252)] [G loss: -0.189]\n",
      "Epoch 882 -- [D loss: 0.019(R -0.221, F 0.260)] [G loss: -0.211]\n",
      "Epoch 883 -- [D loss: -0.002(R -0.231, F 0.227)] [G loss: -0.215]\n",
      "Epoch 884 -- [D loss: -0.012(R -0.237, F 0.212)] [G loss: -0.217]\n",
      "Epoch 885 -- [D loss: -0.012(R -0.250, F 0.226)] [G loss: -0.207]\n",
      "Epoch 886 -- [D loss: -0.011(R -0.246, F 0.224)] [G loss: -0.200]\n",
      "Epoch 887 -- [D loss: -0.006(R -0.242, F 0.229)] [G loss: -0.191]\n",
      "Epoch 888 -- [D loss: -0.006(R -0.230, F 0.218)] [G loss: -0.192]\n",
      "Epoch 889 -- [D loss: -0.012(R -0.229, F 0.205)] [G loss: -0.192]\n",
      "Epoch 890 -- [D loss: -0.002(R -0.221, F 0.216)] [G loss: -0.199]\n",
      "Epoch 891 -- [D loss: -0.002(R -0.220, F 0.215)] [G loss: -0.196]\n",
      "Epoch 892 -- [D loss: -0.007(R -0.223, F 0.209)] [G loss: -0.192]\n",
      "Epoch 893 -- [D loss: -0.007(R -0.219, F 0.205)] [G loss: -0.184]\n",
      "Epoch 894 -- [D loss: -0.001(R -0.214, F 0.212)] [G loss: -0.180]\n",
      "Epoch 895 -- [D loss: -0.004(R -0.208, F 0.200)] [G loss: -0.174]\n",
      "Epoch 896 -- [D loss: -0.008(R -0.212, F 0.197)] [G loss: -0.175]\n",
      "Epoch 897 -- [D loss: -0.021(R -0.212, F 0.170)] [G loss: -0.167]\n",
      "Epoch 898 -- [D loss: -0.013(R -0.203, F 0.177)] [G loss: -0.161]\n",
      "Epoch 899 -- [D loss: -0.013(R -0.200, F 0.174)] [G loss: -0.148]\n",
      "Epoch 900 -- [D loss: -0.019(R -0.203, F 0.166)] [G loss: -0.138]\n",
      "INFO:tensorflow:Assets written to: ram://c24e5d0f-6840-41cf-8f6a-94c28fd8ab23/assets\n",
      "INFO:tensorflow:Assets written to: ram://0ebb1b2b-b07e-4e11-a295-80f4f5dc5e16/assets\n",
      "INFO:tensorflow:Assets written to: ram://07ec2e13-cd53-4736-979f-1d7796a988d8/assets\n",
      "Epoch 901 -- [D loss: -0.027(R -0.209, F 0.155)] [G loss: -0.133]\n",
      "Epoch 902 -- [D loss: -0.016(R -0.201, F 0.169)] [G loss: -0.144]\n",
      "Epoch 903 -- [D loss: -0.015(R -0.210, F 0.179)] [G loss: -0.155]\n",
      "Epoch 904 -- [D loss: -0.020(R -0.216, F 0.176)] [G loss: -0.164]\n",
      "Epoch 905 -- [D loss: -0.020(R -0.207, F 0.168)] [G loss: -0.169]\n",
      "Epoch 906 -- [D loss: -0.014(R -0.215, F 0.187)] [G loss: -0.167]\n",
      "Epoch 907 -- [D loss: -0.002(R -0.215, F 0.212)] [G loss: -0.190]\n",
      "Epoch 908 -- [D loss: -0.004(R -0.228, F 0.220)] [G loss: -0.209]\n",
      "Epoch 909 -- [D loss: -0.031(R -0.250, F 0.189)] [G loss: -0.225]\n",
      "Epoch 910 -- [D loss: -0.012(R -0.253, F 0.228)] [G loss: -0.234]\n",
      "Epoch 911 -- [D loss: -0.006(R -0.248, F 0.236)] [G loss: -0.219]\n",
      "Epoch 912 -- [D loss: -0.002(R -0.239, F 0.235)] [G loss: -0.200]\n",
      "Epoch 913 -- [D loss: -0.013(R -0.232, F 0.206)] [G loss: -0.176]\n",
      "Epoch 914 -- [D loss: -0.019(R -0.230, F 0.193)] [G loss: -0.162]\n",
      "Epoch 915 -- [D loss: -0.023(R -0.231, F 0.186)] [G loss: -0.160]\n",
      "Epoch 916 -- [D loss: -0.023(R -0.230, F 0.184)] [G loss: -0.174]\n",
      "Epoch 917 -- [D loss: -0.019(R -0.234, F 0.196)] [G loss: -0.197]\n",
      "Epoch 918 -- [D loss: -0.009(R -0.233, F 0.216)] [G loss: -0.218]\n",
      "Epoch 919 -- [D loss: -0.013(R -0.253, F 0.227)] [G loss: -0.231]\n",
      "Epoch 920 -- [D loss: -0.000(R -0.245, F 0.245)] [G loss: -0.228]\n",
      "Epoch 921 -- [D loss: -0.003(R -0.244, F 0.239)] [G loss: -0.205]\n",
      "Epoch 922 -- [D loss: -0.013(R -0.246, F 0.221)] [G loss: -0.185]\n",
      "Epoch 923 -- [D loss: -0.019(R -0.239, F 0.200)] [G loss: -0.180]\n",
      "Epoch 924 -- [D loss: -0.020(R -0.246, F 0.206)] [G loss: -0.193]\n",
      "Epoch 925 -- [D loss: -0.006(R -0.239, F 0.227)] [G loss: -0.216]\n",
      "Epoch 926 -- [D loss: -0.012(R -0.260, F 0.235)] [G loss: -0.232]\n",
      "Epoch 927 -- [D loss: -0.004(R -0.260, F 0.252)] [G loss: -0.227]\n",
      "Epoch 928 -- [D loss: -0.014(R -0.255, F 0.228)] [G loss: -0.212]\n",
      "Epoch 929 -- [D loss: -0.009(R -0.244, F 0.227)] [G loss: -0.202]\n",
      "Epoch 930 -- [D loss: -0.012(R -0.233, F 0.208)] [G loss: -0.180]\n",
      "Epoch 931 -- [D loss: -0.019(R -0.223, F 0.185)] [G loss: -0.181]\n",
      "Epoch 932 -- [D loss: -0.032(R -0.234, F 0.171)] [G loss: -0.189]\n",
      "Epoch 933 -- [D loss: -0.029(R -0.221, F 0.163)] [G loss: -0.203]\n",
      "Epoch 934 -- [D loss: -0.034(R -0.252, F 0.185)] [G loss: -0.219]\n",
      "Epoch 935 -- [D loss: 0.003(R -0.230, F 0.236)] [G loss: -0.204]\n",
      "Epoch 936 -- [D loss: 0.001(R -0.238, F 0.240)] [G loss: -0.199]\n",
      "Epoch 937 -- [D loss: -0.009(R -0.238, F 0.221)] [G loss: -0.201]\n",
      "Epoch 938 -- [D loss: -0.031(R -0.264, F 0.203)] [G loss: -0.218]\n",
      "Epoch 939 -- [D loss: -0.028(R -0.280, F 0.223)] [G loss: -0.238]\n",
      "Epoch 940 -- [D loss: -0.013(R -0.279, F 0.253)] [G loss: -0.251]\n",
      "Epoch 941 -- [D loss: 0.004(R -0.293, F 0.302)] [G loss: -0.256]\n",
      "Epoch 942 -- [D loss: 0.015(R -0.278, F 0.307)] [G loss: -0.255]\n",
      "Epoch 943 -- [D loss: -0.008(R -0.279, F 0.263)] [G loss: -0.252]\n",
      "Epoch 944 -- [D loss: -0.011(R -0.278, F 0.257)] [G loss: -0.246]\n",
      "Epoch 945 -- [D loss: -0.005(R -0.260, F 0.250)] [G loss: -0.236]\n",
      "Epoch 946 -- [D loss: -0.003(R -0.263, F 0.257)] [G loss: -0.216]\n",
      "Epoch 947 -- [D loss: 0.007(R -0.245, F 0.258)] [G loss: -0.202]\n",
      "Epoch 948 -- [D loss: -0.026(R -0.255, F 0.203)] [G loss: -0.191]\n",
      "Epoch 949 -- [D loss: -0.059(R -0.279, F 0.160)] [G loss: -0.219]\n",
      "Epoch 950 -- [D loss: -0.061(R -0.294, F 0.172)] [G loss: -0.281]\n",
      "Epoch 951 -- [D loss: -0.014(R -0.327, F 0.300)] [G loss: -0.323]\n",
      "Epoch 952 -- [D loss: 0.029(R -0.323, F 0.380)] [G loss: -0.327]\n",
      "Epoch 953 -- [D loss: 0.028(R -0.297, F 0.353)] [G loss: -0.297]\n",
      "Epoch 954 -- [D loss: 0.024(R -0.289, F 0.337)] [G loss: -0.275]\n",
      "Epoch 955 -- [D loss: 0.008(R -0.275, F 0.290)] [G loss: -0.265]\n",
      "Epoch 956 -- [D loss: 0.001(R -0.272, F 0.274)] [G loss: -0.250]\n",
      "Epoch 957 -- [D loss: -0.006(R -0.272, F 0.260)] [G loss: -0.231]\n",
      "Epoch 958 -- [D loss: -0.019(R -0.272, F 0.234)] [G loss: -0.222]\n",
      "Epoch 959 -- [D loss: -0.043(R -0.283, F 0.197)] [G loss: -0.226]\n",
      "Epoch 960 -- [D loss: -0.040(R -0.297, F 0.217)] [G loss: -0.229]\n",
      "Epoch 961 -- [D loss: -0.024(R -0.283, F 0.234)] [G loss: -0.240]\n",
      "Epoch 962 -- [D loss: -0.009(R -0.296, F 0.277)] [G loss: -0.249]\n",
      "Epoch 963 -- [D loss: 0.003(R -0.290, F 0.296)] [G loss: -0.249]\n",
      "Epoch 964 -- [D loss: -0.002(R -0.289, F 0.285)] [G loss: -0.255]\n",
      "Epoch 965 -- [D loss: -0.012(R -0.299, F 0.274)] [G loss: -0.282]\n",
      "Epoch 966 -- [D loss: -0.024(R -0.320, F 0.273)] [G loss: -0.300]\n",
      "Epoch 967 -- [D loss: -0.020(R -0.323, F 0.284)] [G loss: -0.329]\n",
      "Epoch 968 -- [D loss: -0.001(R -0.324, F 0.321)] [G loss: -0.336]\n",
      "Epoch 969 -- [D loss: 0.007(R -0.323, F 0.338)] [G loss: -0.324]\n",
      "Epoch 970 -- [D loss: 0.021(R -0.325, F 0.367)] [G loss: -0.298]\n",
      "Epoch 971 -- [D loss: 0.020(R -0.294, F 0.333)] [G loss: -0.260]\n",
      "Epoch 972 -- [D loss: 0.001(R -0.274, F 0.277)] [G loss: -0.235]\n",
      "Epoch 973 -- [D loss: -0.013(R -0.263, F 0.237)] [G loss: -0.220]\n",
      "Epoch 974 -- [D loss: -0.015(R -0.255, F 0.225)] [G loss: -0.220]\n",
      "Epoch 975 -- [D loss: -0.009(R -0.249, F 0.230)] [G loss: -0.229]\n",
      "Epoch 976 -- [D loss: -0.003(R -0.257, F 0.251)] [G loss: -0.222]\n",
      "Epoch 977 -- [D loss: 0.008(R -0.238, F 0.253)] [G loss: -0.216]\n",
      "Epoch 978 -- [D loss: -0.006(R -0.241, F 0.229)] [G loss: -0.210]\n",
      "Epoch 979 -- [D loss: -0.012(R -0.242, F 0.218)] [G loss: -0.205]\n",
      "Epoch 980 -- [D loss: -0.016(R -0.249, F 0.217)] [G loss: -0.196]\n",
      "Epoch 981 -- [D loss: -0.010(R -0.224, F 0.204)] [G loss: -0.192]\n",
      "Epoch 982 -- [D loss: -0.017(R -0.239, F 0.205)] [G loss: -0.187]\n",
      "Epoch 983 -- [D loss: -0.017(R -0.243, F 0.210)] [G loss: -0.202]\n",
      "Epoch 984 -- [D loss: -0.007(R -0.237, F 0.222)] [G loss: -0.213]\n",
      "Epoch 985 -- [D loss: 0.010(R -0.223, F 0.242)] [G loss: -0.204]\n",
      "Epoch 986 -- [D loss: -0.001(R -0.219, F 0.217)] [G loss: -0.188]\n",
      "Epoch 987 -- [D loss: -0.018(R -0.218, F 0.183)] [G loss: -0.174]\n",
      "Epoch 988 -- [D loss: -0.022(R -0.211, F 0.166)] [G loss: -0.171]\n",
      "Epoch 989 -- [D loss: -0.046(R -0.238, F 0.145)] [G loss: -0.183]\n",
      "Epoch 990 -- [D loss: -0.036(R -0.232, F 0.161)] [G loss: -0.198]\n",
      "Epoch 991 -- [D loss: -0.019(R -0.252, F 0.213)] [G loss: -0.216]\n",
      "Epoch 992 -- [D loss: 0.004(R -0.242, F 0.249)] [G loss: -0.227]\n",
      "Epoch 993 -- [D loss: 0.007(R -0.246, F 0.260)] [G loss: -0.213]\n",
      "Epoch 994 -- [D loss: 0.006(R -0.235, F 0.247)] [G loss: -0.202]\n",
      "Epoch 995 -- [D loss: 0.002(R -0.230, F 0.234)] [G loss: -0.200]\n",
      "Epoch 996 -- [D loss: -0.009(R -0.242, F 0.223)] [G loss: -0.195]\n",
      "Epoch 997 -- [D loss: -0.011(R -0.237, F 0.216)] [G loss: -0.193]\n",
      "Epoch 998 -- [D loss: -0.008(R -0.227, F 0.211)] [G loss: -0.194]\n",
      "Epoch 999 -- [D loss: -0.018(R -0.245, F 0.209)] [G loss: -0.197]\n",
      "Epoch 1000 -- [D loss: -0.020(R -0.243, F 0.204)] [G loss: -0.194]\n",
      "INFO:tensorflow:Assets written to: ram://4002263b-9e98-4b35-b4da-4ea7c15f6450/assets\n",
      "INFO:tensorflow:Assets written to: ram://9c961e7c-ee1d-49b5-859e-48fa40d386fe/assets\n",
      "INFO:tensorflow:Assets written to: ram://74b9f0a1-e7b5-45d2-bd48-6dfc4c47c4db/assets\n",
      "Epoch 1001 -- [D loss: 0.002(R -0.205, F 0.210)] [G loss: -0.192]\n",
      "Epoch 1002 -- [D loss: 0.001(R -0.207, F 0.210)] [G loss: -0.189]\n",
      "Epoch 1003 -- [D loss: -0.002(R -0.213, F 0.208)] [G loss: -0.184]\n",
      "Epoch 1004 -- [D loss: 0.001(R -0.198, F 0.200)] [G loss: -0.179]\n",
      "Epoch 1005 -- [D loss: -0.002(R -0.199, F 0.196)] [G loss: -0.174]\n",
      "Epoch 1006 -- [D loss: -0.012(R -0.207, F 0.182)] [G loss: -0.176]\n",
      "Epoch 1007 -- [D loss: -0.013(R -0.218, F 0.192)] [G loss: -0.175]\n",
      "Epoch 1008 -- [D loss: -0.005(R -0.207, F 0.197)] [G loss: -0.168]\n",
      "Epoch 1009 -- [D loss: -0.007(R -0.202, F 0.188)] [G loss: -0.161]\n",
      "Epoch 1010 -- [D loss: -0.009(R -0.203, F 0.185)] [G loss: -0.161]\n",
      "Epoch 1011 -- [D loss: -0.013(R -0.213, F 0.186)] [G loss: -0.157]\n",
      "Epoch 1012 -- [D loss: -0.020(R -0.222, F 0.182)] [G loss: -0.159]\n",
      "Epoch 1013 -- [D loss: -0.010(R -0.208, F 0.188)] [G loss: -0.177]\n",
      "Epoch 1014 -- [D loss: -0.008(R -0.223, F 0.208)] [G loss: -0.182]\n",
      "Epoch 1015 -- [D loss: -0.007(R -0.219, F 0.206)] [G loss: -0.191]\n",
      "Epoch 1016 -- [D loss: -0.012(R -0.227, F 0.204)] [G loss: -0.195]\n",
      "Epoch 1017 -- [D loss: -0.000(R -0.223, F 0.222)] [G loss: -0.202]\n",
      "Epoch 1018 -- [D loss: -0.002(R -0.232, F 0.229)] [G loss: -0.203]\n",
      "Epoch 1019 -- [D loss: -0.004(R -0.232, F 0.223)] [G loss: -0.200]\n",
      "Epoch 1020 -- [D loss: -0.000(R -0.233, F 0.233)] [G loss: -0.204]\n",
      "Epoch 1021 -- [D loss: 0.003(R -0.227, F 0.233)] [G loss: -0.202]\n",
      "Epoch 1022 -- [D loss: -0.004(R -0.236, F 0.228)] [G loss: -0.199]\n",
      "Epoch 1023 -- [D loss: -0.006(R -0.229, F 0.217)] [G loss: -0.190]\n",
      "Epoch 1024 -- [D loss: -0.014(R -0.234, F 0.207)] [G loss: -0.179]\n",
      "Epoch 1025 -- [D loss: -0.024(R -0.241, F 0.193)] [G loss: -0.174]\n",
      "Epoch 1026 -- [D loss: -0.013(R -0.229, F 0.202)] [G loss: -0.176]\n",
      "Epoch 1027 -- [D loss: -0.019(R -0.240, F 0.202)] [G loss: -0.187]\n",
      "Epoch 1028 -- [D loss: -0.014(R -0.235, F 0.208)] [G loss: -0.191]\n",
      "Epoch 1029 -- [D loss: -0.008(R -0.224, F 0.207)] [G loss: -0.190]\n",
      "Epoch 1030 -- [D loss: -0.001(R -0.218, F 0.215)] [G loss: -0.192]\n",
      "Epoch 1031 -- [D loss: -0.003(R -0.207, F 0.201)] [G loss: -0.193]\n",
      "Epoch 1032 -- [D loss: 0.000(R -0.201, F 0.201)] [G loss: -0.186]\n",
      "Epoch 1033 -- [D loss: -0.014(R -0.210, F 0.181)] [G loss: -0.184]\n",
      "Epoch 1034 -- [D loss: 0.004(R -0.193, F 0.201)] [G loss: -0.165]\n",
      "Epoch 1035 -- [D loss: -0.003(R -0.191, F 0.185)] [G loss: -0.148]\n",
      "Epoch 1036 -- [D loss: -0.010(R -0.186, F 0.167)] [G loss: -0.138]\n",
      "Epoch 1037 -- [D loss: -0.014(R -0.192, F 0.164)] [G loss: -0.137]\n",
      "Epoch 1038 -- [D loss: -0.013(R -0.190, F 0.165)] [G loss: -0.141]\n",
      "Epoch 1039 -- [D loss: -0.009(R -0.187, F 0.170)] [G loss: -0.147]\n",
      "Epoch 1040 -- [D loss: -0.010(R -0.192, F 0.172)] [G loss: -0.147]\n",
      "Epoch 1041 -- [D loss: -0.008(R -0.192, F 0.176)] [G loss: -0.151]\n",
      "Epoch 1042 -- [D loss: -0.005(R -0.191, F 0.182)] [G loss: -0.157]\n",
      "Epoch 1043 -- [D loss: -0.007(R -0.195, F 0.181)] [G loss: -0.164]\n",
      "Epoch 1044 -- [D loss: -0.009(R -0.204, F 0.186)] [G loss: -0.167]\n",
      "Epoch 1045 -- [D loss: -0.007(R -0.199, F 0.185)] [G loss: -0.169]\n",
      "Epoch 1046 -- [D loss: -0.004(R -0.206, F 0.197)] [G loss: -0.169]\n",
      "Epoch 1047 -- [D loss: -0.004(R -0.216, F 0.207)] [G loss: -0.179]\n",
      "Epoch 1048 -- [D loss: -0.007(R -0.221, F 0.207)] [G loss: -0.185]\n",
      "Epoch 1049 -- [D loss: -0.010(R -0.225, F 0.206)] [G loss: -0.184]\n",
      "Epoch 1050 -- [D loss: -0.006(R -0.223, F 0.211)] [G loss: -0.185]\n",
      "Epoch 1051 -- [D loss: -0.007(R -0.228, F 0.214)] [G loss: -0.187]\n",
      "Epoch 1052 -- [D loss: -0.012(R -0.238, F 0.214)] [G loss: -0.192]\n",
      "Epoch 1053 -- [D loss: -0.006(R -0.235, F 0.223)] [G loss: -0.193]\n",
      "Epoch 1054 -- [D loss: -0.000(R -0.225, F 0.224)] [G loss: -0.189]\n",
      "Epoch 1055 -- [D loss: -0.005(R -0.227, F 0.216)] [G loss: -0.187]\n",
      "Epoch 1056 -- [D loss: -0.003(R -0.223, F 0.216)] [G loss: -0.190]\n",
      "Epoch 1057 -- [D loss: -0.003(R -0.219, F 0.213)] [G loss: -0.189]\n",
      "Epoch 1058 -- [D loss: -0.005(R -0.220, F 0.209)] [G loss: -0.188]\n",
      "Epoch 1059 -- [D loss: -0.004(R -0.215, F 0.207)] [G loss: -0.185]\n",
      "Epoch 1060 -- [D loss: -0.005(R -0.214, F 0.204)] [G loss: -0.180]\n",
      "Epoch 1061 -- [D loss: -0.008(R -0.217, F 0.201)] [G loss: -0.178]\n",
      "Epoch 1062 -- [D loss: -0.009(R -0.213, F 0.196)] [G loss: -0.179]\n",
      "Epoch 1063 -- [D loss: -0.010(R -0.215, F 0.195)] [G loss: -0.181]\n",
      "Epoch 1064 -- [D loss: -0.007(R -0.213, F 0.199)] [G loss: -0.181]\n",
      "Epoch 1065 -- [D loss: -0.008(R -0.220, F 0.203)] [G loss: -0.176]\n",
      "Epoch 1066 -- [D loss: -0.006(R -0.218, F 0.205)] [G loss: -0.183]\n",
      "Epoch 1067 -- [D loss: -0.008(R -0.225, F 0.209)] [G loss: -0.182]\n",
      "Epoch 1068 -- [D loss: -0.005(R -0.221, F 0.210)] [G loss: -0.184]\n",
      "Epoch 1069 -- [D loss: -0.009(R -0.225, F 0.207)] [G loss: -0.183]\n",
      "Epoch 1070 -- [D loss: -0.005(R -0.225, F 0.215)] [G loss: -0.185]\n",
      "Epoch 1071 -- [D loss: -0.008(R -0.225, F 0.209)] [G loss: -0.187]\n",
      "Epoch 1072 -- [D loss: -0.006(R -0.223, F 0.211)] [G loss: -0.183]\n",
      "Epoch 1073 -- [D loss: -0.008(R -0.224, F 0.208)] [G loss: -0.180]\n",
      "Epoch 1074 -- [D loss: -0.004(R -0.213, F 0.206)] [G loss: -0.180]\n",
      "Epoch 1075 -- [D loss: -0.008(R -0.223, F 0.207)] [G loss: -0.178]\n",
      "Epoch 1076 -- [D loss: -0.005(R -0.213, F 0.203)] [G loss: -0.181]\n",
      "Epoch 1077 -- [D loss: -0.008(R -0.221, F 0.205)] [G loss: -0.183]\n",
      "Epoch 1078 -- [D loss: -0.004(R -0.210, F 0.202)] [G loss: -0.182]\n",
      "Epoch 1079 -- [D loss: -0.003(R -0.209, F 0.203)] [G loss: -0.177]\n",
      "Epoch 1080 -- [D loss: -0.008(R -0.208, F 0.192)] [G loss: -0.171]\n",
      "Epoch 1081 -- [D loss: -0.013(R -0.214, F 0.188)] [G loss: -0.167]\n",
      "Epoch 1082 -- [D loss: -0.005(R -0.211, F 0.201)] [G loss: -0.173]\n",
      "Epoch 1083 -- [D loss: -0.006(R -0.205, F 0.193)] [G loss: -0.169]\n",
      "Epoch 1084 -- [D loss: -0.008(R -0.206, F 0.189)] [G loss: -0.169]\n",
      "Epoch 1085 -- [D loss: -0.013(R -0.211, F 0.186)] [G loss: -0.167]\n",
      "Epoch 1086 -- [D loss: -0.016(R -0.211, F 0.180)] [G loss: -0.175]\n",
      "Epoch 1087 -- [D loss: -0.002(R -0.212, F 0.207)] [G loss: -0.178]\n",
      "Epoch 1088 -- [D loss: -0.001(R -0.211, F 0.208)] [G loss: -0.183]\n",
      "Epoch 1089 -- [D loss: -0.007(R -0.224, F 0.210)] [G loss: -0.185]\n",
      "Epoch 1090 -- [D loss: -0.005(R -0.218, F 0.209)] [G loss: -0.189]\n",
      "Epoch 1091 -- [D loss: -0.008(R -0.222, F 0.207)] [G loss: -0.184]\n",
      "Epoch 1092 -- [D loss: -0.005(R -0.219, F 0.210)] [G loss: -0.188]\n",
      "Epoch 1093 -- [D loss: -0.008(R -0.224, F 0.208)] [G loss: -0.183]\n",
      "Epoch 1094 -- [D loss: -0.010(R -0.225, F 0.205)] [G loss: -0.182]\n",
      "Epoch 1095 -- [D loss: -0.011(R -0.226, F 0.203)] [G loss: -0.183]\n",
      "Epoch 1096 -- [D loss: -0.005(R -0.226, F 0.216)] [G loss: -0.185]\n",
      "Epoch 1097 -- [D loss: -0.011(R -0.219, F 0.197)] [G loss: -0.184]\n",
      "Epoch 1098 -- [D loss: -0.006(R -0.211, F 0.199)] [G loss: -0.184]\n",
      "Epoch 1099 -- [D loss: -0.001(R -0.205, F 0.202)] [G loss: -0.176]\n",
      "Epoch 1100 -- [D loss: -0.008(R -0.211, F 0.194)] [G loss: -0.171]\n",
      "INFO:tensorflow:Assets written to: ram://c3c50781-33ff-47ec-b378-97ec089403fa/assets\n",
      "INFO:tensorflow:Assets written to: ram://ed639116-b591-4254-a0fc-a436023ef4a6/assets\n",
      "INFO:tensorflow:Assets written to: ram://e1a536e2-1866-42d1-9c4a-ecf7b87eaa62/assets\n",
      "Epoch 1101 -- [D loss: -0.004(R -0.200, F 0.192)] [G loss: -0.167]\n",
      "Epoch 1102 -- [D loss: -0.004(R -0.198, F 0.190)] [G loss: -0.162]\n",
      "Epoch 1103 -- [D loss: -0.011(R -0.200, F 0.178)] [G loss: -0.157]\n",
      "Epoch 1104 -- [D loss: -0.010(R -0.196, F 0.177)] [G loss: -0.154]\n",
      "Epoch 1105 -- [D loss: -0.007(R -0.200, F 0.186)] [G loss: -0.157]\n",
      "Epoch 1106 -- [D loss: -0.011(R -0.209, F 0.187)] [G loss: -0.169]\n",
      "Epoch 1107 -- [D loss: -0.001(R -0.207, F 0.204)] [G loss: -0.168]\n",
      "Epoch 1108 -- [D loss: -0.011(R -0.212, F 0.191)] [G loss: -0.173]\n",
      "Epoch 1109 -- [D loss: -0.004(R -0.211, F 0.202)] [G loss: -0.179]\n",
      "Epoch 1110 -- [D loss: -0.002(R -0.208, F 0.205)] [G loss: -0.180]\n",
      "Epoch 1111 -- [D loss: -0.008(R -0.217, F 0.200)] [G loss: -0.176]\n",
      "Epoch 1112 -- [D loss: -0.009(R -0.219, F 0.201)] [G loss: -0.173]\n",
      "Epoch 1113 -- [D loss: -0.008(R -0.218, F 0.202)] [G loss: -0.179]\n",
      "Epoch 1114 -- [D loss: -0.005(R -0.221, F 0.211)] [G loss: -0.177]\n",
      "Epoch 1115 -- [D loss: -0.007(R -0.218, F 0.203)] [G loss: -0.178]\n",
      "Epoch 1116 -- [D loss: -0.002(R -0.211, F 0.206)] [G loss: -0.182]\n",
      "Epoch 1117 -- [D loss: -0.001(R -0.213, F 0.211)] [G loss: -0.184]\n",
      "Epoch 1118 -- [D loss: -0.004(R -0.213, F 0.206)] [G loss: -0.185]\n",
      "Epoch 1119 -- [D loss: -0.005(R -0.205, F 0.195)] [G loss: -0.179]\n",
      "Epoch 1120 -- [D loss: -0.005(R -0.205, F 0.195)] [G loss: -0.172]\n",
      "Epoch 1121 -- [D loss: -0.013(R -0.205, F 0.178)] [G loss: -0.160]\n",
      "Epoch 1122 -- [D loss: -0.009(R -0.203, F 0.186)] [G loss: -0.162]\n",
      "Epoch 1123 -- [D loss: -0.000(R -0.193, F 0.193)] [G loss: -0.163]\n",
      "Epoch 1124 -- [D loss: -0.011(R -0.198, F 0.175)] [G loss: -0.157]\n",
      "Epoch 1125 -- [D loss: -0.009(R -0.194, F 0.177)] [G loss: -0.155]\n",
      "Epoch 1126 -- [D loss: -0.014(R -0.194, F 0.166)] [G loss: -0.155]\n",
      "Epoch 1127 -- [D loss: -0.009(R -0.196, F 0.178)] [G loss: -0.159]\n",
      "Epoch 1128 -- [D loss: -0.007(R -0.197, F 0.183)] [G loss: -0.163]\n",
      "Epoch 1129 -- [D loss: -0.005(R -0.194, F 0.184)] [G loss: -0.162]\n",
      "Epoch 1130 -- [D loss: -0.008(R -0.198, F 0.181)] [G loss: -0.164]\n",
      "Epoch 1131 -- [D loss: -0.005(R -0.199, F 0.189)] [G loss: -0.173]\n",
      "Epoch 1132 -- [D loss: -0.008(R -0.213, F 0.198)] [G loss: -0.176]\n",
      "Epoch 1133 -- [D loss: -0.013(R -0.216, F 0.190)] [G loss: -0.173]\n",
      "Epoch 1134 -- [D loss: -0.016(R -0.216, F 0.185)] [G loss: -0.173]\n",
      "Epoch 1135 -- [D loss: -0.011(R -0.211, F 0.189)] [G loss: -0.180]\n",
      "Epoch 1136 -- [D loss: -0.002(R -0.215, F 0.212)] [G loss: -0.181]\n",
      "Epoch 1137 -- [D loss: -0.006(R -0.213, F 0.202)] [G loss: -0.183]\n",
      "Epoch 1138 -- [D loss: -0.004(R -0.205, F 0.196)] [G loss: -0.175]\n",
      "Epoch 1139 -- [D loss: -0.007(R -0.204, F 0.190)] [G loss: -0.167]\n",
      "Epoch 1140 -- [D loss: -0.009(R -0.201, F 0.183)] [G loss: -0.166]\n",
      "Epoch 1141 -- [D loss: -0.005(R -0.187, F 0.176)] [G loss: -0.157]\n",
      "Epoch 1142 -- [D loss: -0.007(R -0.183, F 0.170)] [G loss: -0.148]\n",
      "Epoch 1143 -- [D loss: -0.010(R -0.189, F 0.170)] [G loss: -0.149]\n",
      "Epoch 1144 -- [D loss: -0.014(R -0.193, F 0.165)] [G loss: -0.137]\n",
      "Epoch 1145 -- [D loss: -0.007(R -0.180, F 0.167)] [G loss: -0.150]\n",
      "Epoch 1146 -- [D loss: -0.008(R -0.188, F 0.172)] [G loss: -0.154]\n",
      "Epoch 1147 -- [D loss: -0.009(R -0.193, F 0.175)] [G loss: -0.154]\n",
      "Epoch 1148 -- [D loss: -0.010(R -0.199, F 0.178)] [G loss: -0.160]\n",
      "Epoch 1149 -- [D loss: -0.006(R -0.200, F 0.188)] [G loss: -0.169]\n",
      "Epoch 1150 -- [D loss: -0.004(R -0.202, F 0.195)] [G loss: -0.175]\n",
      "Epoch 1151 -- [D loss: -0.009(R -0.214, F 0.197)] [G loss: -0.174]\n",
      "Epoch 1152 -- [D loss: -0.013(R -0.224, F 0.199)] [G loss: -0.180]\n",
      "Epoch 1153 -- [D loss: -0.007(R -0.216, F 0.203)] [G loss: -0.178]\n",
      "Epoch 1154 -- [D loss: -0.007(R -0.217, F 0.203)] [G loss: -0.180]\n",
      "Epoch 1155 -- [D loss: -0.008(R -0.217, F 0.201)] [G loss: -0.176]\n",
      "Epoch 1156 -- [D loss: -0.006(R -0.208, F 0.196)] [G loss: -0.169]\n",
      "Epoch 1157 -- [D loss: -0.008(R -0.212, F 0.196)] [G loss: -0.170]\n",
      "Epoch 1158 -- [D loss: -0.009(R -0.209, F 0.190)] [G loss: -0.169]\n",
      "Epoch 1159 -- [D loss: -0.006(R -0.196, F 0.185)] [G loss: -0.165]\n",
      "Epoch 1160 -- [D loss: -0.007(R -0.191, F 0.176)] [G loss: -0.161]\n",
      "Epoch 1161 -- [D loss: -0.011(R -0.200, F 0.178)] [G loss: -0.156]\n",
      "Epoch 1162 -- [D loss: -0.011(R -0.191, F 0.169)] [G loss: -0.147]\n",
      "Epoch 1163 -- [D loss: -0.011(R -0.187, F 0.165)] [G loss: -0.144]\n",
      "Epoch 1164 -- [D loss: -0.012(R -0.188, F 0.165)] [G loss: -0.143]\n",
      "Epoch 1165 -- [D loss: -0.008(R -0.188, F 0.172)] [G loss: -0.148]\n",
      "Epoch 1166 -- [D loss: -0.009(R -0.188, F 0.171)] [G loss: -0.151]\n",
      "Epoch 1167 -- [D loss: -0.008(R -0.192, F 0.176)] [G loss: -0.153]\n",
      "Epoch 1168 -- [D loss: -0.007(R -0.197, F 0.182)] [G loss: -0.158]\n",
      "Epoch 1169 -- [D loss: -0.008(R -0.198, F 0.183)] [G loss: -0.160]\n",
      "Epoch 1170 -- [D loss: -0.009(R -0.199, F 0.181)] [G loss: -0.166]\n",
      "Epoch 1171 -- [D loss: -0.014(R -0.206, F 0.179)] [G loss: -0.161]\n",
      "Epoch 1172 -- [D loss: -0.009(R -0.210, F 0.192)] [G loss: -0.167]\n",
      "Epoch 1173 -- [D loss: -0.012(R -0.214, F 0.190)] [G loss: -0.170]\n",
      "Epoch 1174 -- [D loss: -0.009(R -0.212, F 0.194)] [G loss: -0.172]\n",
      "Epoch 1175 -- [D loss: -0.005(R -0.209, F 0.200)] [G loss: -0.172]\n",
      "Epoch 1176 -- [D loss: -0.007(R -0.212, F 0.197)] [G loss: -0.175]\n",
      "Epoch 1177 -- [D loss: -0.012(R -0.211, F 0.186)] [G loss: -0.172]\n",
      "Epoch 1178 -- [D loss: -0.007(R -0.201, F 0.187)] [G loss: -0.156]\n",
      "Epoch 1179 -- [D loss: -0.012(R -0.193, F 0.169)] [G loss: -0.154]\n",
      "Epoch 1180 -- [D loss: -0.009(R -0.199, F 0.182)] [G loss: -0.155]\n",
      "Epoch 1181 -- [D loss: -0.008(R -0.188, F 0.172)] [G loss: -0.144]\n",
      "Epoch 1182 -- [D loss: -0.008(R -0.182, F 0.165)] [G loss: -0.141]\n",
      "Epoch 1183 -- [D loss: -0.010(R -0.182, F 0.162)] [G loss: -0.137]\n",
      "Epoch 1184 -- [D loss: -0.008(R -0.176, F 0.160)] [G loss: -0.134]\n",
      "Epoch 1185 -- [D loss: -0.010(R -0.173, F 0.153)] [G loss: -0.135]\n",
      "Epoch 1186 -- [D loss: -0.007(R -0.175, F 0.161)] [G loss: -0.139]\n",
      "Epoch 1187 -- [D loss: -0.005(R -0.178, F 0.168)] [G loss: -0.145]\n",
      "Epoch 1188 -- [D loss: -0.009(R -0.182, F 0.163)] [G loss: -0.143]\n",
      "Epoch 1189 -- [D loss: -0.007(R -0.184, F 0.170)] [G loss: -0.145]\n",
      "Epoch 1190 -- [D loss: -0.012(R -0.193, F 0.169)] [G loss: -0.150]\n",
      "Epoch 1191 -- [D loss: -0.009(R -0.193, F 0.175)] [G loss: -0.156]\n",
      "Epoch 1192 -- [D loss: -0.011(R -0.201, F 0.180)] [G loss: -0.154]\n",
      "Epoch 1193 -- [D loss: -0.007(R -0.193, F 0.180)] [G loss: -0.154]\n",
      "Epoch 1194 -- [D loss: -0.008(R -0.196, F 0.181)] [G loss: -0.161]\n",
      "Epoch 1195 -- [D loss: -0.010(R -0.196, F 0.176)] [G loss: -0.169]\n",
      "Epoch 1196 -- [D loss: -0.005(R -0.209, F 0.198)] [G loss: -0.168]\n",
      "Epoch 1197 -- [D loss: -0.004(R -0.193, F 0.186)] [G loss: -0.158]\n",
      "Epoch 1198 -- [D loss: -0.014(R -0.200, F 0.172)] [G loss: -0.149]\n",
      "Epoch 1199 -- [D loss: -0.015(R -0.199, F 0.169)] [G loss: -0.148]\n",
      "Epoch 1200 -- [D loss: -0.016(R -0.205, F 0.173)] [G loss: -0.153]\n",
      "INFO:tensorflow:Assets written to: ram://a96ad96b-744b-499a-8658-31c2b233d656/assets\n",
      "INFO:tensorflow:Assets written to: ram://0ba4554a-4ee6-4081-b303-131d52d52616/assets\n",
      "INFO:tensorflow:Assets written to: ram://11a8318c-f14c-4c15-8572-3e2eb7893526/assets\n",
      "Epoch 1201 -- [D loss: -0.006(R -0.202, F 0.190)] [G loss: -0.159]\n",
      "Epoch 1202 -- [D loss: -0.010(R -0.210, F 0.189)] [G loss: -0.160]\n",
      "Epoch 1203 -- [D loss: -0.007(R -0.202, F 0.189)] [G loss: -0.160]\n",
      "Epoch 1204 -- [D loss: -0.014(R -0.203, F 0.174)] [G loss: -0.154]\n",
      "Epoch 1205 -- [D loss: -0.012(R -0.202, F 0.178)] [G loss: -0.157]\n",
      "Epoch 1206 -- [D loss: -0.010(R -0.200, F 0.181)] [G loss: -0.162]\n",
      "Epoch 1207 -- [D loss: -0.015(R -0.201, F 0.171)] [G loss: -0.150]\n",
      "Epoch 1208 -- [D loss: -0.010(R -0.188, F 0.168)] [G loss: -0.147]\n",
      "Epoch 1209 -- [D loss: -0.010(R -0.189, F 0.169)] [G loss: -0.141]\n",
      "Epoch 1210 -- [D loss: -0.023(R -0.197, F 0.150)] [G loss: -0.139]\n",
      "Epoch 1211 -- [D loss: -0.017(R -0.196, F 0.162)] [G loss: -0.149]\n",
      "Epoch 1212 -- [D loss: -0.010(R -0.198, F 0.177)] [G loss: -0.152]\n",
      "Epoch 1213 -- [D loss: -0.015(R -0.200, F 0.171)] [G loss: -0.143]\n",
      "Epoch 1214 -- [D loss: -0.024(R -0.203, F 0.156)] [G loss: -0.146]\n",
      "Epoch 1215 -- [D loss: -0.013(R -0.192, F 0.166)] [G loss: -0.152]\n",
      "Epoch 1216 -- [D loss: -0.008(R -0.184, F 0.167)] [G loss: -0.137]\n",
      "Epoch 1217 -- [D loss: -0.013(R -0.178, F 0.153)] [G loss: -0.129]\n",
      "Epoch 1218 -- [D loss: -0.016(R -0.172, F 0.140)] [G loss: -0.132]\n",
      "Epoch 1219 -- [D loss: -0.009(R -0.174, F 0.155)] [G loss: -0.138]\n",
      "Epoch 1220 -- [D loss: -0.008(R -0.179, F 0.162)] [G loss: -0.138]\n",
      "Epoch 1221 -- [D loss: -0.012(R -0.188, F 0.163)] [G loss: -0.139]\n",
      "Epoch 1222 -- [D loss: -0.013(R -0.187, F 0.162)] [G loss: -0.138]\n",
      "Epoch 1223 -- [D loss: -0.008(R -0.186, F 0.169)] [G loss: -0.146]\n",
      "Epoch 1224 -- [D loss: -0.015(R -0.196, F 0.166)] [G loss: -0.157]\n",
      "Epoch 1225 -- [D loss: -0.011(R -0.193, F 0.171)] [G loss: -0.162]\n",
      "Epoch 1226 -- [D loss: -0.004(R -0.182, F 0.174)] [G loss: -0.144]\n",
      "Epoch 1227 -- [D loss: -0.009(R -0.184, F 0.166)] [G loss: -0.141]\n",
      "Epoch 1228 -- [D loss: -0.009(R -0.177, F 0.160)] [G loss: -0.136]\n",
      "Epoch 1229 -- [D loss: -0.014(R -0.184, F 0.157)] [G loss: -0.139]\n",
      "Epoch 1230 -- [D loss: -0.012(R -0.186, F 0.162)] [G loss: -0.145]\n",
      "Epoch 1231 -- [D loss: -0.008(R -0.191, F 0.174)] [G loss: -0.148]\n",
      "Epoch 1232 -- [D loss: -0.008(R -0.192, F 0.175)] [G loss: -0.152]\n",
      "Epoch 1233 -- [D loss: -0.007(R -0.197, F 0.183)] [G loss: -0.157]\n",
      "Epoch 1234 -- [D loss: -0.006(R -0.200, F 0.187)] [G loss: -0.164]\n",
      "Epoch 1235 -- [D loss: -0.008(R -0.207, F 0.190)] [G loss: -0.160]\n",
      "Epoch 1236 -- [D loss: -0.008(R -0.198, F 0.182)] [G loss: -0.159]\n",
      "Epoch 1237 -- [D loss: -0.009(R -0.201, F 0.183)] [G loss: -0.157]\n",
      "Epoch 1238 -- [D loss: -0.011(R -0.205, F 0.183)] [G loss: -0.155]\n",
      "Epoch 1239 -- [D loss: -0.013(R -0.200, F 0.175)] [G loss: -0.151]\n",
      "Epoch 1240 -- [D loss: -0.010(R -0.200, F 0.180)] [G loss: -0.155]\n",
      "Epoch 1241 -- [D loss: -0.004(R -0.189, F 0.181)] [G loss: -0.152]\n",
      "Epoch 1242 -- [D loss: -0.005(R -0.186, F 0.175)] [G loss: -0.150]\n",
      "Epoch 1243 -- [D loss: -0.007(R -0.183, F 0.170)] [G loss: -0.147]\n",
      "Epoch 1244 -- [D loss: -0.007(R -0.187, F 0.172)] [G loss: -0.144]\n",
      "Epoch 1245 -- [D loss: -0.007(R -0.185, F 0.171)] [G loss: -0.144]\n",
      "Epoch 1246 -- [D loss: -0.014(R -0.190, F 0.162)] [G loss: -0.139]\n",
      "Epoch 1247 -- [D loss: -0.019(R -0.197, F 0.160)] [G loss: -0.145]\n",
      "Epoch 1248 -- [D loss: -0.009(R -0.185, F 0.168)] [G loss: -0.139]\n",
      "Epoch 1249 -- [D loss: -0.006(R -0.183, F 0.170)] [G loss: -0.143]\n",
      "Epoch 1250 -- [D loss: -0.009(R -0.179, F 0.160)] [G loss: -0.142]\n",
      "Epoch 1251 -- [D loss: -0.006(R -0.177, F 0.165)] [G loss: -0.143]\n",
      "Epoch 1252 -- [D loss: -0.006(R -0.176, F 0.165)] [G loss: -0.133]\n",
      "Epoch 1253 -- [D loss: -0.010(R -0.173, F 0.154)] [G loss: -0.124]\n",
      "Epoch 1254 -- [D loss: -0.009(R -0.172, F 0.154)] [G loss: -0.133]\n",
      "Epoch 1255 -- [D loss: -0.011(R -0.177, F 0.155)] [G loss: -0.129]\n",
      "Epoch 1256 -- [D loss: -0.012(R -0.178, F 0.155)] [G loss: -0.128]\n",
      "Epoch 1257 -- [D loss: -0.009(R -0.175, F 0.156)] [G loss: -0.129]\n",
      "Epoch 1258 -- [D loss: -0.010(R -0.182, F 0.162)] [G loss: -0.135]\n",
      "Epoch 1259 -- [D loss: -0.010(R -0.182, F 0.161)] [G loss: -0.133]\n",
      "Epoch 1260 -- [D loss: -0.008(R -0.176, F 0.160)] [G loss: -0.139]\n",
      "Epoch 1261 -- [D loss: -0.008(R -0.175, F 0.160)] [G loss: -0.134]\n",
      "Epoch 1262 -- [D loss: -0.007(R -0.176, F 0.162)] [G loss: -0.133]\n",
      "Epoch 1263 -- [D loss: -0.009(R -0.175, F 0.157)] [G loss: -0.138]\n",
      "Epoch 1264 -- [D loss: -0.006(R -0.173, F 0.161)] [G loss: -0.139]\n",
      "Epoch 1265 -- [D loss: -0.008(R -0.181, F 0.165)] [G loss: -0.140]\n",
      "Epoch 1266 -- [D loss: -0.008(R -0.187, F 0.170)] [G loss: -0.146]\n",
      "Epoch 1267 -- [D loss: -0.007(R -0.186, F 0.172)] [G loss: -0.152]\n",
      "Epoch 1268 -- [D loss: -0.007(R -0.185, F 0.170)] [G loss: -0.141]\n",
      "Epoch 1269 -- [D loss: -0.009(R -0.184, F 0.166)] [G loss: -0.137]\n",
      "Epoch 1270 -- [D loss: -0.014(R -0.189, F 0.162)] [G loss: -0.143]\n",
      "Epoch 1271 -- [D loss: -0.010(R -0.192, F 0.172)] [G loss: -0.146]\n",
      "Epoch 1272 -- [D loss: -0.017(R -0.196, F 0.162)] [G loss: -0.144]\n",
      "Epoch 1273 -- [D loss: -0.010(R -0.198, F 0.177)] [G loss: -0.149]\n",
      "Epoch 1274 -- [D loss: -0.009(R -0.201, F 0.184)] [G loss: -0.153]\n",
      "Epoch 1275 -- [D loss: -0.007(R -0.191, F 0.177)] [G loss: -0.144]\n",
      "Epoch 1276 -- [D loss: -0.012(R -0.189, F 0.165)] [G loss: -0.131]\n",
      "Epoch 1277 -- [D loss: -0.013(R -0.178, F 0.152)] [G loss: -0.130]\n",
      "Epoch 1278 -- [D loss: -0.011(R -0.174, F 0.152)] [G loss: -0.130]\n",
      "Epoch 1279 -- [D loss: -0.008(R -0.177, F 0.161)] [G loss: -0.138]\n",
      "Epoch 1280 -- [D loss: -0.016(R -0.186, F 0.153)] [G loss: -0.141]\n",
      "Epoch 1281 -- [D loss: -0.010(R -0.182, F 0.161)] [G loss: -0.137]\n",
      "Epoch 1282 -- [D loss: -0.009(R -0.178, F 0.160)] [G loss: -0.136]\n",
      "Epoch 1283 -- [D loss: -0.011(R -0.178, F 0.156)] [G loss: -0.134]\n",
      "Epoch 1284 -- [D loss: -0.008(R -0.174, F 0.157)] [G loss: -0.136]\n",
      "Epoch 1285 -- [D loss: -0.013(R -0.175, F 0.149)] [G loss: -0.134]\n",
      "Epoch 1286 -- [D loss: -0.012(R -0.173, F 0.149)] [G loss: -0.133]\n",
      "Epoch 1287 -- [D loss: -0.008(R -0.164, F 0.149)] [G loss: -0.122]\n",
      "Epoch 1288 -- [D loss: -0.009(R -0.160, F 0.142)] [G loss: -0.118]\n",
      "Epoch 1289 -- [D loss: -0.008(R -0.157, F 0.141)] [G loss: -0.113]\n",
      "Epoch 1290 -- [D loss: -0.016(R -0.160, F 0.128)] [G loss: -0.112]\n",
      "Epoch 1291 -- [D loss: -0.021(R -0.178, F 0.137)] [G loss: -0.124]\n",
      "Epoch 1292 -- [D loss: -0.006(R -0.169, F 0.156)] [G loss: -0.129]\n",
      "Epoch 1293 -- [D loss: -0.010(R -0.174, F 0.155)] [G loss: -0.134]\n",
      "Epoch 1294 -- [D loss: -0.014(R -0.179, F 0.150)] [G loss: -0.127]\n",
      "Epoch 1295 -- [D loss: -0.016(R -0.178, F 0.147)] [G loss: -0.130]\n",
      "Epoch 1296 -- [D loss: -0.020(R -0.182, F 0.141)] [G loss: -0.140]\n",
      "Epoch 1297 -- [D loss: -0.009(R -0.190, F 0.172)] [G loss: -0.140]\n",
      "Epoch 1298 -- [D loss: -0.012(R -0.184, F 0.161)] [G loss: -0.134]\n",
      "Epoch 1299 -- [D loss: -0.013(R -0.184, F 0.159)] [G loss: -0.139]\n",
      "Epoch 1300 -- [D loss: -0.010(R -0.188, F 0.169)] [G loss: -0.145]\n",
      "INFO:tensorflow:Assets written to: ram://aeec69ea-33df-4a1c-84c5-f9af3669085f/assets\n",
      "INFO:tensorflow:Assets written to: ram://2f06c01c-2ad1-4191-8707-988a57fffb44/assets\n",
      "INFO:tensorflow:Assets written to: ram://9ca9d3d7-1759-447c-89b9-b78ee893afc5/assets\n",
      "Epoch 1301 -- [D loss: -0.008(R -0.188, F 0.171)] [G loss: -0.150]\n",
      "Epoch 1302 -- [D loss: -0.014(R -0.188, F 0.160)] [G loss: -0.148]\n",
      "Epoch 1303 -- [D loss: -0.010(R -0.195, F 0.174)] [G loss: -0.152]\n",
      "Epoch 1304 -- [D loss: -0.008(R -0.193, F 0.176)] [G loss: -0.151]\n",
      "Epoch 1305 -- [D loss: -0.013(R -0.190, F 0.165)] [G loss: -0.146]\n",
      "Epoch 1306 -- [D loss: -0.009(R -0.185, F 0.166)] [G loss: -0.146]\n",
      "Epoch 1307 -- [D loss: -0.011(R -0.194, F 0.172)] [G loss: -0.145]\n",
      "Epoch 1308 -- [D loss: -0.008(R -0.184, F 0.168)] [G loss: -0.142]\n",
      "Epoch 1309 -- [D loss: -0.009(R -0.181, F 0.163)] [G loss: -0.139]\n",
      "Epoch 1310 -- [D loss: -0.011(R -0.180, F 0.158)] [G loss: -0.140]\n",
      "Epoch 1311 -- [D loss: -0.014(R -0.186, F 0.159)] [G loss: -0.141]\n",
      "Epoch 1312 -- [D loss: -0.008(R -0.185, F 0.169)] [G loss: -0.140]\n",
      "Epoch 1313 -- [D loss: -0.014(R -0.188, F 0.161)] [G loss: -0.142]\n",
      "Epoch 1314 -- [D loss: -0.015(R -0.185, F 0.154)] [G loss: -0.141]\n",
      "Epoch 1315 -- [D loss: -0.007(R -0.174, F 0.161)] [G loss: -0.131]\n",
      "Epoch 1316 -- [D loss: -0.012(R -0.178, F 0.154)] [G loss: -0.121]\n",
      "Epoch 1317 -- [D loss: -0.010(R -0.179, F 0.158)] [G loss: -0.127]\n",
      "Epoch 1318 -- [D loss: -0.011(R -0.173, F 0.150)] [G loss: -0.128]\n",
      "Epoch 1319 -- [D loss: -0.020(R -0.175, F 0.136)] [G loss: -0.135]\n",
      "Epoch 1320 -- [D loss: -0.009(R -0.171, F 0.153)] [G loss: -0.129]\n",
      "Epoch 1321 -- [D loss: -0.009(R -0.169, F 0.150)] [G loss: -0.121]\n",
      "Epoch 1322 -- [D loss: -0.010(R -0.160, F 0.139)] [G loss: -0.120]\n",
      "Epoch 1323 -- [D loss: -0.012(R -0.156, F 0.132)] [G loss: -0.111]\n",
      "Epoch 1324 -- [D loss: -0.008(R -0.150, F 0.135)] [G loss: -0.103]\n",
      "Epoch 1325 -- [D loss: -0.012(R -0.153, F 0.128)] [G loss: -0.108]\n",
      "Epoch 1326 -- [D loss: -0.014(R -0.158, F 0.130)] [G loss: -0.107]\n",
      "Epoch 1327 -- [D loss: -0.013(R -0.160, F 0.135)] [G loss: -0.112]\n",
      "Epoch 1328 -- [D loss: -0.008(R -0.157, F 0.141)] [G loss: -0.118]\n",
      "Epoch 1329 -- [D loss: -0.011(R -0.162, F 0.139)] [G loss: -0.118]\n",
      "Epoch 1330 -- [D loss: -0.014(R -0.162, F 0.134)] [G loss: -0.123]\n",
      "Epoch 1331 -- [D loss: -0.013(R -0.169, F 0.143)] [G loss: -0.128]\n",
      "Epoch 1332 -- [D loss: -0.008(R -0.171, F 0.156)] [G loss: -0.126]\n",
      "Epoch 1333 -- [D loss: -0.011(R -0.173, F 0.151)] [G loss: -0.128]\n",
      "Epoch 1334 -- [D loss: -0.011(R -0.186, F 0.163)] [G loss: -0.136]\n",
      "Epoch 1335 -- [D loss: -0.009(R -0.185, F 0.167)] [G loss: -0.141]\n",
      "Epoch 1336 -- [D loss: -0.008(R -0.193, F 0.178)] [G loss: -0.144]\n",
      "Epoch 1337 -- [D loss: -0.004(R -0.187, F 0.178)] [G loss: -0.146]\n",
      "Epoch 1338 -- [D loss: -0.009(R -0.193, F 0.175)] [G loss: -0.147]\n",
      "Epoch 1339 -- [D loss: -0.005(R -0.182, F 0.171)] [G loss: -0.144]\n",
      "Epoch 1340 -- [D loss: -0.006(R -0.183, F 0.171)] [G loss: -0.147]\n",
      "Epoch 1341 -- [D loss: -0.010(R -0.182, F 0.162)] [G loss: -0.138]\n",
      "Epoch 1342 -- [D loss: -0.007(R -0.181, F 0.167)] [G loss: -0.141]\n",
      "Epoch 1343 -- [D loss: -0.010(R -0.174, F 0.153)] [G loss: -0.135]\n",
      "Epoch 1344 -- [D loss: -0.008(R -0.180, F 0.164)] [G loss: -0.131]\n",
      "Epoch 1345 -- [D loss: -0.014(R -0.178, F 0.151)] [G loss: -0.132]\n",
      "Epoch 1346 -- [D loss: -0.011(R -0.187, F 0.165)] [G loss: -0.137]\n",
      "Epoch 1347 -- [D loss: -0.021(R -0.199, F 0.157)] [G loss: -0.139]\n",
      "Epoch 1348 -- [D loss: -0.009(R -0.188, F 0.170)] [G loss: -0.147]\n",
      "Epoch 1349 -- [D loss: -0.009(R -0.196, F 0.178)] [G loss: -0.144]\n",
      "Epoch 1350 -- [D loss: -0.008(R -0.185, F 0.168)] [G loss: -0.147]\n",
      "Epoch 1351 -- [D loss: -0.008(R -0.184, F 0.167)] [G loss: -0.151]\n",
      "Epoch 1352 -- [D loss: -0.006(R -0.190, F 0.177)] [G loss: -0.149]\n",
      "Epoch 1353 -- [D loss: -0.013(R -0.188, F 0.161)] [G loss: -0.148]\n",
      "Epoch 1354 -- [D loss: -0.011(R -0.188, F 0.166)] [G loss: -0.150]\n",
      "Epoch 1355 -- [D loss: -0.015(R -0.195, F 0.166)] [G loss: -0.148]\n",
      "Epoch 1356 -- [D loss: -0.004(R -0.177, F 0.170)] [G loss: -0.135]\n",
      "Epoch 1357 -- [D loss: -0.010(R -0.175, F 0.156)] [G loss: -0.125]\n",
      "Epoch 1358 -- [D loss: -0.010(R -0.165, F 0.145)] [G loss: -0.130]\n",
      "Epoch 1359 -- [D loss: -0.013(R -0.153, F 0.128)] [G loss: -0.103]\n",
      "Epoch 1360 -- [D loss: -0.010(R -0.146, F 0.125)] [G loss: -0.102]\n",
      "Epoch 1361 -- [D loss: -0.014(R -0.142, F 0.114)] [G loss: -0.092]\n",
      "Epoch 1362 -- [D loss: -0.011(R -0.137, F 0.115)] [G loss: -0.093]\n",
      "Epoch 1363 -- [D loss: -0.012(R -0.142, F 0.117)] [G loss: -0.092]\n",
      "Epoch 1364 -- [D loss: -0.012(R -0.143, F 0.120)] [G loss: -0.097]\n",
      "Epoch 1365 -- [D loss: -0.017(R -0.143, F 0.110)] [G loss: -0.093]\n",
      "Epoch 1366 -- [D loss: -0.019(R -0.154, F 0.117)] [G loss: -0.106]\n",
      "Epoch 1367 -- [D loss: -0.016(R -0.163, F 0.131)] [G loss: -0.114]\n",
      "Epoch 1368 -- [D loss: -0.008(R -0.168, F 0.152)] [G loss: -0.120]\n",
      "Epoch 1369 -- [D loss: -0.009(R -0.173, F 0.155)] [G loss: -0.130]\n",
      "Epoch 1370 -- [D loss: -0.011(R -0.179, F 0.157)] [G loss: -0.130]\n",
      "Epoch 1371 -- [D loss: -0.012(R -0.189, F 0.165)] [G loss: -0.140]\n",
      "Epoch 1372 -- [D loss: -0.013(R -0.196, F 0.169)] [G loss: -0.143]\n",
      "Epoch 1373 -- [D loss: -0.006(R -0.191, F 0.179)] [G loss: -0.150]\n",
      "Epoch 1374 -- [D loss: -0.010(R -0.190, F 0.170)] [G loss: -0.148]\n",
      "Epoch 1375 -- [D loss: -0.009(R -0.197, F 0.179)] [G loss: -0.147]\n",
      "Epoch 1376 -- [D loss: -0.006(R -0.188, F 0.176)] [G loss: -0.144]\n",
      "Epoch 1377 -- [D loss: -0.009(R -0.187, F 0.169)] [G loss: -0.141]\n",
      "Epoch 1378 -- [D loss: -0.013(R -0.186, F 0.159)] [G loss: -0.135]\n",
      "Epoch 1379 -- [D loss: -0.017(R -0.191, F 0.157)] [G loss: -0.141]\n",
      "Epoch 1380 -- [D loss: -0.019(R -0.196, F 0.157)] [G loss: -0.147]\n",
      "Epoch 1381 -- [D loss: -0.005(R -0.184, F 0.174)] [G loss: -0.153]\n",
      "Epoch 1382 -- [D loss: -0.003(R -0.180, F 0.173)] [G loss: -0.148]\n",
      "Epoch 1383 -- [D loss: -0.010(R -0.184, F 0.164)] [G loss: -0.141]\n",
      "Epoch 1384 -- [D loss: -0.011(R -0.188, F 0.165)] [G loss: -0.135]\n",
      "Epoch 1385 -- [D loss: -0.008(R -0.181, F 0.165)] [G loss: -0.128]\n",
      "Epoch 1386 -- [D loss: -0.013(R -0.187, F 0.160)] [G loss: -0.131]\n",
      "Epoch 1387 -- [D loss: -0.012(R -0.186, F 0.161)] [G loss: -0.132]\n",
      "Epoch 1388 -- [D loss: -0.014(R -0.184, F 0.157)] [G loss: -0.137]\n",
      "Epoch 1389 -- [D loss: -0.016(R -0.209, F 0.177)] [G loss: -0.163]\n",
      "Epoch 1390 -- [D loss: -0.001(R -0.188, F 0.185)] [G loss: -0.156]\n",
      "Epoch 1391 -- [D loss: -0.003(R -0.187, F 0.180)] [G loss: -0.150]\n",
      "Epoch 1392 -- [D loss: -0.013(R -0.193, F 0.167)] [G loss: -0.141]\n",
      "Epoch 1393 -- [D loss: -0.006(R -0.187, F 0.174)] [G loss: -0.144]\n",
      "Epoch 1394 -- [D loss: -0.015(R -0.192, F 0.163)] [G loss: -0.149]\n",
      "Epoch 1395 -- [D loss: -0.014(R -0.186, F 0.158)] [G loss: -0.137]\n",
      "Epoch 1396 -- [D loss: -0.010(R -0.178, F 0.158)] [G loss: -0.133]\n",
      "Epoch 1397 -- [D loss: -0.016(R -0.179, F 0.147)] [G loss: -0.123]\n",
      "Epoch 1398 -- [D loss: -0.011(R -0.168, F 0.146)] [G loss: -0.117]\n",
      "Epoch 1399 -- [D loss: -0.022(R -0.173, F 0.129)] [G loss: -0.124]\n",
      "Epoch 1400 -- [D loss: -0.005(R -0.158, F 0.148)] [G loss: -0.122]\n",
      "INFO:tensorflow:Assets written to: ram://7127c0c4-11e1-4390-b808-a0f8ffeaf125/assets\n",
      "INFO:tensorflow:Assets written to: ram://309c1024-4920-4285-99e9-14c400108d88/assets\n",
      "INFO:tensorflow:Assets written to: ram://88157690-b598-4959-ae76-45cd368e5fb0/assets\n",
      "Epoch 1401 -- [D loss: -0.013(R -0.163, F 0.137)] [G loss: -0.117]\n",
      "Epoch 1402 -- [D loss: -0.010(R -0.152, F 0.133)] [G loss: -0.112]\n",
      "Epoch 1403 -- [D loss: -0.015(R -0.155, F 0.126)] [G loss: -0.105]\n",
      "Epoch 1404 -- [D loss: -0.014(R -0.155, F 0.127)] [G loss: -0.100]\n",
      "Epoch 1405 -- [D loss: -0.012(R -0.145, F 0.121)] [G loss: -0.098]\n",
      "Epoch 1406 -- [D loss: -0.017(R -0.152, F 0.118)] [G loss: -0.099]\n",
      "Epoch 1407 -- [D loss: -0.008(R -0.141, F 0.124)] [G loss: -0.106]\n",
      "Epoch 1408 -- [D loss: -0.013(R -0.152, F 0.125)] [G loss: -0.107]\n",
      "Epoch 1409 -- [D loss: -0.008(R -0.145, F 0.130)] [G loss: -0.117]\n",
      "Epoch 1410 -- [D loss: -0.012(R -0.156, F 0.132)] [G loss: -0.119]\n",
      "Epoch 1411 -- [D loss: -0.008(R -0.149, F 0.134)] [G loss: -0.109]\n",
      "Epoch 1412 -- [D loss: -0.016(R -0.160, F 0.128)] [G loss: -0.110]\n",
      "Epoch 1413 -- [D loss: -0.010(R -0.159, F 0.140)] [G loss: -0.117]\n",
      "Epoch 1414 -- [D loss: -0.007(R -0.165, F 0.150)] [G loss: -0.123]\n",
      "Epoch 1415 -- [D loss: -0.009(R -0.172, F 0.153)] [G loss: -0.133]\n",
      "Epoch 1416 -- [D loss: -0.017(R -0.181, F 0.148)] [G loss: -0.128]\n",
      "Epoch 1417 -- [D loss: -0.012(R -0.187, F 0.164)] [G loss: -0.134]\n",
      "Epoch 1418 -- [D loss: -0.008(R -0.182, F 0.167)] [G loss: -0.136]\n",
      "Epoch 1419 -- [D loss: -0.010(R -0.194, F 0.174)] [G loss: -0.143]\n",
      "Epoch 1420 -- [D loss: -0.015(R -0.200, F 0.170)] [G loss: -0.146]\n",
      "Epoch 1421 -- [D loss: -0.015(R -0.197, F 0.167)] [G loss: -0.145]\n",
      "Epoch 1422 -- [D loss: -0.008(R -0.196, F 0.180)] [G loss: -0.140]\n",
      "Epoch 1423 -- [D loss: -0.012(R -0.196, F 0.172)] [G loss: -0.147]\n",
      "Epoch 1424 -- [D loss: -0.013(R -0.204, F 0.179)] [G loss: -0.153]\n",
      "Epoch 1425 -- [D loss: -0.019(R -0.209, F 0.171)] [G loss: -0.157]\n",
      "Epoch 1426 -- [D loss: -0.025(R -0.220, F 0.170)] [G loss: -0.175]\n",
      "Epoch 1427 -- [D loss: -0.017(R -0.214, F 0.180)] [G loss: -0.191]\n",
      "Epoch 1428 -- [D loss: -0.010(R -0.226, F 0.206)] [G loss: -0.194]\n",
      "Epoch 1429 -- [D loss: -0.007(R -0.210, F 0.197)] [G loss: -0.179]\n",
      "Epoch 1430 -- [D loss: -0.007(R -0.207, F 0.193)] [G loss: -0.177]\n",
      "Epoch 1431 -- [D loss: -0.004(R -0.199, F 0.191)] [G loss: -0.165]\n",
      "Epoch 1432 -- [D loss: -0.014(R -0.194, F 0.166)] [G loss: -0.126]\n",
      "Epoch 1433 -- [D loss: -0.015(R -0.201, F 0.171)] [G loss: -0.132]\n",
      "Epoch 1434 -- [D loss: -0.005(R -0.187, F 0.178)] [G loss: -0.137]\n",
      "Epoch 1435 -- [D loss: -0.005(R -0.186, F 0.175)] [G loss: -0.144]\n",
      "Epoch 1436 -- [D loss: -0.005(R -0.181, F 0.172)] [G loss: -0.147]\n",
      "Epoch 1437 -- [D loss: -0.013(R -0.179, F 0.153)] [G loss: -0.130]\n",
      "Epoch 1438 -- [D loss: -0.032(R -0.190, F 0.126)] [G loss: -0.146]\n",
      "Epoch 1439 -- [D loss: -0.025(R -0.205, F 0.155)] [G loss: -0.158]\n",
      "Epoch 1440 -- [D loss: -0.010(R -0.200, F 0.181)] [G loss: -0.156]\n",
      "Epoch 1441 -- [D loss: -0.011(R -0.195, F 0.173)] [G loss: -0.138]\n",
      "Epoch 1442 -- [D loss: -0.014(R -0.194, F 0.166)] [G loss: -0.134]\n",
      "Epoch 1443 -- [D loss: -0.012(R -0.194, F 0.169)] [G loss: -0.135]\n",
      "Epoch 1444 -- [D loss: -0.013(R -0.196, F 0.170)] [G loss: -0.133]\n",
      "Epoch 1445 -- [D loss: -0.016(R -0.193, F 0.161)] [G loss: -0.126]\n",
      "Epoch 1446 -- [D loss: -0.009(R -0.183, F 0.165)] [G loss: -0.132]\n",
      "Epoch 1447 -- [D loss: -0.011(R -0.174, F 0.152)] [G loss: -0.128]\n",
      "Epoch 1448 -- [D loss: -0.010(R -0.173, F 0.153)] [G loss: -0.120]\n",
      "Epoch 1449 -- [D loss: -0.016(R -0.173, F 0.141)] [G loss: -0.108]\n",
      "Epoch 1450 -- [D loss: -0.014(R -0.168, F 0.141)] [G loss: -0.109]\n",
      "Epoch 1451 -- [D loss: -0.012(R -0.161, F 0.136)] [G loss: -0.110]\n",
      "Epoch 1452 -- [D loss: -0.017(R -0.164, F 0.130)] [G loss: -0.107]\n",
      "Epoch 1453 -- [D loss: -0.020(R -0.162, F 0.122)] [G loss: -0.102]\n",
      "Epoch 1454 -- [D loss: -0.008(R -0.151, F 0.135)] [G loss: -0.106]\n",
      "Epoch 1455 -- [D loss: -0.015(R -0.158, F 0.128)] [G loss: -0.104]\n",
      "Epoch 1456 -- [D loss: -0.008(R -0.151, F 0.134)] [G loss: -0.110]\n",
      "Epoch 1457 -- [D loss: -0.010(R -0.158, F 0.138)] [G loss: -0.119]\n",
      "Epoch 1458 -- [D loss: -0.008(R -0.159, F 0.144)] [G loss: -0.112]\n",
      "Epoch 1459 -- [D loss: -0.010(R -0.155, F 0.135)] [G loss: -0.109]\n",
      "Epoch 1460 -- [D loss: -0.012(R -0.155, F 0.132)] [G loss: -0.106]\n",
      "Epoch 1461 -- [D loss: -0.015(R -0.161, F 0.130)] [G loss: -0.112]\n",
      "Epoch 1462 -- [D loss: -0.035(R -0.182, F 0.111)] [G loss: -0.140]\n",
      "Epoch 1463 -- [D loss: -0.012(R -0.171, F 0.147)] [G loss: -0.157]\n",
      "Epoch 1464 -- [D loss: -0.006(R -0.162, F 0.150)] [G loss: -0.124]\n",
      "Epoch 1465 -- [D loss: -0.010(R -0.162, F 0.141)] [G loss: -0.128]\n",
      "Epoch 1466 -- [D loss: -0.021(R -0.177, F 0.136)] [G loss: -0.141]\n",
      "Epoch 1467 -- [D loss: -0.019(R -0.177, F 0.139)] [G loss: -0.134]\n",
      "Epoch 1468 -- [D loss: -0.008(R -0.167, F 0.152)] [G loss: -0.127]\n",
      "Epoch 1469 -- [D loss: -0.016(R -0.176, F 0.143)] [G loss: -0.122]\n",
      "Epoch 1470 -- [D loss: -0.016(R -0.179, F 0.148)] [G loss: -0.120]\n",
      "Epoch 1471 -- [D loss: -0.015(R -0.189, F 0.159)] [G loss: -0.126]\n",
      "Epoch 1472 -- [D loss: -0.016(R -0.187, F 0.155)] [G loss: -0.138]\n",
      "Epoch 1473 -- [D loss: -0.010(R -0.189, F 0.168)] [G loss: -0.135]\n",
      "Epoch 1474 -- [D loss: -0.015(R -0.203, F 0.172)] [G loss: -0.140]\n",
      "Epoch 1475 -- [D loss: -0.019(R -0.207, F 0.170)] [G loss: -0.139]\n",
      "Epoch 1476 -- [D loss: -0.016(R -0.206, F 0.175)] [G loss: -0.148]\n",
      "Epoch 1477 -- [D loss: -0.023(R -0.228, F 0.182)] [G loss: -0.159]\n",
      "Epoch 1478 -- [D loss: -0.025(R -0.236, F 0.187)] [G loss: -0.173]\n",
      "Epoch 1479 -- [D loss: -0.023(R -0.249, F 0.204)] [G loss: -0.186]\n",
      "Epoch 1480 -- [D loss: -0.013(R -0.243, F 0.217)] [G loss: -0.201]\n",
      "Epoch 1481 -- [D loss: -0.016(R -0.245, F 0.213)] [G loss: -0.205]\n",
      "Epoch 1482 -- [D loss: -0.025(R -0.265, F 0.216)] [G loss: -0.214]\n",
      "Epoch 1483 -- [D loss: -0.005(R -0.251, F 0.240)] [G loss: -0.211]\n",
      "Epoch 1484 -- [D loss: -0.017(R -0.256, F 0.223)] [G loss: -0.210]\n",
      "Epoch 1485 -- [D loss: -0.003(R -0.234, F 0.227)] [G loss: -0.194]\n",
      "Epoch 1486 -- [D loss: -0.005(R -0.226, F 0.215)] [G loss: -0.186]\n",
      "Epoch 1487 -- [D loss: -0.011(R -0.219, F 0.196)] [G loss: -0.173]\n",
      "Epoch 1488 -- [D loss: -0.010(R -0.216, F 0.196)] [G loss: -0.167]\n",
      "Epoch 1489 -- [D loss: -0.004(R -0.192, F 0.185)] [G loss: -0.150]\n",
      "Epoch 1490 -- [D loss: -0.012(R -0.186, F 0.161)] [G loss: -0.138]\n",
      "Epoch 1491 -- [D loss: -0.007(R -0.171, F 0.158)] [G loss: -0.131]\n",
      "Epoch 1492 -- [D loss: -0.012(R -0.176, F 0.152)] [G loss: -0.133]\n",
      "Epoch 1493 -- [D loss: -0.009(R -0.162, F 0.144)] [G loss: -0.109]\n",
      "Epoch 1494 -- [D loss: -0.010(R -0.163, F 0.143)] [G loss: -0.104]\n",
      "Epoch 1495 -- [D loss: -0.015(R -0.160, F 0.130)] [G loss: -0.100]\n",
      "Epoch 1496 -- [D loss: -0.016(R -0.155, F 0.124)] [G loss: -0.098]\n",
      "Epoch 1497 -- [D loss: -0.012(R -0.144, F 0.120)] [G loss: -0.087]\n",
      "Epoch 1498 -- [D loss: -0.020(R -0.151, F 0.112)] [G loss: -0.091]\n",
      "Epoch 1499 -- [D loss: -0.013(R -0.136, F 0.111)] [G loss: -0.088]\n",
      "Epoch 1500 -- [D loss: -0.020(R -0.147, F 0.107)] [G loss: -0.086]\n",
      "INFO:tensorflow:Assets written to: ram://69a9e3b0-c34b-498a-88c4-00ca5800ccc9/assets\n",
      "INFO:tensorflow:Assets written to: ram://6b7be01e-86d2-4144-bb30-5c02a95ab1e7/assets\n",
      "INFO:tensorflow:Assets written to: ram://1e51da80-598f-475d-a44a-f361dedb2d2d/assets\n",
      "Epoch 1501 -- [D loss: -0.016(R -0.141, F 0.108)] [G loss: -0.093]\n",
      "Epoch 1502 -- [D loss: -0.020(R -0.141, F 0.102)] [G loss: -0.094]\n",
      "Epoch 1503 -- [D loss: -0.008(R -0.158, F 0.143)] [G loss: -0.090]\n",
      "Epoch 1504 -- [D loss: -0.016(R -0.148, F 0.117)] [G loss: -0.090]\n",
      "Epoch 1505 -- [D loss: -0.021(R -0.146, F 0.105)] [G loss: -0.091]\n",
      "Epoch 1506 -- [D loss: -0.018(R -0.139, F 0.102)] [G loss: -0.097]\n",
      "Epoch 1507 -- [D loss: -0.014(R -0.143, F 0.115)] [G loss: -0.093]\n",
      "Epoch 1508 -- [D loss: -0.020(R -0.145, F 0.106)] [G loss: -0.103]\n",
      "Epoch 1509 -- [D loss: -0.017(R -0.159, F 0.125)] [G loss: -0.110]\n",
      "Epoch 1510 -- [D loss: -0.010(R -0.151, F 0.132)] [G loss: -0.113]\n",
      "Epoch 1511 -- [D loss: -0.013(R -0.159, F 0.133)] [G loss: -0.124]\n",
      "Epoch 1512 -- [D loss: -0.020(R -0.175, F 0.136)] [G loss: -0.136]\n",
      "Epoch 1513 -- [D loss: -0.005(R -0.174, F 0.164)] [G loss: -0.140]\n",
      "Epoch 1514 -- [D loss: -0.011(R -0.195, F 0.173)] [G loss: -0.143]\n",
      "Epoch 1515 -- [D loss: -0.012(R -0.201, F 0.177)] [G loss: -0.151]\n",
      "Epoch 1516 -- [D loss: -0.009(R -0.203, F 0.185)] [G loss: -0.152]\n",
      "Epoch 1517 -- [D loss: -0.013(R -0.203, F 0.178)] [G loss: -0.163]\n",
      "Epoch 1518 -- [D loss: -0.011(R -0.211, F 0.188)] [G loss: -0.165]\n",
      "Epoch 1519 -- [D loss: -0.010(R -0.219, F 0.199)] [G loss: -0.173]\n",
      "Epoch 1520 -- [D loss: -0.016(R -0.233, F 0.201)] [G loss: -0.176]\n",
      "Epoch 1521 -- [D loss: -0.021(R -0.249, F 0.206)] [G loss: -0.175]\n",
      "Epoch 1522 -- [D loss: -0.016(R -0.248, F 0.216)] [G loss: -0.176]\n",
      "Epoch 1523 -- [D loss: -0.015(R -0.269, F 0.238)] [G loss: -0.193]\n",
      "Epoch 1524 -- [D loss: -0.010(R -0.266, F 0.245)] [G loss: -0.204]\n",
      "Epoch 1525 -- [D loss: -0.018(R -0.268, F 0.232)] [G loss: -0.197]\n",
      "Epoch 1526 -- [D loss: -0.028(R -0.268, F 0.212)] [G loss: -0.192]\n",
      "Epoch 1527 -- [D loss: -0.013(R -0.275, F 0.249)] [G loss: -0.209]\n",
      "Epoch 1528 -- [D loss: -0.018(R -0.267, F 0.231)] [G loss: -0.215]\n",
      "Epoch 1529 -- [D loss: -0.014(R -0.262, F 0.235)] [G loss: -0.210]\n",
      "Epoch 1530 -- [D loss: -0.011(R -0.251, F 0.228)] [G loss: -0.202]\n",
      "Epoch 1531 -- [D loss: -0.008(R -0.234, F 0.218)] [G loss: -0.198]\n",
      "Epoch 1532 -- [D loss: -0.006(R -0.226, F 0.213)] [G loss: -0.178]\n",
      "Epoch 1533 -- [D loss: -0.005(R -0.213, F 0.203)] [G loss: -0.167]\n",
      "Epoch 1534 -- [D loss: -0.005(R -0.200, F 0.190)] [G loss: -0.151]\n",
      "Epoch 1535 -- [D loss: -0.007(R -0.192, F 0.178)] [G loss: -0.145]\n",
      "Epoch 1536 -- [D loss: -0.012(R -0.188, F 0.163)] [G loss: -0.130]\n",
      "Epoch 1537 -- [D loss: -0.010(R -0.175, F 0.155)] [G loss: -0.123]\n",
      "Epoch 1538 -- [D loss: -0.014(R -0.173, F 0.145)] [G loss: -0.115]\n",
      "Epoch 1539 -- [D loss: -0.010(R -0.165, F 0.146)] [G loss: -0.110]\n",
      "Epoch 1540 -- [D loss: -0.012(R -0.160, F 0.136)] [G loss: -0.101]\n",
      "Epoch 1541 -- [D loss: -0.014(R -0.155, F 0.127)] [G loss: -0.100]\n",
      "Epoch 1542 -- [D loss: -0.010(R -0.145, F 0.126)] [G loss: -0.099]\n",
      "Epoch 1543 -- [D loss: -0.012(R -0.149, F 0.125)] [G loss: -0.089]\n",
      "Epoch 1544 -- [D loss: -0.017(R -0.145, F 0.111)] [G loss: -0.093]\n",
      "Epoch 1545 -- [D loss: -0.015(R -0.150, F 0.120)] [G loss: -0.097]\n",
      "Epoch 1546 -- [D loss: -0.018(R -0.154, F 0.118)] [G loss: -0.101]\n",
      "Epoch 1547 -- [D loss: -0.016(R -0.142, F 0.111)] [G loss: -0.110]\n",
      "Epoch 1548 -- [D loss: -0.020(R -0.161, F 0.121)] [G loss: -0.111]\n",
      "Epoch 1549 -- [D loss: -0.016(R -0.156, F 0.124)] [G loss: -0.091]\n",
      "Epoch 1550 -- [D loss: -0.011(R -0.151, F 0.128)] [G loss: -0.092]\n",
      "Epoch 1551 -- [D loss: -0.015(R -0.150, F 0.120)] [G loss: -0.095]\n",
      "Epoch 1552 -- [D loss: -0.023(R -0.157, F 0.111)] [G loss: -0.102]\n",
      "Epoch 1553 -- [D loss: -0.018(R -0.161, F 0.125)] [G loss: -0.098]\n",
      "Epoch 1554 -- [D loss: -0.013(R -0.154, F 0.128)] [G loss: -0.104]\n",
      "Epoch 1555 -- [D loss: -0.017(R -0.165, F 0.132)] [G loss: -0.103]\n",
      "Epoch 1556 -- [D loss: -0.013(R -0.168, F 0.142)] [G loss: -0.121]\n",
      "Epoch 1557 -- [D loss: -0.014(R -0.173, F 0.144)] [G loss: -0.131]\n",
      "Epoch 1558 -- [D loss: -0.014(R -0.189, F 0.160)] [G loss: -0.141]\n",
      "Epoch 1559 -- [D loss: -0.013(R -0.202, F 0.177)] [G loss: -0.143]\n",
      "Epoch 1560 -- [D loss: -0.015(R -0.206, F 0.177)] [G loss: -0.153]\n",
      "Epoch 1561 -- [D loss: -0.024(R -0.227, F 0.180)] [G loss: -0.157]\n",
      "Epoch 1562 -- [D loss: -0.030(R -0.254, F 0.194)] [G loss: -0.177]\n",
      "Epoch 1563 -- [D loss: -0.018(R -0.252, F 0.217)] [G loss: -0.193]\n",
      "Epoch 1564 -- [D loss: -0.021(R -0.265, F 0.223)] [G loss: -0.219]\n",
      "Epoch 1565 -- [D loss: -0.009(R -0.268, F 0.251)] [G loss: -0.230]\n",
      "Epoch 1566 -- [D loss: -0.004(R -0.265, F 0.256)] [G loss: -0.236]\n",
      "Epoch 1567 -- [D loss: -0.005(R -0.262, F 0.253)] [G loss: -0.221]\n",
      "Epoch 1568 -- [D loss: -0.007(R -0.257, F 0.243)] [G loss: -0.211]\n",
      "Epoch 1569 -- [D loss: -0.010(R -0.257, F 0.237)] [G loss: -0.199]\n",
      "Epoch 1570 -- [D loss: -0.006(R -0.245, F 0.233)] [G loss: -0.184]\n",
      "Epoch 1571 -- [D loss: -0.011(R -0.243, F 0.220)] [G loss: -0.169]\n",
      "Epoch 1572 -- [D loss: -0.021(R -0.234, F 0.191)] [G loss: -0.162]\n",
      "Epoch 1573 -- [D loss: -0.015(R -0.227, F 0.196)] [G loss: -0.153]\n",
      "Epoch 1574 -- [D loss: -0.018(R -0.223, F 0.187)] [G loss: -0.156]\n",
      "Epoch 1575 -- [D loss: -0.010(R -0.205, F 0.185)] [G loss: -0.150]\n",
      "Epoch 1576 -- [D loss: -0.017(R -0.208, F 0.174)] [G loss: -0.148]\n",
      "Epoch 1577 -- [D loss: -0.014(R -0.199, F 0.171)] [G loss: -0.150]\n",
      "Epoch 1578 -- [D loss: -0.013(R -0.186, F 0.160)] [G loss: -0.130]\n",
      "Epoch 1579 -- [D loss: -0.018(R -0.181, F 0.145)] [G loss: -0.112]\n",
      "Epoch 1580 -- [D loss: -0.015(R -0.170, F 0.140)] [G loss: -0.108]\n",
      "Epoch 1581 -- [D loss: -0.016(R -0.164, F 0.131)] [G loss: -0.096]\n",
      "Epoch 1582 -- [D loss: -0.013(R -0.162, F 0.136)] [G loss: -0.107]\n",
      "Epoch 1583 -- [D loss: -0.015(R -0.158, F 0.128)] [G loss: -0.092]\n",
      "Epoch 1584 -- [D loss: -0.011(R -0.147, F 0.125)] [G loss: -0.094]\n",
      "Epoch 1585 -- [D loss: -0.015(R -0.160, F 0.130)] [G loss: -0.101]\n",
      "Epoch 1586 -- [D loss: -0.009(R -0.149, F 0.132)] [G loss: -0.100]\n",
      "Epoch 1587 -- [D loss: -0.015(R -0.160, F 0.130)] [G loss: -0.112]\n",
      "Epoch 1588 -- [D loss: -0.004(R -0.141, F 0.134)] [G loss: -0.104]\n",
      "Epoch 1589 -- [D loss: -0.013(R -0.147, F 0.121)] [G loss: -0.094]\n",
      "Epoch 1590 -- [D loss: -0.012(R -0.147, F 0.124)] [G loss: -0.097]\n",
      "Epoch 1591 -- [D loss: -0.021(R -0.158, F 0.116)] [G loss: -0.100]\n",
      "Epoch 1592 -- [D loss: -0.013(R -0.154, F 0.127)] [G loss: -0.098]\n",
      "Epoch 1593 -- [D loss: -0.011(R -0.148, F 0.126)] [G loss: -0.103]\n",
      "Epoch 1594 -- [D loss: -0.017(R -0.161, F 0.127)] [G loss: -0.097]\n",
      "Epoch 1595 -- [D loss: -0.015(R -0.153, F 0.124)] [G loss: -0.099]\n",
      "Epoch 1596 -- [D loss: -0.015(R -0.158, F 0.129)] [G loss: -0.108]\n",
      "Epoch 1597 -- [D loss: -0.017(R -0.173, F 0.140)] [G loss: -0.107]\n",
      "Epoch 1598 -- [D loss: -0.008(R -0.164, F 0.148)] [G loss: -0.115]\n",
      "Epoch 1599 -- [D loss: -0.014(R -0.178, F 0.151)] [G loss: -0.122]\n",
      "Epoch 1600 -- [D loss: -0.020(R -0.189, F 0.148)] [G loss: -0.130]\n",
      "INFO:tensorflow:Assets written to: ram://d49c374e-d1fc-467e-b283-1ffb617e7224/assets\n",
      "INFO:tensorflow:Assets written to: ram://81cef8e0-c271-4703-ac5d-c9d03f49b0c8/assets\n",
      "INFO:tensorflow:Assets written to: ram://423fab7e-b7ff-4998-8901-8e0f681a4d2c/assets\n",
      "Epoch 1601 -- [D loss: -0.019(R -0.195, F 0.157)] [G loss: -0.143]\n",
      "Epoch 1602 -- [D loss: -0.016(R -0.207, F 0.175)] [G loss: -0.154]\n",
      "Epoch 1603 -- [D loss: -0.021(R -0.218, F 0.177)] [G loss: -0.163]\n",
      "Epoch 1604 -- [D loss: -0.023(R -0.228, F 0.182)] [G loss: -0.167]\n",
      "Epoch 1605 -- [D loss: -0.009(R -0.220, F 0.201)] [G loss: -0.168]\n",
      "Epoch 1606 -- [D loss: -0.011(R -0.227, F 0.205)] [G loss: -0.170]\n",
      "Epoch 1607 -- [D loss: -0.014(R -0.230, F 0.201)] [G loss: -0.166]\n",
      "Epoch 1608 -- [D loss: -0.014(R -0.235, F 0.208)] [G loss: -0.176]\n",
      "Epoch 1609 -- [D loss: -0.007(R -0.229, F 0.215)] [G loss: -0.180]\n",
      "Epoch 1610 -- [D loss: -0.015(R -0.235, F 0.205)] [G loss: -0.171]\n",
      "Epoch 1611 -- [D loss: -0.010(R -0.227, F 0.206)] [G loss: -0.181]\n",
      "Epoch 1612 -- [D loss: -0.007(R -0.220, F 0.207)] [G loss: -0.175]\n",
      "Epoch 1613 -- [D loss: -0.008(R -0.211, F 0.195)] [G loss: -0.162]\n",
      "Epoch 1614 -- [D loss: -0.018(R -0.213, F 0.176)] [G loss: -0.146]\n",
      "Epoch 1615 -- [D loss: -0.016(R -0.202, F 0.171)] [G loss: -0.150]\n",
      "Epoch 1616 -- [D loss: -0.001(R -0.191, F 0.189)] [G loss: -0.146]\n",
      "Epoch 1617 -- [D loss: -0.008(R -0.198, F 0.181)] [G loss: -0.133]\n",
      "Epoch 1618 -- [D loss: -0.017(R -0.195, F 0.161)] [G loss: -0.121]\n",
      "Epoch 1619 -- [D loss: -0.011(R -0.168, F 0.146)] [G loss: -0.103]\n",
      "Epoch 1620 -- [D loss: -0.021(R -0.171, F 0.129)] [G loss: -0.100]\n",
      "Epoch 1621 -- [D loss: -0.011(R -0.162, F 0.140)] [G loss: -0.095]\n",
      "Epoch 1622 -- [D loss: -0.011(R -0.150, F 0.127)] [G loss: -0.093]\n",
      "Epoch 1623 -- [D loss: -0.017(R -0.154, F 0.121)] [G loss: -0.083]\n",
      "Epoch 1624 -- [D loss: -0.013(R -0.142, F 0.116)] [G loss: -0.078]\n",
      "Epoch 1625 -- [D loss: -0.013(R -0.143, F 0.117)] [G loss: -0.094]\n",
      "Epoch 1626 -- [D loss: -0.004(R -0.134, F 0.125)] [G loss: -0.093]\n",
      "Epoch 1627 -- [D loss: -0.008(R -0.147, F 0.130)] [G loss: -0.103]\n",
      "Epoch 1628 -- [D loss: -0.011(R -0.148, F 0.125)] [G loss: -0.099]\n",
      "Epoch 1629 -- [D loss: -0.009(R -0.152, F 0.134)] [G loss: -0.106]\n",
      "Epoch 1630 -- [D loss: -0.020(R -0.164, F 0.124)] [G loss: -0.113]\n",
      "Epoch 1631 -- [D loss: -0.014(R -0.161, F 0.134)] [G loss: -0.105]\n",
      "Epoch 1632 -- [D loss: -0.010(R -0.162, F 0.142)] [G loss: -0.110]\n",
      "Epoch 1633 -- [D loss: -0.012(R -0.164, F 0.140)] [G loss: -0.117]\n",
      "Epoch 1634 -- [D loss: -0.013(R -0.169, F 0.142)] [G loss: -0.115]\n",
      "Epoch 1635 -- [D loss: -0.013(R -0.170, F 0.144)] [G loss: -0.115]\n",
      "Epoch 1636 -- [D loss: -0.010(R -0.168, F 0.148)] [G loss: -0.115]\n",
      "Epoch 1637 -- [D loss: -0.015(R -0.181, F 0.151)] [G loss: -0.121]\n",
      "Epoch 1638 -- [D loss: -0.016(R -0.192, F 0.160)] [G loss: -0.125]\n",
      "Epoch 1639 -- [D loss: -0.013(R -0.197, F 0.172)] [G loss: -0.136]\n",
      "Epoch 1640 -- [D loss: -0.014(R -0.204, F 0.175)] [G loss: -0.150]\n",
      "Epoch 1641 -- [D loss: -0.013(R -0.210, F 0.184)] [G loss: -0.155]\n",
      "Epoch 1642 -- [D loss: -0.018(R -0.213, F 0.177)] [G loss: -0.162]\n",
      "Epoch 1643 -- [D loss: -0.008(R -0.222, F 0.205)] [G loss: -0.164]\n",
      "Epoch 1644 -- [D loss: -0.011(R -0.227, F 0.205)] [G loss: -0.166]\n",
      "Epoch 1645 -- [D loss: -0.013(R -0.229, F 0.204)] [G loss: -0.171]\n",
      "Epoch 1646 -- [D loss: -0.017(R -0.232, F 0.198)] [G loss: -0.164]\n",
      "Epoch 1647 -- [D loss: -0.016(R -0.225, F 0.193)] [G loss: -0.159]\n",
      "Epoch 1648 -- [D loss: -0.019(R -0.233, F 0.195)] [G loss: -0.177]\n",
      "Epoch 1649 -- [D loss: -0.022(R -0.233, F 0.188)] [G loss: -0.177]\n",
      "Epoch 1650 -- [D loss: -0.004(R -0.217, F 0.209)] [G loss: -0.172]\n",
      "Epoch 1651 -- [D loss: -0.019(R -0.214, F 0.177)] [G loss: -0.156]\n",
      "Epoch 1652 -- [D loss: -0.022(R -0.220, F 0.177)] [G loss: -0.155]\n",
      "Epoch 1653 -- [D loss: -0.013(R -0.217, F 0.191)] [G loss: -0.150]\n",
      "Epoch 1654 -- [D loss: -0.005(R -0.190, F 0.180)] [G loss: -0.152]\n",
      "Epoch 1655 -- [D loss: -0.016(R -0.198, F 0.167)] [G loss: -0.137]\n",
      "Epoch 1656 -- [D loss: -0.020(R -0.192, F 0.153)] [G loss: -0.126]\n",
      "Epoch 1657 -- [D loss: -0.008(R -0.174, F 0.158)] [G loss: -0.127]\n",
      "Epoch 1658 -- [D loss: -0.014(R -0.181, F 0.153)] [G loss: -0.129]\n",
      "Epoch 1659 -- [D loss: -0.013(R -0.184, F 0.158)] [G loss: -0.122]\n",
      "Epoch 1660 -- [D loss: -0.014(R -0.174, F 0.146)] [G loss: -0.119]\n",
      "Epoch 1661 -- [D loss: -0.011(R -0.177, F 0.156)] [G loss: -0.125]\n",
      "Epoch 1662 -- [D loss: -0.015(R -0.176, F 0.145)] [G loss: -0.104]\n",
      "Epoch 1663 -- [D loss: -0.018(R -0.170, F 0.134)] [G loss: -0.109]\n",
      "Epoch 1664 -- [D loss: -0.019(R -0.167, F 0.129)] [G loss: -0.102]\n",
      "Epoch 1665 -- [D loss: -0.021(R -0.160, F 0.118)] [G loss: -0.101]\n",
      "Epoch 1666 -- [D loss: -0.022(R -0.154, F 0.110)] [G loss: -0.109]\n",
      "Epoch 1667 -- [D loss: -0.014(R -0.150, F 0.121)] [G loss: -0.093]\n",
      "Epoch 1668 -- [D loss: -0.016(R -0.142, F 0.111)] [G loss: -0.091]\n",
      "Epoch 1669 -- [D loss: -0.017(R -0.145, F 0.110)] [G loss: -0.079]\n",
      "Epoch 1670 -- [D loss: -0.020(R -0.143, F 0.104)] [G loss: -0.083]\n",
      "Epoch 1671 -- [D loss: -0.025(R -0.151, F 0.102)] [G loss: -0.080]\n",
      "Epoch 1672 -- [D loss: -0.017(R -0.148, F 0.114)] [G loss: -0.085]\n",
      "Epoch 1673 -- [D loss: -0.020(R -0.158, F 0.118)] [G loss: -0.083]\n",
      "Epoch 1674 -- [D loss: -0.016(R -0.161, F 0.130)] [G loss: -0.100]\n",
      "Epoch 1675 -- [D loss: -0.015(R -0.168, F 0.138)] [G loss: -0.108]\n",
      "Epoch 1676 -- [D loss: -0.012(R -0.169, F 0.146)] [G loss: -0.124]\n",
      "Epoch 1677 -- [D loss: -0.013(R -0.176, F 0.151)] [G loss: -0.126]\n",
      "Epoch 1678 -- [D loss: -0.007(R -0.171, F 0.157)] [G loss: -0.128]\n",
      "Epoch 1679 -- [D loss: -0.011(R -0.181, F 0.160)] [G loss: -0.127]\n",
      "Epoch 1680 -- [D loss: -0.012(R -0.186, F 0.162)] [G loss: -0.135]\n",
      "Epoch 1681 -- [D loss: -0.010(R -0.193, F 0.174)] [G loss: -0.136]\n",
      "Epoch 1682 -- [D loss: -0.008(R -0.186, F 0.169)] [G loss: -0.133]\n",
      "Epoch 1683 -- [D loss: -0.013(R -0.191, F 0.164)] [G loss: -0.139]\n",
      "Epoch 1684 -- [D loss: -0.011(R -0.183, F 0.162)] [G loss: -0.139]\n",
      "Epoch 1685 -- [D loss: -0.011(R -0.184, F 0.161)] [G loss: -0.137]\n",
      "Epoch 1686 -- [D loss: -0.015(R -0.196, F 0.167)] [G loss: -0.141]\n",
      "Epoch 1687 -- [D loss: -0.017(R -0.198, F 0.165)] [G loss: -0.131]\n",
      "Epoch 1688 -- [D loss: -0.018(R -0.210, F 0.175)] [G loss: -0.137]\n",
      "Epoch 1689 -- [D loss: -0.027(R -0.218, F 0.164)] [G loss: -0.146]\n",
      "Epoch 1690 -- [D loss: -0.019(R -0.223, F 0.185)] [G loss: -0.142]\n",
      "Epoch 1691 -- [D loss: -0.024(R -0.229, F 0.181)] [G loss: -0.151]\n",
      "Epoch 1692 -- [D loss: -0.031(R -0.232, F 0.170)] [G loss: -0.165]\n",
      "Epoch 1693 -- [D loss: -0.035(R -0.228, F 0.159)] [G loss: -0.172]\n",
      "Epoch 1694 -- [D loss: -0.020(R -0.216, F 0.175)] [G loss: -0.196]\n",
      "Epoch 1695 -- [D loss: -0.005(R -0.217, F 0.207)] [G loss: -0.185]\n",
      "Epoch 1696 -- [D loss: -0.009(R -0.218, F 0.200)] [G loss: -0.190]\n",
      "Epoch 1697 -- [D loss: -0.011(R -0.217, F 0.195)] [G loss: -0.169]\n",
      "Epoch 1698 -- [D loss: -0.009(R -0.199, F 0.182)] [G loss: -0.151]\n",
      "Epoch 1699 -- [D loss: -0.012(R -0.200, F 0.176)] [G loss: -0.142]\n",
      "Epoch 1700 -- [D loss: -0.011(R -0.183, F 0.162)] [G loss: -0.124]\n",
      "INFO:tensorflow:Assets written to: ram://e7fd5cd6-3dee-4e1b-95fc-9af14efb6188/assets\n",
      "INFO:tensorflow:Assets written to: ram://53e98b5d-0941-4a54-b521-0232afe44857/assets\n",
      "INFO:tensorflow:Assets written to: ram://90c1f794-3c53-4b9b-8617-df0782148472/assets\n",
      "Epoch 1701 -- [D loss: -0.014(R -0.168, F 0.140)] [G loss: -0.111]\n",
      "Epoch 1702 -- [D loss: -0.012(R -0.165, F 0.141)] [G loss: -0.100]\n",
      "Epoch 1703 -- [D loss: -0.022(R -0.157, F 0.112)] [G loss: -0.088]\n",
      "Epoch 1704 -- [D loss: -0.027(R -0.159, F 0.105)] [G loss: -0.085]\n",
      "Epoch 1705 -- [D loss: -0.013(R -0.145, F 0.119)] [G loss: -0.084]\n",
      "Epoch 1706 -- [D loss: -0.016(R -0.148, F 0.115)] [G loss: -0.075]\n",
      "Epoch 1707 -- [D loss: -0.019(R -0.142, F 0.103)] [G loss: -0.073]\n",
      "Epoch 1708 -- [D loss: -0.017(R -0.147, F 0.114)] [G loss: -0.080]\n",
      "Epoch 1709 -- [D loss: -0.019(R -0.148, F 0.111)] [G loss: -0.089]\n",
      "Epoch 1710 -- [D loss: -0.014(R -0.153, F 0.125)] [G loss: -0.092]\n",
      "Epoch 1711 -- [D loss: -0.013(R -0.164, F 0.137)] [G loss: -0.105]\n",
      "Epoch 1712 -- [D loss: -0.013(R -0.163, F 0.138)] [G loss: -0.110]\n",
      "Epoch 1713 -- [D loss: -0.020(R -0.165, F 0.125)] [G loss: -0.115]\n",
      "Epoch 1714 -- [D loss: -0.010(R -0.175, F 0.154)] [G loss: -0.116]\n",
      "Epoch 1715 -- [D loss: -0.008(R -0.172, F 0.156)] [G loss: -0.125]\n",
      "Epoch 1716 -- [D loss: -0.006(R -0.164, F 0.151)] [G loss: -0.123]\n",
      "Epoch 1717 -- [D loss: -0.012(R -0.171, F 0.147)] [G loss: -0.114]\n",
      "Epoch 1718 -- [D loss: -0.019(R -0.170, F 0.132)] [G loss: -0.120]\n",
      "Epoch 1719 -- [D loss: -0.011(R -0.170, F 0.148)] [G loss: -0.121]\n",
      "Epoch 1720 -- [D loss: -0.008(R -0.164, F 0.149)] [G loss: -0.111]\n",
      "Epoch 1721 -- [D loss: -0.018(R -0.168, F 0.132)] [G loss: -0.109]\n",
      "Epoch 1722 -- [D loss: -0.007(R -0.173, F 0.159)] [G loss: -0.117]\n",
      "Epoch 1723 -- [D loss: -0.018(R -0.185, F 0.148)] [G loss: -0.122]\n",
      "Epoch 1724 -- [D loss: -0.016(R -0.180, F 0.148)] [G loss: -0.122]\n",
      "Epoch 1725 -- [D loss: -0.009(R -0.178, F 0.159)] [G loss: -0.126]\n",
      "Epoch 1726 -- [D loss: -0.021(R -0.183, F 0.141)] [G loss: -0.119]\n",
      "Epoch 1727 -- [D loss: -0.023(R -0.185, F 0.139)] [G loss: -0.106]\n",
      "Epoch 1728 -- [D loss: -0.020(R -0.186, F 0.145)] [G loss: -0.118]\n",
      "Epoch 1729 -- [D loss: -0.027(R -0.199, F 0.146)] [G loss: -0.124]\n",
      "Epoch 1730 -- [D loss: -0.019(R -0.206, F 0.167)] [G loss: -0.135]\n",
      "Epoch 1731 -- [D loss: -0.025(R -0.215, F 0.165)] [G loss: -0.145]\n",
      "Epoch 1732 -- [D loss: -0.024(R -0.220, F 0.172)] [G loss: -0.157]\n",
      "Epoch 1733 -- [D loss: -0.014(R -0.248, F 0.219)] [G loss: -0.184]\n",
      "Epoch 1734 -- [D loss: -0.024(R -0.253, F 0.205)] [G loss: -0.203]\n",
      "Epoch 1735 -- [D loss: -0.009(R -0.263, F 0.245)] [G loss: -0.213]\n",
      "Epoch 1736 -- [D loss: -0.014(R -0.260, F 0.233)] [G loss: -0.231]\n",
      "Epoch 1737 -- [D loss: -0.014(R -0.269, F 0.240)] [G loss: -0.243]\n",
      "Epoch 1738 -- [D loss: -0.012(R -0.265, F 0.242)] [G loss: -0.240]\n",
      "Epoch 1739 -- [D loss: -0.023(R -0.275, F 0.229)] [G loss: -0.243]\n",
      "Epoch 1740 -- [D loss: -0.016(R -0.287, F 0.256)] [G loss: -0.243]\n",
      "Epoch 1741 -- [D loss: -0.007(R -0.265, F 0.250)] [G loss: -0.223]\n",
      "Epoch 1742 -- [D loss: -0.008(R -0.260, F 0.245)] [G loss: -0.209]\n",
      "Epoch 1743 -- [D loss: -0.019(R -0.253, F 0.214)] [G loss: -0.191]\n",
      "Epoch 1744 -- [D loss: -0.015(R -0.236, F 0.206)] [G loss: -0.173]\n",
      "Epoch 1745 -- [D loss: -0.013(R -0.217, F 0.190)] [G loss: -0.140]\n",
      "Epoch 1746 -- [D loss: -0.018(R -0.197, F 0.160)] [G loss: -0.114]\n",
      "Epoch 1747 -- [D loss: -0.022(R -0.176, F 0.132)] [G loss: -0.099]\n",
      "Epoch 1748 -- [D loss: -0.021(R -0.169, F 0.128)] [G loss: -0.091]\n",
      "Epoch 1749 -- [D loss: -0.022(R -0.157, F 0.112)] [G loss: -0.074]\n",
      "Epoch 1750 -- [D loss: -0.011(R -0.133, F 0.111)] [G loss: -0.072]\n",
      "Epoch 1751 -- [D loss: -0.014(R -0.121, F 0.093)] [G loss: -0.066]\n",
      "Epoch 1752 -- [D loss: -0.019(R -0.127, F 0.090)] [G loss: -0.058]\n",
      "Epoch 1753 -- [D loss: -0.009(R -0.110, F 0.091)] [G loss: -0.049]\n",
      "Epoch 1754 -- [D loss: -0.017(R -0.104, F 0.070)] [G loss: -0.043]\n",
      "Epoch 1755 -- [D loss: -0.012(R -0.107, F 0.083)] [G loss: -0.047]\n",
      "Epoch 1756 -- [D loss: -0.008(R -0.108, F 0.092)] [G loss: -0.049]\n",
      "Epoch 1757 -- [D loss: -0.014(R -0.116, F 0.088)] [G loss: -0.049]\n",
      "Epoch 1758 -- [D loss: -0.013(R -0.111, F 0.085)] [G loss: -0.045]\n",
      "Epoch 1759 -- [D loss: -0.024(R -0.124, F 0.076)] [G loss: -0.070]\n",
      "Epoch 1760 -- [D loss: -0.011(R -0.130, F 0.108)] [G loss: -0.079]\n",
      "Epoch 1761 -- [D loss: -0.015(R -0.141, F 0.112)] [G loss: -0.084]\n",
      "Epoch 1762 -- [D loss: -0.015(R -0.143, F 0.113)] [G loss: -0.095]\n",
      "Epoch 1763 -- [D loss: -0.020(R -0.160, F 0.119)] [G loss: -0.106]\n",
      "Epoch 1764 -- [D loss: -0.015(R -0.151, F 0.121)] [G loss: -0.101]\n",
      "Epoch 1765 -- [D loss: -0.025(R -0.173, F 0.122)] [G loss: -0.104]\n",
      "Epoch 1766 -- [D loss: -0.019(R -0.180, F 0.143)] [G loss: -0.116]\n",
      "Epoch 1767 -- [D loss: -0.020(R -0.188, F 0.148)] [G loss: -0.136]\n",
      "Epoch 1768 -- [D loss: -0.010(R -0.192, F 0.172)] [G loss: -0.143]\n",
      "Epoch 1769 -- [D loss: -0.013(R -0.202, F 0.176)] [G loss: -0.146]\n",
      "Epoch 1770 -- [D loss: -0.013(R -0.218, F 0.191)] [G loss: -0.159]\n",
      "Epoch 1771 -- [D loss: -0.019(R -0.230, F 0.191)] [G loss: -0.168]\n",
      "Epoch 1772 -- [D loss: -0.021(R -0.243, F 0.200)] [G loss: -0.175]\n",
      "Epoch 1773 -- [D loss: -0.018(R -0.249, F 0.213)] [G loss: -0.175]\n",
      "Epoch 1774 -- [D loss: -0.024(R -0.257, F 0.209)] [G loss: -0.174]\n",
      "Epoch 1775 -- [D loss: -0.027(R -0.265, F 0.211)] [G loss: -0.182]\n",
      "Epoch 1776 -- [D loss: -0.022(R -0.260, F 0.217)] [G loss: -0.200]\n",
      "Epoch 1777 -- [D loss: -0.025(R -0.268, F 0.219)] [G loss: -0.210]\n",
      "Epoch 1778 -- [D loss: -0.021(R -0.283, F 0.241)] [G loss: -0.217]\n",
      "Epoch 1779 -- [D loss: -0.026(R -0.290, F 0.238)] [G loss: -0.230]\n",
      "Epoch 1780 -- [D loss: -0.014(R -0.267, F 0.239)] [G loss: -0.236]\n",
      "Epoch 1781 -- [D loss: -0.012(R -0.280, F 0.257)] [G loss: -0.233]\n",
      "Epoch 1782 -- [D loss: -0.021(R -0.282, F 0.241)] [G loss: -0.231]\n",
      "Epoch 1783 -- [D loss: -0.008(R -0.261, F 0.246)] [G loss: -0.221]\n",
      "Epoch 1784 -- [D loss: -0.018(R -0.266, F 0.230)] [G loss: -0.221]\n",
      "Epoch 1785 -- [D loss: -0.014(R -0.259, F 0.231)] [G loss: -0.210]\n",
      "Epoch 1786 -- [D loss: -0.013(R -0.243, F 0.217)] [G loss: -0.189]\n",
      "Epoch 1787 -- [D loss: -0.013(R -0.231, F 0.205)] [G loss: -0.171]\n",
      "Epoch 1788 -- [D loss: -0.007(R -0.208, F 0.194)] [G loss: -0.145]\n",
      "Epoch 1789 -- [D loss: -0.014(R -0.199, F 0.172)] [G loss: -0.134]\n",
      "Epoch 1790 -- [D loss: -0.011(R -0.178, F 0.156)] [G loss: -0.108]\n",
      "Epoch 1791 -- [D loss: -0.020(R -0.174, F 0.134)] [G loss: -0.093]\n",
      "Epoch 1792 -- [D loss: -0.020(R -0.146, F 0.105)] [G loss: -0.086]\n",
      "Epoch 1793 -- [D loss: -0.021(R -0.152, F 0.109)] [G loss: -0.073]\n",
      "Epoch 1794 -- [D loss: -0.023(R -0.136, F 0.090)] [G loss: -0.057]\n",
      "Epoch 1795 -- [D loss: -0.023(R -0.126, F 0.079)] [G loss: -0.053]\n",
      "Epoch 1796 -- [D loss: -0.024(R -0.126, F 0.079)] [G loss: -0.058]\n",
      "Epoch 1797 -- [D loss: -0.023(R -0.124, F 0.078)] [G loss: -0.060]\n",
      "Epoch 1798 -- [D loss: -0.025(R -0.132, F 0.081)] [G loss: -0.069]\n",
      "Epoch 1799 -- [D loss: -0.026(R -0.119, F 0.068)] [G loss: -0.082]\n",
      "Epoch 1800 -- [D loss: -0.018(R -0.131, F 0.095)] [G loss: -0.065]\n",
      "INFO:tensorflow:Assets written to: ram://b2c7ae43-be2c-4996-8962-e08be7948987/assets\n",
      "INFO:tensorflow:Assets written to: ram://23011a75-26dc-4309-b28a-3c791d4c83c7/assets\n",
      "INFO:tensorflow:Assets written to: ram://7230464d-1787-4165-a8ea-0fc1f7f1ee10/assets\n",
      "Epoch 1801 -- [D loss: -0.017(R -0.132, F 0.099)] [G loss: -0.065]\n",
      "Epoch 1802 -- [D loss: -0.018(R -0.128, F 0.093)] [G loss: -0.062]\n",
      "Epoch 1803 -- [D loss: -0.019(R -0.131, F 0.094)] [G loss: -0.062]\n",
      "Epoch 1804 -- [D loss: -0.018(R -0.133, F 0.098)] [G loss: -0.073]\n",
      "Epoch 1805 -- [D loss: -0.007(R -0.133, F 0.119)] [G loss: -0.083]\n",
      "Epoch 1806 -- [D loss: -0.021(R -0.159, F 0.117)] [G loss: -0.102]\n",
      "Epoch 1807 -- [D loss: -0.012(R -0.159, F 0.134)] [G loss: -0.113]\n",
      "Epoch 1808 -- [D loss: -0.018(R -0.181, F 0.145)] [G loss: -0.128]\n",
      "Epoch 1809 -- [D loss: -0.011(R -0.184, F 0.162)] [G loss: -0.138]\n",
      "Epoch 1810 -- [D loss: -0.018(R -0.194, F 0.158)] [G loss: -0.161]\n",
      "Epoch 1811 -- [D loss: -0.010(R -0.212, F 0.192)] [G loss: -0.170]\n",
      "Epoch 1812 -- [D loss: -0.015(R -0.224, F 0.194)] [G loss: -0.173]\n",
      "Epoch 1813 -- [D loss: -0.018(R -0.241, F 0.205)] [G loss: -0.177]\n",
      "Epoch 1814 -- [D loss: -0.017(R -0.254, F 0.220)] [G loss: -0.187]\n",
      "Epoch 1815 -- [D loss: -0.018(R -0.265, F 0.229)] [G loss: -0.194]\n",
      "Epoch 1816 -- [D loss: -0.019(R -0.271, F 0.234)] [G loss: -0.197]\n",
      "Epoch 1817 -- [D loss: -0.018(R -0.270, F 0.235)] [G loss: -0.193]\n",
      "Epoch 1818 -- [D loss: -0.019(R -0.269, F 0.230)] [G loss: -0.207]\n",
      "Epoch 1819 -- [D loss: -0.015(R -0.277, F 0.248)] [G loss: -0.218]\n",
      "Epoch 1820 -- [D loss: -0.021(R -0.292, F 0.250)] [G loss: -0.226]\n",
      "Epoch 1821 -- [D loss: -0.029(R -0.297, F 0.239)] [G loss: -0.231]\n",
      "Epoch 1822 -- [D loss: -0.007(R -0.284, F 0.269)] [G loss: -0.246]\n",
      "Epoch 1823 -- [D loss: -0.005(R -0.293, F 0.284)] [G loss: -0.244]\n",
      "Epoch 1824 -- [D loss: -0.008(R -0.284, F 0.269)] [G loss: -0.242]\n",
      "Epoch 1825 -- [D loss: -0.007(R -0.269, F 0.254)] [G loss: -0.229]\n",
      "Epoch 1826 -- [D loss: -0.011(R -0.264, F 0.241)] [G loss: -0.202]\n",
      "Epoch 1827 -- [D loss: -0.008(R -0.232, F 0.216)] [G loss: -0.180]\n",
      "Epoch 1828 -- [D loss: -0.013(R -0.218, F 0.192)] [G loss: -0.162]\n",
      "Epoch 1829 -- [D loss: -0.020(R -0.205, F 0.166)] [G loss: -0.139]\n",
      "Epoch 1830 -- [D loss: -0.017(R -0.189, F 0.155)] [G loss: -0.123]\n",
      "Epoch 1831 -- [D loss: -0.014(R -0.182, F 0.155)] [G loss: -0.102]\n",
      "Epoch 1832 -- [D loss: -0.018(R -0.169, F 0.133)] [G loss: -0.096]\n",
      "Epoch 1833 -- [D loss: -0.020(R -0.164, F 0.123)] [G loss: -0.090]\n",
      "Epoch 1834 -- [D loss: -0.019(R -0.152, F 0.114)] [G loss: -0.085]\n",
      "Epoch 1835 -- [D loss: -0.016(R -0.162, F 0.129)] [G loss: -0.082]\n",
      "Epoch 1836 -- [D loss: -0.021(R -0.143, F 0.101)] [G loss: -0.072]\n",
      "Epoch 1837 -- [D loss: -0.017(R -0.132, F 0.097)] [G loss: -0.067]\n",
      "Epoch 1838 -- [D loss: -0.011(R -0.116, F 0.094)] [G loss: -0.066]\n",
      "Epoch 1839 -- [D loss: -0.019(R -0.118, F 0.080)] [G loss: -0.076]\n",
      "Epoch 1840 -- [D loss: -0.008(R -0.120, F 0.103)] [G loss: -0.084]\n",
      "Epoch 1841 -- [D loss: -0.016(R -0.122, F 0.091)] [G loss: -0.069]\n",
      "Epoch 1842 -- [D loss: -0.013(R -0.123, F 0.096)] [G loss: -0.075]\n",
      "Epoch 1843 -- [D loss: -0.017(R -0.124, F 0.089)] [G loss: -0.066]\n",
      "Epoch 1844 -- [D loss: -0.011(R -0.123, F 0.102)] [G loss: -0.080]\n",
      "Epoch 1845 -- [D loss: -0.007(R -0.127, F 0.112)] [G loss: -0.087]\n",
      "Epoch 1846 -- [D loss: -0.017(R -0.151, F 0.117)] [G loss: -0.098]\n",
      "Epoch 1847 -- [D loss: -0.014(R -0.159, F 0.131)] [G loss: -0.104]\n",
      "Epoch 1848 -- [D loss: -0.014(R -0.168, F 0.140)] [G loss: -0.117]\n",
      "Epoch 1849 -- [D loss: -0.014(R -0.193, F 0.165)] [G loss: -0.132]\n",
      "Epoch 1850 -- [D loss: -0.012(R -0.203, F 0.179)] [G loss: -0.147]\n",
      "Epoch 1851 -- [D loss: -0.020(R -0.235, F 0.196)] [G loss: -0.166]\n",
      "Epoch 1852 -- [D loss: -0.024(R -0.253, F 0.206)] [G loss: -0.176]\n",
      "Epoch 1853 -- [D loss: -0.021(R -0.258, F 0.216)] [G loss: -0.193]\n",
      "Epoch 1854 -- [D loss: -0.017(R -0.271, F 0.237)] [G loss: -0.209]\n",
      "Epoch 1855 -- [D loss: -0.013(R -0.289, F 0.263)] [G loss: -0.222]\n",
      "Epoch 1856 -- [D loss: -0.017(R -0.287, F 0.253)] [G loss: -0.237]\n",
      "Epoch 1857 -- [D loss: -0.019(R -0.294, F 0.257)] [G loss: -0.240]\n",
      "Epoch 1858 -- [D loss: -0.012(R -0.289, F 0.264)] [G loss: -0.240]\n",
      "Epoch 1859 -- [D loss: -0.018(R -0.285, F 0.249)] [G loss: -0.249]\n",
      "Epoch 1860 -- [D loss: -0.023(R -0.297, F 0.251)] [G loss: -0.263]\n",
      "Epoch 1861 -- [D loss: -0.010(R -0.293, F 0.273)] [G loss: -0.260]\n",
      "Epoch 1862 -- [D loss: -0.007(R -0.293, F 0.278)] [G loss: -0.236]\n",
      "Epoch 1863 -- [D loss: -0.021(R -0.287, F 0.245)] [G loss: -0.236]\n",
      "Epoch 1864 -- [D loss: -0.016(R -0.284, F 0.251)] [G loss: -0.211]\n",
      "Epoch 1865 -- [D loss: -0.023(R -0.287, F 0.242)] [G loss: -0.194]\n",
      "Epoch 1866 -- [D loss: -0.009(R -0.257, F 0.239)] [G loss: -0.195]\n",
      "Epoch 1867 -- [D loss: -0.016(R -0.251, F 0.219)] [G loss: -0.191]\n",
      "Epoch 1868 -- [D loss: -0.025(R -0.249, F 0.198)] [G loss: -0.181]\n",
      "Epoch 1869 -- [D loss: -0.020(R -0.261, F 0.222)] [G loss: -0.179]\n",
      "Epoch 1870 -- [D loss: -0.018(R -0.239, F 0.202)] [G loss: -0.174]\n",
      "Epoch 1871 -- [D loss: -0.005(R -0.221, F 0.211)] [G loss: -0.146]\n",
      "Epoch 1872 -- [D loss: -0.013(R -0.201, F 0.176)] [G loss: -0.129]\n",
      "Epoch 1873 -- [D loss: -0.020(R -0.183, F 0.142)] [G loss: -0.112]\n",
      "Epoch 1874 -- [D loss: -0.024(R -0.159, F 0.111)] [G loss: -0.097]\n",
      "Epoch 1875 -- [D loss: -0.016(R -0.148, F 0.115)] [G loss: -0.081]\n",
      "Epoch 1876 -- [D loss: -0.016(R -0.142, F 0.109)] [G loss: -0.063]\n",
      "Epoch 1877 -- [D loss: -0.025(R -0.129, F 0.079)] [G loss: -0.049]\n",
      "Epoch 1878 -- [D loss: -0.025(R -0.122, F 0.072)] [G loss: -0.057]\n",
      "Epoch 1879 -- [D loss: -0.028(R -0.123, F 0.067)] [G loss: -0.061]\n",
      "Epoch 1880 -- [D loss: -0.022(R -0.124, F 0.080)] [G loss: -0.068]\n",
      "Epoch 1881 -- [D loss: -0.019(R -0.141, F 0.103)] [G loss: -0.071]\n",
      "Epoch 1882 -- [D loss: -0.013(R -0.123, F 0.097)] [G loss: -0.065]\n",
      "Epoch 1883 -- [D loss: -0.019(R -0.134, F 0.097)] [G loss: -0.072]\n",
      "Epoch 1884 -- [D loss: -0.017(R -0.141, F 0.106)] [G loss: -0.076]\n",
      "Epoch 1885 -- [D loss: -0.015(R -0.137, F 0.107)] [G loss: -0.080]\n",
      "Epoch 1886 -- [D loss: -0.022(R -0.155, F 0.112)] [G loss: -0.095]\n",
      "Epoch 1887 -- [D loss: -0.023(R -0.170, F 0.125)] [G loss: -0.102]\n",
      "Epoch 1888 -- [D loss: -0.025(R -0.175, F 0.126)] [G loss: -0.105]\n",
      "Epoch 1889 -- [D loss: -0.013(R -0.184, F 0.158)] [G loss: -0.131]\n",
      "Epoch 1890 -- [D loss: -0.007(R -0.172, F 0.159)] [G loss: -0.130]\n",
      "Epoch 1891 -- [D loss: -0.014(R -0.183, F 0.154)] [G loss: -0.125]\n",
      "Epoch 1892 -- [D loss: -0.019(R -0.194, F 0.157)] [G loss: -0.136]\n",
      "Epoch 1893 -- [D loss: -0.025(R -0.221, F 0.171)] [G loss: -0.155]\n",
      "Epoch 1894 -- [D loss: 0.003(R -0.219, F 0.224)] [G loss: -0.170]\n",
      "Epoch 1895 -- [D loss: -0.012(R -0.245, F 0.221)] [G loss: -0.177]\n",
      "Epoch 1896 -- [D loss: -0.018(R -0.247, F 0.212)] [G loss: -0.179]\n",
      "Epoch 1897 -- [D loss: -0.025(R -0.269, F 0.220)] [G loss: -0.191]\n",
      "Epoch 1898 -- [D loss: -0.025(R -0.287, F 0.236)] [G loss: -0.224]\n",
      "Epoch 1899 -- [D loss: -0.022(R -0.296, F 0.252)] [G loss: -0.253]\n",
      "Epoch 1900 -- [D loss: -0.022(R -0.322, F 0.278)] [G loss: -0.259]\n",
      "INFO:tensorflow:Assets written to: ram://44a9a28e-b3f6-4650-b975-02c4a5e2166e/assets\n",
      "INFO:tensorflow:Assets written to: ram://e70e8df1-5921-4cb9-854c-b417036413f6/assets\n",
      "INFO:tensorflow:Assets written to: ram://97d44114-11c3-435c-b599-cdbee038aee4/assets\n",
      "Epoch 1901 -- [D loss: -0.019(R -0.316, F 0.279)] [G loss: -0.253]\n",
      "Epoch 1902 -- [D loss: -0.021(R -0.321, F 0.279)] [G loss: -0.251]\n",
      "Epoch 1903 -- [D loss: -0.027(R -0.316, F 0.261)] [G loss: -0.257]\n",
      "Epoch 1904 -- [D loss: -0.005(R -0.287, F 0.276)] [G loss: -0.241]\n",
      "Epoch 1905 -- [D loss: -0.004(R -0.284, F 0.275)] [G loss: -0.231]\n",
      "Epoch 1906 -- [D loss: -0.009(R -0.279, F 0.262)] [G loss: -0.227]\n",
      "Epoch 1907 -- [D loss: -0.018(R -0.266, F 0.230)] [G loss: -0.221]\n",
      "Epoch 1908 -- [D loss: -0.002(R -0.239, F 0.235)] [G loss: -0.199]\n",
      "Epoch 1909 -- [D loss: -0.016(R -0.233, F 0.201)] [G loss: -0.174]\n",
      "Epoch 1910 -- [D loss: -0.005(R -0.215, F 0.205)] [G loss: -0.158]\n",
      "Epoch 1911 -- [D loss: -0.018(R -0.212, F 0.175)] [G loss: -0.145]\n",
      "Epoch 1912 -- [D loss: -0.015(R -0.196, F 0.167)] [G loss: -0.114]\n",
      "Epoch 1913 -- [D loss: -0.016(R -0.186, F 0.154)] [G loss: -0.101]\n",
      "Epoch 1914 -- [D loss: -0.026(R -0.176, F 0.125)] [G loss: -0.100]\n",
      "Epoch 1915 -- [D loss: -0.026(R -0.175, F 0.123)] [G loss: -0.096]\n",
      "Epoch 1916 -- [D loss: -0.027(R -0.180, F 0.127)] [G loss: -0.076]\n",
      "Epoch 1917 -- [D loss: -0.026(R -0.167, F 0.116)] [G loss: -0.068]\n",
      "Epoch 1918 -- [D loss: -0.035(R -0.170, F 0.100)] [G loss: -0.076]\n",
      "Epoch 1919 -- [D loss: -0.037(R -0.183, F 0.109)] [G loss: -0.093]\n",
      "Epoch 1920 -- [D loss: -0.031(R -0.164, F 0.102)] [G loss: -0.106]\n",
      "Epoch 1921 -- [D loss: -0.020(R -0.161, F 0.122)] [G loss: -0.090]\n",
      "Epoch 1922 -- [D loss: -0.021(R -0.146, F 0.103)] [G loss: -0.091]\n",
      "Epoch 1923 -- [D loss: -0.025(R -0.149, F 0.099)] [G loss: -0.107]\n",
      "Epoch 1924 -- [D loss: -0.040(R -0.179, F 0.099)] [G loss: -0.140]\n",
      "Epoch 1925 -- [D loss: -0.029(R -0.180, F 0.122)] [G loss: -0.144]\n",
      "Epoch 1926 -- [D loss: -0.012(R -0.181, F 0.158)] [G loss: -0.126]\n",
      "Epoch 1927 -- [D loss: -0.012(R -0.182, F 0.157)] [G loss: -0.114]\n",
      "Epoch 1928 -- [D loss: -0.011(R -0.176, F 0.155)] [G loss: -0.113]\n",
      "Epoch 1929 -- [D loss: -0.012(R -0.188, F 0.165)] [G loss: -0.120]\n",
      "Epoch 1930 -- [D loss: -0.015(R -0.197, F 0.166)] [G loss: -0.145]\n",
      "Epoch 1931 -- [D loss: -0.019(R -0.211, F 0.172)] [G loss: -0.163]\n",
      "Epoch 1932 -- [D loss: -0.015(R -0.230, F 0.199)] [G loss: -0.169]\n",
      "Epoch 1933 -- [D loss: -0.016(R -0.240, F 0.209)] [G loss: -0.183]\n",
      "Epoch 1934 -- [D loss: -0.017(R -0.251, F 0.216)] [G loss: -0.181]\n",
      "Epoch 1935 -- [D loss: -0.015(R -0.263, F 0.232)] [G loss: -0.196]\n",
      "Epoch 1936 -- [D loss: -0.016(R -0.258, F 0.225)] [G loss: -0.198]\n",
      "Epoch 1937 -- [D loss: -0.017(R -0.269, F 0.235)] [G loss: -0.194]\n",
      "Epoch 1938 -- [D loss: -0.021(R -0.272, F 0.229)] [G loss: -0.195]\n",
      "Epoch 1939 -- [D loss: -0.024(R -0.269, F 0.221)] [G loss: -0.194]\n",
      "Epoch 1940 -- [D loss: -0.020(R -0.290, F 0.251)] [G loss: -0.209]\n",
      "Epoch 1941 -- [D loss: -0.022(R -0.291, F 0.247)] [G loss: -0.215]\n",
      "Epoch 1942 -- [D loss: -0.023(R -0.301, F 0.256)] [G loss: -0.226]\n",
      "Epoch 1943 -- [D loss: -0.018(R -0.310, F 0.275)] [G loss: -0.250]\n",
      "Epoch 1944 -- [D loss: -0.009(R -0.302, F 0.283)] [G loss: -0.261]\n",
      "Epoch 1945 -- [D loss: -0.019(R -0.322, F 0.284)] [G loss: -0.279]\n",
      "Epoch 1946 -- [D loss: -0.027(R -0.322, F 0.269)] [G loss: -0.307]\n",
      "Epoch 1947 -- [D loss: -0.019(R -0.305, F 0.267)] [G loss: -0.312]\n",
      "Epoch 1948 -- [D loss: -0.006(R -0.303, F 0.291)] [G loss: -0.289]\n",
      "Epoch 1949 -- [D loss: -0.006(R -0.295, F 0.283)] [G loss: -0.248]\n",
      "Epoch 1950 -- [D loss: -0.004(R -0.272, F 0.263)] [G loss: -0.221]\n",
      "Epoch 1951 -- [D loss: -0.009(R -0.262, F 0.244)] [G loss: -0.199]\n",
      "Epoch 1952 -- [D loss: -0.025(R -0.247, F 0.196)] [G loss: -0.184]\n",
      "Epoch 1953 -- [D loss: -0.012(R -0.220, F 0.197)] [G loss: -0.146]\n",
      "Epoch 1954 -- [D loss: -0.014(R -0.193, F 0.165)] [G loss: -0.116]\n",
      "Epoch 1955 -- [D loss: -0.017(R -0.182, F 0.147)] [G loss: -0.091]\n",
      "Epoch 1956 -- [D loss: -0.017(R -0.176, F 0.142)] [G loss: -0.076]\n",
      "Epoch 1957 -- [D loss: -0.023(R -0.157, F 0.111)] [G loss: -0.067]\n",
      "Epoch 1958 -- [D loss: -0.017(R -0.150, F 0.117)] [G loss: -0.064]\n",
      "Epoch 1959 -- [D loss: -0.031(R -0.149, F 0.087)] [G loss: -0.068]\n",
      "Epoch 1960 -- [D loss: -0.017(R -0.139, F 0.105)] [G loss: -0.066]\n",
      "Epoch 1961 -- [D loss: -0.028(R -0.147, F 0.091)] [G loss: -0.073]\n",
      "Epoch 1962 -- [D loss: -0.024(R -0.148, F 0.101)] [G loss: -0.078]\n",
      "Epoch 1963 -- [D loss: -0.030(R -0.153, F 0.094)] [G loss: -0.091]\n",
      "Epoch 1964 -- [D loss: -0.018(R -0.158, F 0.122)] [G loss: -0.103]\n",
      "Epoch 1965 -- [D loss: -0.029(R -0.170, F 0.112)] [G loss: -0.112]\n",
      "Epoch 1966 -- [D loss: -0.015(R -0.160, F 0.130)] [G loss: -0.100]\n",
      "Epoch 1967 -- [D loss: -0.019(R -0.171, F 0.133)] [G loss: -0.122]\n",
      "Epoch 1968 -- [D loss: -0.028(R -0.186, F 0.130)] [G loss: -0.132]\n",
      "Epoch 1969 -- [D loss: -0.040(R -0.207, F 0.127)] [G loss: -0.156]\n",
      "Epoch 1970 -- [D loss: -0.006(R -0.187, F 0.174)] [G loss: -0.149]\n",
      "Epoch 1971 -- [D loss: -0.013(R -0.208, F 0.182)] [G loss: -0.153]\n",
      "Epoch 1972 -- [D loss: -0.008(R -0.218, F 0.201)] [G loss: -0.167]\n",
      "Epoch 1973 -- [D loss: -0.013(R -0.205, F 0.179)] [G loss: -0.185]\n",
      "Epoch 1974 -- [D loss: -0.027(R -0.241, F 0.187)] [G loss: -0.201]\n",
      "Epoch 1975 -- [D loss: -0.019(R -0.236, F 0.198)] [G loss: -0.193]\n",
      "Epoch 1976 -- [D loss: -0.018(R -0.244, F 0.209)] [G loss: -0.198]\n",
      "Epoch 1977 -- [D loss: -0.016(R -0.249, F 0.217)] [G loss: -0.207]\n",
      "Epoch 1978 -- [D loss: -0.019(R -0.271, F 0.232)] [G loss: -0.218]\n",
      "Epoch 1979 -- [D loss: -0.024(R -0.294, F 0.246)] [G loss: -0.203]\n",
      "Epoch 1980 -- [D loss: -0.023(R -0.300, F 0.254)] [G loss: -0.215]\n",
      "Epoch 1981 -- [D loss: -0.046(R -0.345, F 0.252)] [G loss: -0.231]\n",
      "Epoch 1982 -- [D loss: -0.020(R -0.340, F 0.300)] [G loss: -0.249]\n",
      "Epoch 1983 -- [D loss: -0.040(R -0.366, F 0.286)] [G loss: -0.268]\n",
      "Epoch 1984 -- [D loss: -0.036(R -0.386, F 0.314)] [G loss: -0.291]\n",
      "Epoch 1985 -- [D loss: -0.020(R -0.380, F 0.340)] [G loss: -0.305]\n",
      "Epoch 1986 -- [D loss: -0.032(R -0.390, F 0.325)] [G loss: -0.327]\n",
      "Epoch 1987 -- [D loss: -0.020(R -0.394, F 0.353)] [G loss: -0.345]\n",
      "Epoch 1988 -- [D loss: -0.027(R -0.389, F 0.335)] [G loss: -0.373]\n",
      "Epoch 1989 -- [D loss: -0.034(R -0.416, F 0.348)] [G loss: -0.386]\n",
      "Epoch 1990 -- [D loss: 0.004(R -0.343, F 0.350)] [G loss: -0.363]\n",
      "Epoch 1991 -- [D loss: 0.007(R -0.350, F 0.365)] [G loss: -0.322]\n",
      "Epoch 1992 -- [D loss: -0.009(R -0.337, F 0.319)] [G loss: -0.284]\n",
      "Epoch 1993 -- [D loss: 0.000(R -0.292, F 0.292)] [G loss: -0.276]\n",
      "Epoch 1994 -- [D loss: -0.005(R -0.275, F 0.264)] [G loss: -0.254]\n",
      "Epoch 1995 -- [D loss: 0.000(R -0.253, F 0.254)] [G loss: -0.211]\n",
      "Epoch 1996 -- [D loss: -0.005(R -0.236, F 0.226)] [G loss: -0.179]\n",
      "Epoch 1997 -- [D loss: -0.016(R -0.218, F 0.187)] [G loss: -0.146]\n",
      "Epoch 1998 -- [D loss: -0.015(R -0.199, F 0.169)] [G loss: -0.131]\n",
      "Epoch 1999 -- [D loss: -0.016(R -0.183, F 0.151)] [G loss: -0.098]\n",
      "Epoch 2000 -- [D loss: -0.020(R -0.162, F 0.121)] [G loss: -0.084]\n",
      "INFO:tensorflow:Assets written to: ram://d63bf61d-94db-4524-9405-2a20c25399fd/assets\n",
      "INFO:tensorflow:Assets written to: ram://223a9364-b020-4cd2-b77f-85188f0e5489/assets\n",
      "INFO:tensorflow:Assets written to: ram://dfa12f86-0b7f-43ee-9cfc-eb843ad88005/assets\n",
      "Epoch 2001 -- [D loss: -0.018(R -0.144, F 0.107)] [G loss: -0.058]\n",
      "Epoch 2002 -- [D loss: -0.025(R -0.140, F 0.090)] [G loss: -0.051]\n",
      "Epoch 2003 -- [D loss: -0.036(R -0.155, F 0.082)] [G loss: -0.044]\n",
      "Epoch 2004 -- [D loss: -0.020(R -0.120, F 0.080)] [G loss: -0.039]\n",
      "Epoch 2005 -- [D loss: -0.027(R -0.127, F 0.072)] [G loss: -0.039]\n",
      "Epoch 2006 -- [D loss: -0.030(R -0.126, F 0.066)] [G loss: -0.057]\n",
      "Epoch 2007 -- [D loss: -0.024(R -0.131, F 0.082)] [G loss: -0.075]\n",
      "Epoch 2008 -- [D loss: -0.021(R -0.139, F 0.098)] [G loss: -0.088]\n",
      "Epoch 2009 -- [D loss: -0.019(R -0.146, F 0.108)] [G loss: -0.111]\n",
      "Epoch 2010 -- [D loss: -0.015(R -0.168, F 0.138)] [G loss: -0.108]\n",
      "Epoch 2011 -- [D loss: -0.026(R -0.184, F 0.133)] [G loss: -0.093]\n",
      "Epoch 2012 -- [D loss: -0.032(R -0.187, F 0.122)] [G loss: -0.119]\n",
      "Epoch 2013 -- [D loss: -0.039(R -0.217, F 0.138)] [G loss: -0.149]\n",
      "Epoch 2014 -- [D loss: -0.021(R -0.226, F 0.184)] [G loss: -0.177]\n",
      "Epoch 2015 -- [D loss: -0.027(R -0.251, F 0.197)] [G loss: -0.181]\n",
      "Epoch 2016 -- [D loss: -0.019(R -0.257, F 0.219)] [G loss: -0.193]\n",
      "Epoch 2017 -- [D loss: -0.019(R -0.268, F 0.231)] [G loss: -0.207]\n",
      "Epoch 2018 -- [D loss: -0.026(R -0.264, F 0.213)] [G loss: -0.204]\n",
      "Epoch 2019 -- [D loss: -0.034(R -0.285, F 0.217)] [G loss: -0.247]\n",
      "Epoch 2020 -- [D loss: -0.014(R -0.288, F 0.261)] [G loss: -0.246]\n",
      "Epoch 2021 -- [D loss: -0.009(R -0.293, F 0.274)] [G loss: -0.252]\n",
      "Epoch 2022 -- [D loss: -0.031(R -0.314, F 0.251)] [G loss: -0.246]\n",
      "Epoch 2023 -- [D loss: -0.022(R -0.335, F 0.292)] [G loss: -0.265]\n",
      "Epoch 2024 -- [D loss: -0.023(R -0.343, F 0.298)] [G loss: -0.278]\n",
      "Epoch 2025 -- [D loss: -0.015(R -0.337, F 0.308)] [G loss: -0.272]\n",
      "Epoch 2026 -- [D loss: -0.013(R -0.336, F 0.311)] [G loss: -0.275]\n",
      "Epoch 2027 -- [D loss: -0.014(R -0.332, F 0.303)] [G loss: -0.270]\n",
      "Epoch 2028 -- [D loss: -0.014(R -0.341, F 0.314)] [G loss: -0.280]\n",
      "Epoch 2029 -- [D loss: -0.009(R -0.339, F 0.321)] [G loss: -0.275]\n",
      "Epoch 2030 -- [D loss: -0.016(R -0.337, F 0.306)] [G loss: -0.256]\n",
      "Epoch 2031 -- [D loss: -0.019(R -0.334, F 0.296)] [G loss: -0.260]\n",
      "Epoch 2032 -- [D loss: -0.022(R -0.342, F 0.298)] [G loss: -0.268]\n",
      "Epoch 2033 -- [D loss: -0.016(R -0.326, F 0.293)] [G loss: -0.264]\n",
      "Epoch 2034 -- [D loss: -0.000(R -0.302, F 0.301)] [G loss: -0.246]\n",
      "Epoch 2035 -- [D loss: -0.007(R -0.275, F 0.260)] [G loss: -0.222]\n",
      "Epoch 2036 -- [D loss: -0.008(R -0.263, F 0.247)] [G loss: -0.202]\n",
      "Epoch 2037 -- [D loss: -0.019(R -0.243, F 0.206)] [G loss: -0.176]\n",
      "Epoch 2038 -- [D loss: -0.018(R -0.219, F 0.183)] [G loss: -0.142]\n",
      "Epoch 2039 -- [D loss: -0.033(R -0.220, F 0.154)] [G loss: -0.124]\n",
      "Epoch 2040 -- [D loss: -0.024(R -0.191, F 0.143)] [G loss: -0.099]\n",
      "Epoch 2041 -- [D loss: -0.030(R -0.176, F 0.117)] [G loss: -0.084]\n",
      "Epoch 2042 -- [D loss: -0.018(R -0.165, F 0.129)] [G loss: -0.077]\n",
      "Epoch 2043 -- [D loss: -0.023(R -0.146, F 0.100)] [G loss: -0.065]\n",
      "Epoch 2044 -- [D loss: -0.014(R -0.142, F 0.114)] [G loss: -0.080]\n",
      "Epoch 2045 -- [D loss: -0.010(R -0.145, F 0.126)] [G loss: -0.080]\n",
      "Epoch 2046 -- [D loss: -0.006(R -0.151, F 0.140)] [G loss: -0.090]\n",
      "Epoch 2047 -- [D loss: -0.006(R -0.150, F 0.138)] [G loss: -0.093]\n",
      "Epoch 2048 -- [D loss: -0.020(R -0.182, F 0.142)] [G loss: -0.108]\n",
      "Epoch 2049 -- [D loss: -0.019(R -0.178, F 0.139)] [G loss: -0.107]\n",
      "Epoch 2050 -- [D loss: -0.028(R -0.205, F 0.149)] [G loss: -0.137]\n",
      "Epoch 2051 -- [D loss: -0.004(R -0.181, F 0.173)] [G loss: -0.153]\n",
      "Epoch 2052 -- [D loss: -0.006(R -0.208, F 0.197)] [G loss: -0.166]\n",
      "Epoch 2053 -- [D loss: -0.005(R -0.209, F 0.199)] [G loss: -0.174]\n",
      "Epoch 2054 -- [D loss: -0.004(R -0.204, F 0.197)] [G loss: -0.163]\n",
      "Epoch 2055 -- [D loss: -0.012(R -0.214, F 0.190)] [G loss: -0.151]\n",
      "Epoch 2056 -- [D loss: -0.017(R -0.207, F 0.173)] [G loss: -0.139]\n",
      "Epoch 2057 -- [D loss: -0.022(R -0.209, F 0.165)] [G loss: -0.132]\n",
      "Epoch 2058 -- [D loss: -0.030(R -0.242, F 0.182)] [G loss: -0.139]\n",
      "Epoch 2059 -- [D loss: -0.020(R -0.229, F 0.190)] [G loss: -0.135]\n",
      "Epoch 2060 -- [D loss: -0.028(R -0.236, F 0.180)] [G loss: -0.147]\n",
      "Epoch 2061 -- [D loss: -0.032(R -0.244, F 0.180)] [G loss: -0.172]\n",
      "Epoch 2062 -- [D loss: -0.020(R -0.225, F 0.186)] [G loss: -0.193]\n",
      "Epoch 2063 -- [D loss: -0.020(R -0.258, F 0.218)] [G loss: -0.215]\n",
      "Epoch 2064 -- [D loss: -0.022(R -0.272, F 0.227)] [G loss: -0.214]\n",
      "Epoch 2065 -- [D loss: -0.023(R -0.277, F 0.231)] [G loss: -0.199]\n",
      "Epoch 2066 -- [D loss: -0.025(R -0.286, F 0.236)] [G loss: -0.211]\n",
      "Epoch 2067 -- [D loss: -0.031(R -0.297, F 0.234)] [G loss: -0.228]\n",
      "Epoch 2068 -- [D loss: -0.019(R -0.291, F 0.254)] [G loss: -0.221]\n",
      "Epoch 2069 -- [D loss: -0.018(R -0.311, F 0.274)] [G loss: -0.240]\n",
      "Epoch 2070 -- [D loss: -0.008(R -0.296, F 0.279)] [G loss: -0.233]\n",
      "Epoch 2071 -- [D loss: -0.016(R -0.306, F 0.275)] [G loss: -0.249]\n",
      "Epoch 2072 -- [D loss: -0.020(R -0.314, F 0.275)] [G loss: -0.249]\n",
      "Epoch 2073 -- [D loss: -0.034(R -0.351, F 0.283)] [G loss: -0.262]\n",
      "Epoch 2074 -- [D loss: -0.022(R -0.355, F 0.311)] [G loss: -0.285]\n",
      "Epoch 2075 -- [D loss: 0.001(R -0.341, F 0.342)] [G loss: -0.291]\n",
      "Epoch 2076 -- [D loss: -0.014(R -0.342, F 0.315)] [G loss: -0.269]\n",
      "Epoch 2077 -- [D loss: 0.005(R -0.306, F 0.316)] [G loss: -0.277]\n",
      "Epoch 2078 -- [D loss: -0.027(R -0.326, F 0.272)] [G loss: -0.278]\n",
      "Epoch 2079 -- [D loss: -0.023(R -0.334, F 0.289)] [G loss: -0.281]\n",
      "Epoch 2080 -- [D loss: -0.011(R -0.305, F 0.282)] [G loss: -0.259]\n",
      "Epoch 2081 -- [D loss: -0.005(R -0.284, F 0.273)] [G loss: -0.223]\n",
      "Epoch 2082 -- [D loss: -0.015(R -0.248, F 0.219)] [G loss: -0.159]\n",
      "Epoch 2083 -- [D loss: -0.024(R -0.226, F 0.178)] [G loss: -0.116]\n",
      "Epoch 2084 -- [D loss: -0.027(R -0.210, F 0.157)] [G loss: -0.107]\n",
      "Epoch 2085 -- [D loss: -0.034(R -0.189, F 0.121)] [G loss: -0.111]\n",
      "Epoch 2086 -- [D loss: -0.028(R -0.183, F 0.126)] [G loss: -0.091]\n",
      "Epoch 2087 -- [D loss: -0.028(R -0.178, F 0.122)] [G loss: -0.076]\n",
      "Epoch 2088 -- [D loss: -0.026(R -0.160, F 0.108)] [G loss: -0.078]\n",
      "Epoch 2089 -- [D loss: -0.021(R -0.157, F 0.115)] [G loss: -0.068]\n",
      "Epoch 2090 -- [D loss: -0.027(R -0.171, F 0.117)] [G loss: -0.078]\n",
      "Epoch 2091 -- [D loss: -0.020(R -0.162, F 0.122)] [G loss: -0.086]\n",
      "Epoch 2092 -- [D loss: -0.014(R -0.157, F 0.129)] [G loss: -0.100]\n",
      "Epoch 2093 -- [D loss: -0.006(R -0.149, F 0.137)] [G loss: -0.101]\n",
      "Epoch 2094 -- [D loss: -0.019(R -0.164, F 0.126)] [G loss: -0.112]\n",
      "Epoch 2095 -- [D loss: -0.017(R -0.169, F 0.135)] [G loss: -0.116]\n",
      "Epoch 2096 -- [D loss: -0.015(R -0.173, F 0.143)] [G loss: -0.111]\n",
      "Epoch 2097 -- [D loss: -0.013(R -0.175, F 0.150)] [G loss: -0.105]\n",
      "Epoch 2098 -- [D loss: -0.013(R -0.176, F 0.150)] [G loss: -0.103]\n",
      "Epoch 2099 -- [D loss: -0.028(R -0.181, F 0.125)] [G loss: -0.109]\n",
      "Epoch 2100 -- [D loss: -0.016(R -0.182, F 0.149)] [G loss: -0.109]\n",
      "INFO:tensorflow:Assets written to: ram://989e52a6-5b70-4eb7-93e7-926b40a5a4a4/assets\n",
      "INFO:tensorflow:Assets written to: ram://31183260-f219-446f-b71d-b440df24cb3f/assets\n",
      "INFO:tensorflow:Assets written to: ram://b7c051df-83a3-4c9b-90ab-92711e620512/assets\n",
      "Epoch 2101 -- [D loss: -0.016(R -0.173, F 0.141)] [G loss: -0.129]\n",
      "Epoch 2102 -- [D loss: -0.026(R -0.186, F 0.134)] [G loss: -0.137]\n",
      "Epoch 2103 -- [D loss: -0.012(R -0.177, F 0.152)] [G loss: -0.131]\n",
      "Epoch 2104 -- [D loss: -0.013(R -0.182, F 0.156)] [G loss: -0.137]\n",
      "Epoch 2105 -- [D loss: -0.018(R -0.196, F 0.160)] [G loss: -0.125]\n",
      "Epoch 2106 -- [D loss: -0.024(R -0.205, F 0.157)] [G loss: -0.125]\n",
      "Epoch 2107 -- [D loss: -0.020(R -0.199, F 0.158)] [G loss: -0.147]\n",
      "Epoch 2108 -- [D loss: -0.029(R -0.223, F 0.164)] [G loss: -0.184]\n",
      "Epoch 2109 -- [D loss: -0.040(R -0.258, F 0.177)] [G loss: -0.206]\n",
      "Epoch 2110 -- [D loss: -0.016(R -0.244, F 0.211)] [G loss: -0.211]\n",
      "Epoch 2111 -- [D loss: -0.008(R -0.265, F 0.249)] [G loss: -0.199]\n",
      "Epoch 2112 -- [D loss: -0.019(R -0.272, F 0.235)] [G loss: -0.181]\n",
      "Epoch 2113 -- [D loss: -0.018(R -0.268, F 0.231)] [G loss: -0.193]\n",
      "Epoch 2114 -- [D loss: -0.034(R -0.287, F 0.220)] [G loss: -0.192]\n",
      "Epoch 2115 -- [D loss: -0.035(R -0.313, F 0.242)] [G loss: -0.197]\n",
      "Epoch 2116 -- [D loss: -0.026(R -0.305, F 0.254)] [G loss: -0.220]\n",
      "Epoch 2117 -- [D loss: -0.023(R -0.310, F 0.264)] [G loss: -0.235]\n",
      "Epoch 2118 -- [D loss: -0.019(R -0.329, F 0.291)] [G loss: -0.248]\n",
      "Epoch 2119 -- [D loss: -0.021(R -0.332, F 0.290)] [G loss: -0.260]\n",
      "Epoch 2120 -- [D loss: -0.009(R -0.322, F 0.304)] [G loss: -0.273]\n",
      "Epoch 2121 -- [D loss: -0.015(R -0.329, F 0.300)] [G loss: -0.271]\n",
      "Epoch 2122 -- [D loss: -0.038(R -0.333, F 0.257)] [G loss: -0.286]\n",
      "Epoch 2123 -- [D loss: 0.003(R -0.305, F 0.312)] [G loss: -0.272]\n",
      "Epoch 2124 -- [D loss: -0.011(R -0.312, F 0.290)] [G loss: -0.258]\n",
      "Epoch 2125 -- [D loss: -0.011(R -0.307, F 0.284)] [G loss: -0.239]\n",
      "Epoch 2126 -- [D loss: -0.005(R -0.285, F 0.275)] [G loss: -0.235]\n",
      "Epoch 2127 -- [D loss: -0.007(R -0.273, F 0.260)] [G loss: -0.220]\n",
      "Epoch 2128 -- [D loss: -0.005(R -0.258, F 0.248)] [G loss: -0.201]\n",
      "Epoch 2129 -- [D loss: -0.011(R -0.242, F 0.221)] [G loss: -0.189]\n",
      "Epoch 2130 -- [D loss: -0.010(R -0.231, F 0.210)] [G loss: -0.153]\n",
      "Epoch 2131 -- [D loss: -0.019(R -0.216, F 0.178)] [G loss: -0.132]\n",
      "Epoch 2132 -- [D loss: -0.022(R -0.188, F 0.143)] [G loss: -0.103]\n",
      "Epoch 2133 -- [D loss: -0.033(R -0.188, F 0.122)] [G loss: -0.096]\n",
      "Epoch 2134 -- [D loss: -0.029(R -0.166, F 0.108)] [G loss: -0.069]\n",
      "Epoch 2135 -- [D loss: -0.033(R -0.154, F 0.088)] [G loss: -0.065]\n",
      "Epoch 2136 -- [D loss: -0.014(R -0.127, F 0.099)] [G loss: -0.060]\n",
      "Epoch 2137 -- [D loss: -0.034(R -0.138, F 0.070)] [G loss: -0.077]\n",
      "Epoch 2138 -- [D loss: -0.026(R -0.147, F 0.095)] [G loss: -0.088]\n",
      "Epoch 2139 -- [D loss: -0.033(R -0.151, F 0.085)] [G loss: -0.073]\n",
      "Epoch 2140 -- [D loss: -0.022(R -0.123, F 0.079)] [G loss: -0.040]\n",
      "Epoch 2141 -- [D loss: -0.022(R -0.125, F 0.081)] [G loss: -0.048]\n",
      "Epoch 2142 -- [D loss: -0.021(R -0.120, F 0.078)] [G loss: -0.049]\n",
      "Epoch 2143 -- [D loss: -0.022(R -0.130, F 0.086)] [G loss: -0.051]\n",
      "Epoch 2144 -- [D loss: -0.010(R -0.133, F 0.113)] [G loss: -0.071]\n",
      "Epoch 2145 -- [D loss: -0.017(R -0.143, F 0.110)] [G loss: -0.090]\n",
      "Epoch 2146 -- [D loss: -0.018(R -0.149, F 0.114)] [G loss: -0.097]\n",
      "Epoch 2147 -- [D loss: -0.005(R -0.147, F 0.137)] [G loss: -0.098]\n",
      "Epoch 2148 -- [D loss: -0.005(R -0.149, F 0.139)] [G loss: -0.112]\n",
      "Epoch 2149 -- [D loss: -0.008(R -0.163, F 0.148)] [G loss: -0.110]\n",
      "Epoch 2150 -- [D loss: -0.018(R -0.180, F 0.144)] [G loss: -0.119]\n",
      "Epoch 2151 -- [D loss: -0.012(R -0.184, F 0.160)] [G loss: -0.131]\n",
      "Epoch 2152 -- [D loss: -0.016(R -0.205, F 0.172)] [G loss: -0.147]\n",
      "Epoch 2153 -- [D loss: -0.016(R -0.220, F 0.188)] [G loss: -0.157]\n",
      "Epoch 2154 -- [D loss: -0.019(R -0.234, F 0.195)] [G loss: -0.172]\n",
      "Epoch 2155 -- [D loss: -0.011(R -0.241, F 0.220)] [G loss: -0.187]\n",
      "Epoch 2156 -- [D loss: -0.008(R -0.253, F 0.236)] [G loss: -0.194]\n",
      "Epoch 2157 -- [D loss: -0.014(R -0.270, F 0.242)] [G loss: -0.199]\n",
      "Epoch 2158 -- [D loss: -0.010(R -0.256, F 0.236)] [G loss: -0.194]\n",
      "Epoch 2159 -- [D loss: -0.021(R -0.288, F 0.247)] [G loss: -0.207]\n",
      "Epoch 2160 -- [D loss: -0.030(R -0.305, F 0.246)] [G loss: -0.209]\n",
      "Epoch 2161 -- [D loss: -0.011(R -0.295, F 0.274)] [G loss: -0.221]\n",
      "Epoch 2162 -- [D loss: -0.032(R -0.311, F 0.248)] [G loss: -0.227]\n",
      "Epoch 2163 -- [D loss: -0.026(R -0.303, F 0.252)] [G loss: -0.238]\n",
      "Epoch 2164 -- [D loss: -0.041(R -0.356, F 0.274)] [G loss: -0.256]\n",
      "Epoch 2165 -- [D loss: -0.013(R -0.337, F 0.312)] [G loss: -0.274]\n",
      "Epoch 2166 -- [D loss: -0.012(R -0.339, F 0.314)] [G loss: -0.287]\n",
      "Epoch 2167 -- [D loss: -0.017(R -0.339, F 0.305)] [G loss: -0.295]\n",
      "Epoch 2168 -- [D loss: -0.014(R -0.329, F 0.302)] [G loss: -0.294]\n",
      "Epoch 2169 -- [D loss: -0.002(R -0.317, F 0.313)] [G loss: -0.296]\n",
      "Epoch 2170 -- [D loss: -0.010(R -0.326, F 0.306)] [G loss: -0.294]\n",
      "Epoch 2171 -- [D loss: -0.002(R -0.313, F 0.308)] [G loss: -0.275]\n",
      "Epoch 2172 -- [D loss: -0.014(R -0.315, F 0.287)] [G loss: -0.267]\n",
      "Epoch 2173 -- [D loss: -0.008(R -0.282, F 0.267)] [G loss: -0.261]\n",
      "Epoch 2174 -- [D loss: -0.005(R -0.276, F 0.265)] [G loss: -0.242]\n",
      "Epoch 2175 -- [D loss: 0.000(R -0.251, F 0.252)] [G loss: -0.205]\n",
      "Epoch 2176 -- [D loss: -0.012(R -0.247, F 0.224)] [G loss: -0.172]\n",
      "Epoch 2177 -- [D loss: -0.023(R -0.225, F 0.178)] [G loss: -0.130]\n",
      "Epoch 2178 -- [D loss: -0.023(R -0.203, F 0.157)] [G loss: -0.105]\n",
      "Epoch 2179 -- [D loss: -0.036(R -0.192, F 0.121)] [G loss: -0.075]\n",
      "Epoch 2180 -- [D loss: -0.036(R -0.171, F 0.099)] [G loss: -0.065]\n",
      "Epoch 2181 -- [D loss: -0.032(R -0.148, F 0.085)] [G loss: -0.052]\n",
      "Epoch 2182 -- [D loss: -0.025(R -0.148, F 0.099)] [G loss: -0.052]\n",
      "Epoch 2183 -- [D loss: -0.025(R -0.126, F 0.076)] [G loss: -0.054]\n",
      "Epoch 2184 -- [D loss: -0.020(R -0.124, F 0.083)] [G loss: -0.066]\n",
      "Epoch 2185 -- [D loss: -0.025(R -0.133, F 0.082)] [G loss: -0.083]\n",
      "Epoch 2186 -- [D loss: -0.009(R -0.133, F 0.114)] [G loss: -0.093]\n",
      "Epoch 2187 -- [D loss: -0.015(R -0.136, F 0.105)] [G loss: -0.090]\n",
      "Epoch 2188 -- [D loss: -0.012(R -0.137, F 0.113)] [G loss: -0.079]\n",
      "Epoch 2189 -- [D loss: -0.021(R -0.143, F 0.101)] [G loss: -0.076]\n",
      "Epoch 2190 -- [D loss: -0.011(R -0.134, F 0.112)] [G loss: -0.079]\n",
      "Epoch 2191 -- [D loss: -0.022(R -0.155, F 0.111)] [G loss: -0.075]\n",
      "Epoch 2192 -- [D loss: -0.023(R -0.158, F 0.113)] [G loss: -0.084]\n",
      "Epoch 2193 -- [D loss: -0.031(R -0.157, F 0.096)] [G loss: -0.076]\n",
      "Epoch 2194 -- [D loss: -0.027(R -0.178, F 0.124)] [G loss: -0.100]\n",
      "Epoch 2195 -- [D loss: -0.037(R -0.188, F 0.115)] [G loss: -0.114]\n",
      "Epoch 2196 -- [D loss: -0.027(R -0.196, F 0.142)] [G loss: -0.121]\n",
      "Epoch 2197 -- [D loss: -0.011(R -0.203, F 0.182)] [G loss: -0.147]\n",
      "Epoch 2198 -- [D loss: -0.024(R -0.218, F 0.171)] [G loss: -0.165]\n",
      "Epoch 2199 -- [D loss: -0.015(R -0.230, F 0.201)] [G loss: -0.199]\n",
      "Epoch 2200 -- [D loss: -0.017(R -0.253, F 0.220)] [G loss: -0.229]\n",
      "INFO:tensorflow:Assets written to: ram://2090e555-61dd-4620-8680-fba801bef7ae/assets\n",
      "INFO:tensorflow:Assets written to: ram://7248eebe-5ddd-41b2-9b61-2559bc8ca795/assets\n",
      "INFO:tensorflow:Assets written to: ram://e4c871c5-aea8-489b-afe1-9c9823429150/assets\n",
      "Epoch 2201 -- [D loss: -0.010(R -0.241, F 0.221)] [G loss: -0.256]\n",
      "Epoch 2202 -- [D loss: -0.002(R -0.264, F 0.259)] [G loss: -0.239]\n",
      "Epoch 2203 -- [D loss: -0.009(R -0.264, F 0.247)] [G loss: -0.240]\n",
      "Epoch 2204 -- [D loss: -0.012(R -0.278, F 0.254)] [G loss: -0.223]\n",
      "Epoch 2205 -- [D loss: -0.020(R -0.290, F 0.250)] [G loss: -0.215]\n",
      "Epoch 2206 -- [D loss: -0.024(R -0.300, F 0.253)] [G loss: -0.208]\n",
      "Epoch 2207 -- [D loss: -0.024(R -0.313, F 0.264)] [G loss: -0.215]\n",
      "Epoch 2208 -- [D loss: -0.032(R -0.328, F 0.265)] [G loss: -0.228]\n",
      "Epoch 2209 -- [D loss: -0.028(R -0.334, F 0.278)] [G loss: -0.242]\n",
      "Epoch 2210 -- [D loss: -0.020(R -0.330, F 0.290)] [G loss: -0.262]\n",
      "Epoch 2211 -- [D loss: -0.043(R -0.363, F 0.276)] [G loss: -0.285]\n",
      "Epoch 2212 -- [D loss: -0.054(R -0.382, F 0.274)] [G loss: -0.322]\n",
      "Epoch 2213 -- [D loss: -0.020(R -0.364, F 0.325)] [G loss: -0.364]\n",
      "Epoch 2214 -- [D loss: -0.036(R -0.421, F 0.349)] [G loss: -0.388]\n",
      "Epoch 2215 -- [D loss: 0.019(R -0.383, F 0.421)] [G loss: -0.366]\n",
      "Epoch 2216 -- [D loss: -0.001(R -0.361, F 0.359)] [G loss: -0.306]\n",
      "Epoch 2217 -- [D loss: -0.016(R -0.347, F 0.315)] [G loss: -0.270]\n",
      "Epoch 2218 -- [D loss: -0.006(R -0.318, F 0.307)] [G loss: -0.264]\n",
      "Epoch 2219 -- [D loss: -0.013(R -0.291, F 0.266)] [G loss: -0.269]\n",
      "Epoch 2220 -- [D loss: -0.031(R -0.325, F 0.263)] [G loss: -0.270]\n",
      "Epoch 2221 -- [D loss: -0.037(R -0.314, F 0.240)] [G loss: -0.279]\n",
      "Epoch 2222 -- [D loss: -0.029(R -0.304, F 0.247)] [G loss: -0.252]\n",
      "Epoch 2223 -- [D loss: -0.010(R -0.257, F 0.236)] [G loss: -0.210]\n",
      "Epoch 2224 -- [D loss: -0.007(R -0.224, F 0.210)] [G loss: -0.146]\n",
      "Epoch 2225 -- [D loss: -0.025(R -0.200, F 0.149)] [G loss: -0.108]\n",
      "Epoch 2226 -- [D loss: -0.028(R -0.193, F 0.138)] [G loss: -0.097]\n",
      "Epoch 2227 -- [D loss: -0.033(R -0.176, F 0.111)] [G loss: -0.087]\n",
      "Epoch 2228 -- [D loss: -0.022(R -0.148, F 0.104)] [G loss: -0.058]\n",
      "Epoch 2229 -- [D loss: -0.032(R -0.141, F 0.077)] [G loss: -0.045]\n",
      "Epoch 2230 -- [D loss: -0.033(R -0.135, F 0.068)] [G loss: -0.046]\n",
      "Epoch 2231 -- [D loss: -0.059(R -0.160, F 0.042)] [G loss: -0.060]\n",
      "Epoch 2232 -- [D loss: -0.031(R -0.130, F 0.068)] [G loss: -0.077]\n",
      "Epoch 2233 -- [D loss: -0.029(R -0.165, F 0.107)] [G loss: -0.098]\n",
      "Epoch 2234 -- [D loss: -0.009(R -0.158, F 0.139)] [G loss: -0.107]\n",
      "Epoch 2235 -- [D loss: -0.038(R -0.172, F 0.096)] [G loss: -0.112]\n",
      "Epoch 2236 -- [D loss: -0.041(R -0.184, F 0.102)] [G loss: -0.125]\n",
      "Epoch 2237 -- [D loss: -0.045(R -0.198, F 0.108)] [G loss: -0.148]\n",
      "Epoch 2238 -- [D loss: -0.029(R -0.193, F 0.135)] [G loss: -0.168]\n",
      "Epoch 2239 -- [D loss: -0.047(R -0.203, F 0.109)] [G loss: -0.181]\n",
      "Epoch 2240 -- [D loss: -0.025(R -0.212, F 0.161)] [G loss: -0.196]\n",
      "Epoch 2241 -- [D loss: -0.018(R -0.225, F 0.189)] [G loss: -0.190]\n",
      "Epoch 2242 -- [D loss: -0.014(R -0.234, F 0.206)] [G loss: -0.197]\n",
      "Epoch 2243 -- [D loss: -0.010(R -0.237, F 0.218)] [G loss: -0.191]\n",
      "Epoch 2244 -- [D loss: -0.027(R -0.265, F 0.211)] [G loss: -0.186]\n",
      "Epoch 2245 -- [D loss: -0.016(R -0.259, F 0.228)] [G loss: -0.192]\n",
      "Epoch 2246 -- [D loss: -0.014(R -0.259, F 0.230)] [G loss: -0.198]\n",
      "Epoch 2247 -- [D loss: -0.030(R -0.301, F 0.241)] [G loss: -0.188]\n",
      "Epoch 2248 -- [D loss: -0.027(R -0.301, F 0.247)] [G loss: -0.190]\n",
      "Epoch 2249 -- [D loss: -0.026(R -0.306, F 0.253)] [G loss: -0.187]\n",
      "Epoch 2250 -- [D loss: -0.033(R -0.325, F 0.258)] [G loss: -0.186]\n",
      "Epoch 2251 -- [D loss: -0.016(R -0.301, F 0.269)] [G loss: -0.216]\n",
      "Epoch 2252 -- [D loss: -0.037(R -0.322, F 0.248)] [G loss: -0.241]\n",
      "Epoch 2253 -- [D loss: -0.040(R -0.305, F 0.224)] [G loss: -0.267]\n",
      "Epoch 2254 -- [D loss: -0.024(R -0.304, F 0.257)] [G loss: -0.287]\n",
      "Epoch 2255 -- [D loss: 0.004(R -0.302, F 0.311)] [G loss: -0.294]\n",
      "Epoch 2256 -- [D loss: -0.007(R -0.301, F 0.287)] [G loss: -0.285]\n",
      "Epoch 2257 -- [D loss: -0.006(R -0.309, F 0.297)] [G loss: -0.301]\n",
      "Epoch 2258 -- [D loss: 0.005(R -0.301, F 0.311)] [G loss: -0.307]\n",
      "Epoch 2259 -- [D loss: 0.002(R -0.309, F 0.312)] [G loss: -0.306]\n",
      "Epoch 2260 -- [D loss: 0.000(R -0.295, F 0.296)] [G loss: -0.286]\n",
      "Epoch 2261 -- [D loss: -0.004(R -0.299, F 0.291)] [G loss: -0.260]\n",
      "Epoch 2262 -- [D loss: -0.019(R -0.309, F 0.272)] [G loss: -0.221]\n",
      "Epoch 2263 -- [D loss: -0.018(R -0.287, F 0.250)] [G loss: -0.201]\n",
      "Epoch 2264 -- [D loss: -0.037(R -0.292, F 0.219)] [G loss: -0.190]\n",
      "Epoch 2265 -- [D loss: -0.045(R -0.316, F 0.225)] [G loss: -0.211]\n",
      "Epoch 2266 -- [D loss: -0.036(R -0.318, F 0.247)] [G loss: -0.225]\n",
      "Epoch 2267 -- [D loss: -0.026(R -0.320, F 0.267)] [G loss: -0.232]\n",
      "Epoch 2268 -- [D loss: -0.016(R -0.311, F 0.279)] [G loss: -0.222]\n",
      "Epoch 2269 -- [D loss: -0.027(R -0.301, F 0.248)] [G loss: -0.218]\n",
      "Epoch 2270 -- [D loss: -0.026(R -0.285, F 0.233)] [G loss: -0.209]\n",
      "Epoch 2271 -- [D loss: -0.021(R -0.284, F 0.243)] [G loss: -0.221]\n",
      "Epoch 2272 -- [D loss: -0.002(R -0.254, F 0.249)] [G loss: -0.214]\n",
      "Epoch 2273 -- [D loss: -0.012(R -0.245, F 0.220)] [G loss: -0.207]\n",
      "Epoch 2274 -- [D loss: -0.026(R -0.240, F 0.189)] [G loss: -0.213]\n",
      "Epoch 2275 -- [D loss: -0.022(R -0.238, F 0.194)] [G loss: -0.196]\n",
      "Epoch 2276 -- [D loss: -0.031(R -0.243, F 0.181)] [G loss: -0.213]\n",
      "Epoch 2277 -- [D loss: -0.013(R -0.208, F 0.181)] [G loss: -0.209]\n",
      "Epoch 2278 -- [D loss: -0.025(R -0.257, F 0.208)] [G loss: -0.204]\n",
      "Epoch 2279 -- [D loss: -0.023(R -0.232, F 0.185)] [G loss: -0.187]\n",
      "Epoch 2280 -- [D loss: -0.019(R -0.233, F 0.194)] [G loss: -0.180]\n",
      "Epoch 2281 -- [D loss: -0.020(R -0.232, F 0.192)] [G loss: -0.167]\n",
      "Epoch 2282 -- [D loss: -0.026(R -0.243, F 0.192)] [G loss: -0.184]\n",
      "Epoch 2283 -- [D loss: -0.025(R -0.249, F 0.198)] [G loss: -0.172]\n",
      "Epoch 2284 -- [D loss: -0.023(R -0.240, F 0.193)] [G loss: -0.167]\n",
      "Epoch 2285 -- [D loss: -0.007(R -0.224, F 0.211)] [G loss: -0.178]\n",
      "Epoch 2286 -- [D loss: 0.006(R -0.223, F 0.235)] [G loss: -0.182]\n",
      "Epoch 2287 -- [D loss: -0.008(R -0.241, F 0.225)] [G loss: -0.188]\n",
      "Epoch 2288 -- [D loss: -0.013(R -0.244, F 0.218)] [G loss: -0.176]\n",
      "Epoch 2289 -- [D loss: -0.065(R -0.280, F 0.149)] [G loss: -0.200]\n",
      "Epoch 2290 -- [D loss: -0.049(R -0.323, F 0.226)] [G loss: -0.219]\n",
      "Epoch 2291 -- [D loss: -0.005(R -0.273, F 0.263)] [G loss: -0.232]\n",
      "Epoch 2292 -- [D loss: -0.043(R -0.315, F 0.230)] [G loss: -0.246]\n",
      "Epoch 2293 -- [D loss: -0.037(R -0.339, F 0.265)] [G loss: -0.246]\n",
      "Epoch 2294 -- [D loss: -0.027(R -0.324, F 0.270)] [G loss: -0.235]\n",
      "Epoch 2295 -- [D loss: -0.026(R -0.331, F 0.279)] [G loss: -0.236]\n",
      "Epoch 2296 -- [D loss: -0.029(R -0.325, F 0.267)] [G loss: -0.242]\n",
      "Epoch 2297 -- [D loss: -0.024(R -0.317, F 0.268)] [G loss: -0.265]\n",
      "Epoch 2298 -- [D loss: -0.016(R -0.297, F 0.266)] [G loss: -0.270]\n",
      "Epoch 2299 -- [D loss: -0.021(R -0.298, F 0.256)] [G loss: -0.290]\n",
      "Epoch 2300 -- [D loss: -0.012(R -0.281, F 0.256)] [G loss: -0.272]\n",
      "INFO:tensorflow:Assets written to: ram://a2dc3655-c440-46e7-bb93-3b927e377f79/assets\n",
      "INFO:tensorflow:Assets written to: ram://4d2d7f4e-7426-416a-a418-0134b5677c7e/assets\n",
      "INFO:tensorflow:Assets written to: ram://f996074f-ee04-4b4c-b1ff-a3eeec692319/assets\n",
      "Epoch 2301 -- [D loss: -0.013(R -0.285, F 0.260)] [G loss: -0.271]\n",
      "Epoch 2302 -- [D loss: -0.007(R -0.297, F 0.284)] [G loss: -0.265]\n",
      "Epoch 2303 -- [D loss: -0.004(R -0.289, F 0.280)] [G loss: -0.246]\n",
      "Epoch 2304 -- [D loss: -0.017(R -0.291, F 0.257)] [G loss: -0.241]\n",
      "Epoch 2305 -- [D loss: -0.010(R -0.270, F 0.250)] [G loss: -0.245]\n",
      "Epoch 2306 -- [D loss: -0.011(R -0.283, F 0.261)] [G loss: -0.254]\n",
      "Epoch 2307 -- [D loss: -0.006(R -0.279, F 0.267)] [G loss: -0.258]\n",
      "Epoch 2308 -- [D loss: 0.002(R -0.277, F 0.281)] [G loss: -0.233]\n",
      "Epoch 2309 -- [D loss: -0.008(R -0.299, F 0.283)] [G loss: -0.246]\n",
      "Epoch 2310 -- [D loss: -0.005(R -0.299, F 0.289)] [G loss: -0.263]\n",
      "Epoch 2311 -- [D loss: -0.009(R -0.305, F 0.287)] [G loss: -0.261]\n",
      "Epoch 2312 -- [D loss: -0.013(R -0.316, F 0.289)] [G loss: -0.253]\n",
      "Epoch 2313 -- [D loss: -0.021(R -0.325, F 0.284)] [G loss: -0.254]\n",
      "Epoch 2314 -- [D loss: -0.016(R -0.332, F 0.300)] [G loss: -0.265]\n",
      "Epoch 2315 -- [D loss: -0.035(R -0.343, F 0.272)] [G loss: -0.271]\n",
      "Epoch 2316 -- [D loss: -0.022(R -0.358, F 0.313)] [G loss: -0.308]\n",
      "Epoch 2317 -- [D loss: -0.022(R -0.353, F 0.309)] [G loss: -0.351]\n",
      "Epoch 2318 -- [D loss: 0.001(R -0.402, F 0.403)] [G loss: -0.379]\n",
      "Epoch 2319 -- [D loss: -0.004(R -0.395, F 0.387)] [G loss: -0.344]\n",
      "Epoch 2320 -- [D loss: 0.008(R -0.364, F 0.380)] [G loss: -0.315]\n",
      "Epoch 2321 -- [D loss: -0.010(R -0.339, F 0.319)] [G loss: -0.235]\n",
      "Epoch 2322 -- [D loss: -0.034(R -0.314, F 0.246)] [G loss: -0.180]\n",
      "Epoch 2323 -- [D loss: -0.036(R -0.293, F 0.221)] [G loss: -0.203]\n",
      "Epoch 2324 -- [D loss: -0.061(R -0.302, F 0.179)] [G loss: -0.230]\n",
      "Epoch 2325 -- [D loss: -0.036(R -0.278, F 0.207)] [G loss: -0.233]\n",
      "Epoch 2326 -- [D loss: -0.034(R -0.264, F 0.197)] [G loss: -0.222]\n",
      "Epoch 2327 -- [D loss: -0.026(R -0.263, F 0.211)] [G loss: -0.212]\n",
      "Epoch 2328 -- [D loss: -0.004(R -0.246, F 0.238)] [G loss: -0.204]\n",
      "Epoch 2329 -- [D loss: -0.008(R -0.219, F 0.203)] [G loss: -0.172]\n",
      "Epoch 2330 -- [D loss: -0.007(R -0.215, F 0.201)] [G loss: -0.147]\n",
      "Epoch 2331 -- [D loss: -0.010(R -0.201, F 0.182)] [G loss: -0.138]\n",
      "Epoch 2332 -- [D loss: -0.006(R -0.187, F 0.175)] [G loss: -0.137]\n",
      "Epoch 2333 -- [D loss: -0.016(R -0.204, F 0.172)] [G loss: -0.147]\n",
      "Epoch 2334 -- [D loss: -0.011(R -0.202, F 0.180)] [G loss: -0.146]\n",
      "Epoch 2335 -- [D loss: -0.012(R -0.205, F 0.180)] [G loss: -0.130]\n",
      "Epoch 2336 -- [D loss: -0.029(R -0.225, F 0.168)] [G loss: -0.126]\n",
      "Epoch 2337 -- [D loss: -0.025(R -0.218, F 0.167)] [G loss: -0.138]\n",
      "Epoch 2338 -- [D loss: -0.015(R -0.210, F 0.179)] [G loss: -0.146]\n",
      "Epoch 2339 -- [D loss: -0.025(R -0.207, F 0.158)] [G loss: -0.145]\n",
      "Epoch 2340 -- [D loss: -0.011(R -0.199, F 0.176)] [G loss: -0.141]\n",
      "Epoch 2341 -- [D loss: -0.028(R -0.204, F 0.148)] [G loss: -0.142]\n",
      "Epoch 2342 -- [D loss: -0.036(R -0.223, F 0.151)] [G loss: -0.166]\n",
      "Epoch 2343 -- [D loss: -0.055(R -0.248, F 0.137)] [G loss: -0.201]\n",
      "Epoch 2344 -- [D loss: -0.054(R -0.306, F 0.199)] [G loss: -0.250]\n",
      "Epoch 2345 -- [D loss: -0.025(R -0.243, F 0.194)] [G loss: -0.269]\n",
      "Epoch 2346 -- [D loss: -0.006(R -0.274, F 0.263)] [G loss: -0.263]\n",
      "Epoch 2347 -- [D loss: -0.005(R -0.272, F 0.262)] [G loss: -0.212]\n",
      "Epoch 2348 -- [D loss: -0.027(R -0.276, F 0.221)] [G loss: -0.226]\n",
      "Epoch 2349 -- [D loss: -0.040(R -0.284, F 0.204)] [G loss: -0.266]\n",
      "Epoch 2350 -- [D loss: -0.036(R -0.305, F 0.232)] [G loss: -0.263]\n",
      "Epoch 2351 -- [D loss: -0.019(R -0.309, F 0.271)] [G loss: -0.239]\n",
      "Epoch 2352 -- [D loss: -0.015(R -0.299, F 0.269)] [G loss: -0.220]\n",
      "Epoch 2353 -- [D loss: -0.028(R -0.314, F 0.258)] [G loss: -0.226]\n",
      "Epoch 2354 -- [D loss: -0.037(R -0.341, F 0.267)] [G loss: -0.240]\n",
      "Epoch 2355 -- [D loss: -0.006(R -0.339, F 0.326)] [G loss: -0.278]\n",
      "Epoch 2356 -- [D loss: -0.004(R -0.351, F 0.343)] [G loss: -0.294]\n",
      "Epoch 2357 -- [D loss: -0.013(R -0.366, F 0.340)] [G loss: -0.331]\n",
      "Epoch 2358 -- [D loss: -0.005(R -0.357, F 0.346)] [G loss: -0.325]\n",
      "Epoch 2359 -- [D loss: -0.011(R -0.370, F 0.349)] [G loss: -0.332]\n",
      "Epoch 2360 -- [D loss: -0.028(R -0.406, F 0.350)] [G loss: -0.344]\n",
      "Epoch 2361 -- [D loss: -0.065(R -0.465, F 0.335)] [G loss: -0.371]\n",
      "Epoch 2362 -- [D loss: -0.027(R -0.448, F 0.393)] [G loss: -0.383]\n",
      "Epoch 2363 -- [D loss: 0.009(R -0.397, F 0.415)] [G loss: -0.395]\n",
      "Epoch 2364 -- [D loss: -0.001(R -0.411, F 0.408)] [G loss: -0.386]\n",
      "Epoch 2365 -- [D loss: -0.005(R -0.401, F 0.391)] [G loss: -0.354]\n",
      "Epoch 2366 -- [D loss: -0.009(R -0.386, F 0.368)] [G loss: -0.349]\n",
      "Epoch 2367 -- [D loss: -0.001(R -0.378, F 0.376)] [G loss: -0.340]\n",
      "Epoch 2368 -- [D loss: -0.019(R -0.382, F 0.343)] [G loss: -0.368]\n",
      "Epoch 2369 -- [D loss: -0.007(R -0.372, F 0.359)] [G loss: -0.349]\n",
      "Epoch 2370 -- [D loss: -0.012(R -0.350, F 0.326)] [G loss: -0.307]\n",
      "Epoch 2371 -- [D loss: -0.028(R -0.336, F 0.281)] [G loss: -0.256]\n",
      "Epoch 2372 -- [D loss: -0.015(R -0.292, F 0.262)] [G loss: -0.211]\n",
      "Epoch 2373 -- [D loss: -0.021(R -0.275, F 0.233)] [G loss: -0.186]\n",
      "Epoch 2374 -- [D loss: -0.019(R -0.248, F 0.210)] [G loss: -0.158]\n",
      "Epoch 2375 -- [D loss: -0.021(R -0.247, F 0.205)] [G loss: -0.142]\n",
      "Epoch 2376 -- [D loss: -0.038(R -0.228, F 0.153)] [G loss: -0.120]\n",
      "Epoch 2377 -- [D loss: -0.041(R -0.217, F 0.134)] [G loss: -0.138]\n",
      "Epoch 2378 -- [D loss: -0.046(R -0.204, F 0.112)] [G loss: -0.140]\n",
      "Epoch 2379 -- [D loss: -0.030(R -0.206, F 0.145)] [G loss: -0.148]\n",
      "Epoch 2380 -- [D loss: -0.017(R -0.172, F 0.139)] [G loss: -0.155]\n",
      "Epoch 2381 -- [D loss: -0.014(R -0.185, F 0.157)] [G loss: -0.177]\n",
      "Epoch 2382 -- [D loss: -0.013(R -0.162, F 0.135)] [G loss: -0.173]\n",
      "Epoch 2383 -- [D loss: -0.009(R -0.168, F 0.149)] [G loss: -0.164]\n",
      "Epoch 2384 -- [D loss: -0.019(R -0.158, F 0.120)] [G loss: -0.136]\n",
      "Epoch 2385 -- [D loss: -0.017(R -0.151, F 0.116)] [G loss: -0.103]\n",
      "Epoch 2386 -- [D loss: -0.025(R -0.144, F 0.095)] [G loss: -0.069]\n",
      "Epoch 2387 -- [D loss: -0.025(R -0.129, F 0.078)] [G loss: -0.048]\n",
      "Epoch 2388 -- [D loss: -0.035(R -0.129, F 0.060)] [G loss: -0.041]\n",
      "Epoch 2389 -- [D loss: -0.027(R -0.130, F 0.076)] [G loss: -0.059]\n",
      "Epoch 2390 -- [D loss: -0.028(R -0.165, F 0.109)] [G loss: -0.056]\n",
      "Epoch 2391 -- [D loss: -0.019(R -0.143, F 0.104)] [G loss: -0.058]\n",
      "Epoch 2392 -- [D loss: -0.025(R -0.169, F 0.120)] [G loss: -0.074]\n",
      "Epoch 2393 -- [D loss: -0.034(R -0.188, F 0.119)] [G loss: -0.098]\n",
      "Epoch 2394 -- [D loss: -0.013(R -0.182, F 0.155)] [G loss: -0.133]\n",
      "Epoch 2395 -- [D loss: -0.028(R -0.205, F 0.148)] [G loss: -0.157]\n",
      "Epoch 2396 -- [D loss: -0.020(R -0.232, F 0.191)] [G loss: -0.181]\n",
      "Epoch 2397 -- [D loss: -0.033(R -0.268, F 0.203)] [G loss: -0.211]\n",
      "Epoch 2398 -- [D loss: -0.010(R -0.228, F 0.209)] [G loss: -0.233]\n",
      "Epoch 2399 -- [D loss: -0.029(R -0.236, F 0.179)] [G loss: -0.258]\n",
      "Epoch 2400 -- [D loss: -0.005(R -0.281, F 0.270)] [G loss: -0.270]\n",
      "INFO:tensorflow:Assets written to: ram://4c95f4ef-7b5a-4a0a-96e6-1402c7838e38/assets\n",
      "INFO:tensorflow:Assets written to: ram://37fd832d-0a63-4908-b049-8c32a0f14093/assets\n",
      "INFO:tensorflow:Assets written to: ram://f12be69d-a9b0-4bb5-a503-2975aef1b07f/assets\n",
      "Epoch 2401 -- [D loss: -0.004(R -0.293, F 0.284)] [G loss: -0.267]\n",
      "Epoch 2402 -- [D loss: -0.022(R -0.329, F 0.285)] [G loss: -0.270]\n",
      "Epoch 2403 -- [D loss: -0.029(R -0.352, F 0.295)] [G loss: -0.265]\n",
      "Epoch 2404 -- [D loss: -0.024(R -0.351, F 0.302)] [G loss: -0.273]\n",
      "Epoch 2405 -- [D loss: -0.031(R -0.379, F 0.316)] [G loss: -0.284]\n",
      "Epoch 2406 -- [D loss: -0.024(R -0.379, F 0.330)] [G loss: -0.284]\n",
      "Epoch 2407 -- [D loss: -0.032(R -0.412, F 0.349)] [G loss: -0.310]\n",
      "Epoch 2408 -- [D loss: -0.006(R -0.395, F 0.382)] [G loss: -0.336]\n",
      "Epoch 2409 -- [D loss: -0.014(R -0.399, F 0.371)] [G loss: -0.352]\n",
      "Epoch 2410 -- [D loss: -0.008(R -0.394, F 0.378)] [G loss: -0.356]\n",
      "Epoch 2411 -- [D loss: -0.014(R -0.413, F 0.384)] [G loss: -0.344]\n",
      "Epoch 2412 -- [D loss: 0.015(R -0.395, F 0.424)] [G loss: -0.347]\n",
      "Epoch 2413 -- [D loss: 0.005(R -0.372, F 0.381)] [G loss: -0.362]\n",
      "Epoch 2414 -- [D loss: -0.001(R -0.379, F 0.376)] [G loss: -0.331]\n",
      "Epoch 2415 -- [D loss: -0.000(R -0.360, F 0.359)] [G loss: -0.333]\n",
      "Epoch 2416 -- [D loss: 0.002(R -0.331, F 0.336)] [G loss: -0.315]\n",
      "Epoch 2417 -- [D loss: 0.001(R -0.323, F 0.325)] [G loss: -0.284]\n",
      "Epoch 2418 -- [D loss: 0.010(R -0.287, F 0.308)] [G loss: -0.256]\n",
      "Epoch 2419 -- [D loss: 0.004(R -0.250, F 0.259)] [G loss: -0.235]\n",
      "Epoch 2420 -- [D loss: -0.034(R -0.273, F 0.205)] [G loss: -0.227]\n",
      "Epoch 2421 -- [D loss: -0.018(R -0.252, F 0.216)] [G loss: -0.215]\n",
      "Epoch 2422 -- [D loss: -0.028(R -0.246, F 0.190)] [G loss: -0.198]\n",
      "Epoch 2423 -- [D loss: -0.012(R -0.219, F 0.194)] [G loss: -0.164]\n",
      "Epoch 2424 -- [D loss: -0.026(R -0.201, F 0.149)] [G loss: -0.121]\n",
      "Epoch 2425 -- [D loss: -0.022(R -0.180, F 0.135)] [G loss: -0.087]\n",
      "Epoch 2426 -- [D loss: -0.031(R -0.167, F 0.104)] [G loss: -0.063]\n",
      "Epoch 2427 -- [D loss: -0.037(R -0.164, F 0.090)] [G loss: -0.076]\n",
      "Epoch 2428 -- [D loss: -0.018(R -0.152, F 0.115)] [G loss: -0.075]\n",
      "Epoch 2429 -- [D loss: -0.031(R -0.164, F 0.101)] [G loss: -0.069]\n",
      "Epoch 2430 -- [D loss: -0.024(R -0.149, F 0.100)] [G loss: -0.082]\n",
      "Epoch 2431 -- [D loss: -0.029(R -0.169, F 0.112)] [G loss: -0.080]\n",
      "Epoch 2432 -- [D loss: -0.028(R -0.161, F 0.106)] [G loss: -0.109]\n",
      "Epoch 2433 -- [D loss: -0.043(R -0.179, F 0.094)] [G loss: -0.144]\n",
      "Epoch 2434 -- [D loss: -0.038(R -0.187, F 0.111)] [G loss: -0.166]\n",
      "Epoch 2435 -- [D loss: -0.030(R -0.219, F 0.158)] [G loss: -0.196]\n",
      "Epoch 2436 -- [D loss: -0.018(R -0.211, F 0.174)] [G loss: -0.219]\n",
      "Epoch 2437 -- [D loss: -0.030(R -0.235, F 0.175)] [G loss: -0.247]\n",
      "Epoch 2438 -- [D loss: -0.014(R -0.265, F 0.237)] [G loss: -0.264]\n",
      "Epoch 2439 -- [D loss: -0.025(R -0.300, F 0.250)] [G loss: -0.284]\n",
      "Epoch 2440 -- [D loss: -0.020(R -0.319, F 0.278)] [G loss: -0.291]\n",
      "Epoch 2441 -- [D loss: 0.003(R -0.323, F 0.329)] [G loss: -0.289]\n",
      "Epoch 2442 -- [D loss: -0.010(R -0.358, F 0.339)] [G loss: -0.306]\n",
      "Epoch 2443 -- [D loss: -0.016(R -0.372, F 0.339)] [G loss: -0.303]\n",
      "Epoch 2444 -- [D loss: -0.016(R -0.384, F 0.352)] [G loss: -0.309]\n",
      "Epoch 2445 -- [D loss: -0.010(R -0.390, F 0.371)] [G loss: -0.331]\n",
      "Epoch 2446 -- [D loss: -0.033(R -0.422, F 0.357)] [G loss: -0.351]\n",
      "Epoch 2447 -- [D loss: -0.032(R -0.436, F 0.372)] [G loss: -0.350]\n",
      "Epoch 2448 -- [D loss: -0.031(R -0.428, F 0.367)] [G loss: -0.350]\n",
      "Epoch 2449 -- [D loss: -0.047(R -0.441, F 0.347)] [G loss: -0.365]\n",
      "Epoch 2450 -- [D loss: -0.049(R -0.506, F 0.408)] [G loss: -0.381]\n",
      "Epoch 2451 -- [D loss: -0.029(R -0.489, F 0.431)] [G loss: -0.399]\n",
      "Epoch 2452 -- [D loss: 0.002(R -0.482, F 0.485)] [G loss: -0.414]\n",
      "Epoch 2453 -- [D loss: -0.006(R -0.458, F 0.446)] [G loss: -0.395]\n",
      "Epoch 2454 -- [D loss: -0.004(R -0.452, F 0.443)] [G loss: -0.399]\n",
      "Epoch 2455 -- [D loss: 0.007(R -0.432, F 0.446)] [G loss: -0.407]\n",
      "Epoch 2456 -- [D loss: -0.022(R -0.434, F 0.389)] [G loss: -0.407]\n",
      "Epoch 2457 -- [D loss: -0.034(R -0.412, F 0.344)] [G loss: -0.426]\n",
      "Epoch 2458 -- [D loss: -0.021(R -0.407, F 0.364)] [G loss: -0.422]\n",
      "Epoch 2459 -- [D loss: -0.026(R -0.428, F 0.376)] [G loss: -0.403]\n",
      "Epoch 2460 -- [D loss: 0.003(R -0.405, F 0.411)] [G loss: -0.373]\n",
      "Epoch 2461 -- [D loss: -0.039(R -0.378, F 0.301)] [G loss: -0.344]\n",
      "Epoch 2462 -- [D loss: -0.005(R -0.333, F 0.322)] [G loss: -0.335]\n",
      "Epoch 2463 -- [D loss: -0.044(R -0.327, F 0.239)] [G loss: -0.359]\n",
      "Epoch 2464 -- [D loss: -0.050(R -0.328, F 0.229)] [G loss: -0.399]\n",
      "Epoch 2465 -- [D loss: 0.021(R -0.347, F 0.390)] [G loss: -0.390]\n",
      "Epoch 2466 -- [D loss: -0.010(R -0.317, F 0.298)] [G loss: -0.354]\n",
      "Epoch 2467 -- [D loss: 0.006(R -0.303, F 0.315)] [G loss: -0.293]\n",
      "Epoch 2468 -- [D loss: -0.001(R -0.273, F 0.271)] [G loss: -0.206]\n",
      "Epoch 2469 -- [D loss: -0.030(R -0.272, F 0.211)] [G loss: -0.122]\n",
      "Epoch 2470 -- [D loss: -0.070(R -0.300, F 0.159)] [G loss: -0.108]\n",
      "Epoch 2471 -- [D loss: -0.082(R -0.268, F 0.105)] [G loss: -0.114]\n",
      "Epoch 2472 -- [D loss: -0.065(R -0.322, F 0.192)] [G loss: -0.154]\n",
      "Epoch 2473 -- [D loss: -0.068(R -0.310, F 0.174)] [G loss: -0.186]\n",
      "Epoch 2474 -- [D loss: 0.013(R -0.286, F 0.311)] [G loss: -0.214]\n",
      "Epoch 2475 -- [D loss: -0.037(R -0.322, F 0.249)] [G loss: -0.198]\n",
      "Epoch 2476 -- [D loss: -0.065(R -0.302, F 0.171)] [G loss: -0.242]\n",
      "Epoch 2477 -- [D loss: -0.078(R -0.314, F 0.158)] [G loss: -0.282]\n",
      "Epoch 2478 -- [D loss: -0.014(R -0.268, F 0.240)] [G loss: -0.332]\n",
      "Epoch 2479 -- [D loss: -0.033(R -0.340, F 0.274)] [G loss: -0.365]\n",
      "Epoch 2480 -- [D loss: -0.039(R -0.311, F 0.232)] [G loss: -0.387]\n",
      "Epoch 2481 -- [D loss: 0.002(R -0.302, F 0.307)] [G loss: -0.386]\n",
      "Epoch 2482 -- [D loss: 0.014(R -0.315, F 0.343)] [G loss: -0.371]\n",
      "Epoch 2483 -- [D loss: 0.006(R -0.341, F 0.353)] [G loss: -0.341]\n",
      "Epoch 2484 -- [D loss: -0.012(R -0.382, F 0.358)] [G loss: -0.316]\n",
      "Epoch 2485 -- [D loss: -0.031(R -0.427, F 0.365)] [G loss: -0.298]\n",
      "Epoch 2486 -- [D loss: -0.016(R -0.414, F 0.383)] [G loss: -0.288]\n",
      "Epoch 2487 -- [D loss: -0.024(R -0.438, F 0.389)] [G loss: -0.298]\n",
      "Epoch 2488 -- [D loss: 0.008(R -0.394, F 0.409)] [G loss: -0.313]\n",
      "Epoch 2489 -- [D loss: 0.006(R -0.381, F 0.392)] [G loss: -0.334]\n",
      "Epoch 2490 -- [D loss: 0.006(R -0.362, F 0.374)] [G loss: -0.333]\n",
      "Epoch 2491 -- [D loss: -0.001(R -0.356, F 0.353)] [G loss: -0.325]\n",
      "Epoch 2492 -- [D loss: 0.001(R -0.349, F 0.350)] [G loss: -0.295]\n",
      "Epoch 2493 -- [D loss: -0.027(R -0.356, F 0.301)] [G loss: -0.239]\n",
      "Epoch 2494 -- [D loss: -0.050(R -0.342, F 0.242)] [G loss: -0.205]\n",
      "Epoch 2495 -- [D loss: -0.058(R -0.337, F 0.221)] [G loss: -0.188]\n",
      "Epoch 2496 -- [D loss: -0.039(R -0.321, F 0.242)] [G loss: -0.186]\n",
      "Epoch 2497 -- [D loss: -0.040(R -0.293, F 0.212)] [G loss: -0.175]\n",
      "Epoch 2498 -- [D loss: -0.036(R -0.251, F 0.179)] [G loss: -0.174]\n",
      "Epoch 2499 -- [D loss: -0.033(R -0.247, F 0.180)] [G loss: -0.171]\n",
      "Epoch 2500 -- [D loss: -0.011(R -0.228, F 0.206)] [G loss: -0.197]\n",
      "INFO:tensorflow:Assets written to: ram://b0f81087-54ac-475f-b075-845efdcaf9e0/assets\n",
      "INFO:tensorflow:Assets written to: ram://3526216d-71e2-4e37-891d-555905689a29/assets\n",
      "INFO:tensorflow:Assets written to: ram://f59fe0b1-aac1-4c5f-855e-f77832e48f3c/assets\n",
      "Epoch 2501 -- [D loss: -0.014(R -0.227, F 0.199)] [G loss: -0.189]\n",
      "Epoch 2502 -- [D loss: -0.007(R -0.198, F 0.184)] [G loss: -0.176]\n",
      "Epoch 2503 -- [D loss: -0.051(R -0.262, F 0.159)] [G loss: -0.181]\n",
      "Epoch 2504 -- [D loss: -0.022(R -0.191, F 0.147)] [G loss: -0.192]\n",
      "Epoch 2505 -- [D loss: -0.010(R -0.223, F 0.202)] [G loss: -0.190]\n",
      "Epoch 2506 -- [D loss: -0.038(R -0.230, F 0.154)] [G loss: -0.187]\n",
      "Epoch 2507 -- [D loss: -0.054(R -0.250, F 0.142)] [G loss: -0.187]\n",
      "Epoch 2508 -- [D loss: -0.018(R -0.250, F 0.213)] [G loss: -0.189]\n",
      "Epoch 2509 -- [D loss: -0.042(R -0.270, F 0.185)] [G loss: -0.191]\n",
      "Epoch 2510 -- [D loss: -0.027(R -0.245, F 0.191)] [G loss: -0.189]\n",
      "Epoch 2511 -- [D loss: -0.013(R -0.236, F 0.210)] [G loss: -0.206]\n",
      "Epoch 2512 -- [D loss: -0.023(R -0.240, F 0.194)] [G loss: -0.204]\n",
      "Epoch 2513 -- [D loss: -0.015(R -0.254, F 0.225)] [G loss: -0.209]\n",
      "Epoch 2514 -- [D loss: 0.005(R -0.260, F 0.270)] [G loss: -0.237]\n",
      "Epoch 2515 -- [D loss: 0.010(R -0.249, F 0.269)] [G loss: -0.268]\n",
      "Epoch 2516 -- [D loss: 0.013(R -0.271, F 0.296)] [G loss: -0.266]\n",
      "Epoch 2517 -- [D loss: -0.005(R -0.297, F 0.286)] [G loss: -0.233]\n",
      "Epoch 2518 -- [D loss: 0.001(R -0.266, F 0.268)] [G loss: -0.209]\n",
      "Epoch 2519 -- [D loss: -0.037(R -0.311, F 0.237)] [G loss: -0.210]\n",
      "Epoch 2520 -- [D loss: -0.092(R -0.384, F 0.199)] [G loss: -0.244]\n",
      "Epoch 2521 -- [D loss: -0.083(R -0.393, F 0.226)] [G loss: -0.293]\n",
      "Epoch 2522 -- [D loss: -0.077(R -0.473, F 0.319)] [G loss: -0.374]\n",
      "Epoch 2523 -- [D loss: -0.003(R -0.419, F 0.414)] [G loss: -0.425]\n",
      "Epoch 2524 -- [D loss: 0.005(R -0.451, F 0.462)] [G loss: -0.493]\n",
      "Epoch 2525 -- [D loss: -0.069(R -0.513, F 0.375)] [G loss: -0.551]\n",
      "Epoch 2526 -- [D loss: -0.040(R -0.572, F 0.491)] [G loss: -0.609]\n",
      "Epoch 2527 -- [D loss: -0.020(R -0.575, F 0.534)] [G loss: -0.649]\n",
      "Epoch 2528 -- [D loss: -0.037(R -0.580, F 0.506)] [G loss: -0.690]\n",
      "Epoch 2529 -- [D loss: -0.031(R -0.599, F 0.537)] [G loss: -0.666]\n",
      "Epoch 2530 -- [D loss: 0.046(R -0.566, F 0.658)] [G loss: -0.597]\n",
      "Epoch 2531 -- [D loss: 0.017(R -0.539, F 0.574)] [G loss: -0.539]\n",
      "Epoch 2532 -- [D loss: -0.013(R -0.538, F 0.512)] [G loss: -0.467]\n",
      "Epoch 2533 -- [D loss: -0.036(R -0.519, F 0.447)] [G loss: -0.409]\n",
      "Epoch 2534 -- [D loss: -0.031(R -0.511, F 0.449)] [G loss: -0.376]\n",
      "Epoch 2535 -- [D loss: -0.014(R -0.470, F 0.441)] [G loss: -0.375]\n",
      "Epoch 2536 -- [D loss: -0.018(R -0.465, F 0.429)] [G loss: -0.360]\n",
      "Epoch 2537 -- [D loss: -0.000(R -0.420, F 0.420)] [G loss: -0.348]\n",
      "Epoch 2538 -- [D loss: -0.038(R -0.410, F 0.335)] [G loss: -0.342]\n",
      "Epoch 2539 -- [D loss: -0.035(R -0.395, F 0.326)] [G loss: -0.324]\n",
      "Epoch 2540 -- [D loss: -0.003(R -0.285, F 0.278)] [G loss: -0.342]\n",
      "Epoch 2541 -- [D loss: -0.032(R -0.345, F 0.281)] [G loss: -0.326]\n",
      "Epoch 2542 -- [D loss: -0.011(R -0.356, F 0.334)] [G loss: -0.337]\n",
      "Epoch 2543 -- [D loss: 0.024(R -0.216, F 0.265)] [G loss: -0.324]\n",
      "Epoch 2544 -- [D loss: -0.077(R -0.306, F 0.153)] [G loss: -0.309]\n",
      "Epoch 2545 -- [D loss: -0.106(R -0.314, F 0.102)] [G loss: -0.283]\n",
      "Epoch 2546 -- [D loss: -0.056(R -0.284, F 0.172)] [G loss: -0.275]\n",
      "Epoch 2547 -- [D loss: -0.045(R -0.256, F 0.166)] [G loss: -0.264]\n",
      "Epoch 2548 -- [D loss: -0.000(R -0.227, F 0.227)] [G loss: -0.219]\n",
      "Epoch 2549 -- [D loss: -0.029(R -0.237, F 0.180)] [G loss: -0.189]\n",
      "Epoch 2550 -- [D loss: -0.037(R -0.229, F 0.155)] [G loss: -0.176]\n",
      "Epoch 2551 -- [D loss: -0.020(R -0.229, F 0.190)] [G loss: -0.183]\n",
      "Epoch 2552 -- [D loss: -0.007(R -0.212, F 0.197)] [G loss: -0.167]\n",
      "Epoch 2553 -- [D loss: -0.017(R -0.221, F 0.188)] [G loss: -0.156]\n",
      "Epoch 2554 -- [D loss: -0.020(R -0.220, F 0.181)] [G loss: -0.116]\n",
      "Epoch 2555 -- [D loss: -0.036(R -0.239, F 0.166)] [G loss: -0.091]\n",
      "Epoch 2556 -- [D loss: -0.034(R -0.207, F 0.139)] [G loss: -0.070]\n",
      "Epoch 2557 -- [D loss: -0.078(R -0.227, F 0.072)] [G loss: -0.086]\n",
      "Epoch 2558 -- [D loss: -0.061(R -0.231, F 0.110)] [G loss: -0.104]\n",
      "Epoch 2559 -- [D loss: -0.043(R -0.224, F 0.137)] [G loss: -0.141]\n",
      "Epoch 2560 -- [D loss: -0.085(R -0.327, F 0.157)] [G loss: -0.180]\n",
      "Epoch 2561 -- [D loss: -0.028(R -0.279, F 0.222)] [G loss: -0.205]\n",
      "Epoch 2562 -- [D loss: -0.052(R -0.317, F 0.212)] [G loss: -0.220]\n",
      "Epoch 2563 -- [D loss: -0.073(R -0.304, F 0.158)] [G loss: -0.253]\n",
      "Epoch 2564 -- [D loss: -0.084(R -0.292, F 0.125)] [G loss: -0.307]\n",
      "Epoch 2565 -- [D loss: -0.004(R -0.218, F 0.209)] [G loss: -0.357]\n",
      "Epoch 2566 -- [D loss: -0.052(R -0.416, F 0.311)] [G loss: -0.399]\n",
      "Epoch 2567 -- [D loss: -0.063(R -0.371, F 0.246)] [G loss: -0.459]\n",
      "Epoch 2568 -- [D loss: -0.052(R -0.404, F 0.300)] [G loss: -0.497]\n",
      "Epoch 2569 -- [D loss: -0.018(R -0.352, F 0.315)] [G loss: -0.487]\n",
      "Epoch 2570 -- [D loss: -0.003(R -0.417, F 0.411)] [G loss: -0.488]\n",
      "Epoch 2571 -- [D loss: 0.055(R -0.371, F 0.482)] [G loss: -0.478]\n",
      "Epoch 2572 -- [D loss: 0.047(R -0.370, F 0.465)] [G loss: -0.444]\n",
      "Epoch 2573 -- [D loss: 0.032(R -0.400, F 0.464)] [G loss: -0.427]\n",
      "Epoch 2574 -- [D loss: -0.010(R -0.479, F 0.459)] [G loss: -0.412]\n",
      "Epoch 2575 -- [D loss: -0.000(R -0.456, F 0.456)] [G loss: -0.387]\n",
      "Epoch 2576 -- [D loss: -0.026(R -0.490, F 0.438)] [G loss: -0.377]\n",
      "Epoch 2577 -- [D loss: -0.023(R -0.470, F 0.425)] [G loss: -0.365]\n",
      "Epoch 2578 -- [D loss: -0.030(R -0.468, F 0.408)] [G loss: -0.344]\n",
      "Epoch 2579 -- [D loss: -0.018(R -0.448, F 0.411)] [G loss: -0.332]\n",
      "Epoch 2580 -- [D loss: -0.014(R -0.445, F 0.417)] [G loss: -0.334]\n",
      "Epoch 2581 -- [D loss: -0.026(R -0.455, F 0.403)] [G loss: -0.318]\n",
      "Epoch 2582 -- [D loss: -0.024(R -0.423, F 0.376)] [G loss: -0.322]\n",
      "Epoch 2583 -- [D loss: -0.005(R -0.431, F 0.420)] [G loss: -0.330]\n",
      "Epoch 2584 -- [D loss: -0.014(R -0.396, F 0.368)] [G loss: -0.325]\n",
      "Epoch 2585 -- [D loss: -0.085(R -0.407, F 0.238)] [G loss: -0.342]\n",
      "Epoch 2586 -- [D loss: -0.057(R -0.395, F 0.281)] [G loss: -0.380]\n",
      "Epoch 2587 -- [D loss: -0.017(R -0.350, F 0.315)] [G loss: -0.400]\n",
      "Epoch 2588 -- [D loss: 0.002(R -0.372, F 0.377)] [G loss: -0.410]\n",
      "Epoch 2589 -- [D loss: 0.049(R -0.343, F 0.440)] [G loss: -0.421]\n",
      "Epoch 2590 -- [D loss: 0.042(R -0.392, F 0.476)] [G loss: -0.417]\n",
      "Epoch 2591 -- [D loss: -0.025(R -0.414, F 0.365)] [G loss: -0.420]\n",
      "Epoch 2592 -- [D loss: 0.018(R -0.349, F 0.386)] [G loss: -0.397]\n",
      "Epoch 2593 -- [D loss: -0.027(R -0.399, F 0.344)] [G loss: -0.410]\n",
      "Epoch 2594 -- [D loss: -0.035(R -0.382, F 0.311)] [G loss: -0.419]\n",
      "Epoch 2595 -- [D loss: -0.015(R -0.397, F 0.368)] [G loss: -0.422]\n",
      "Epoch 2596 -- [D loss: 0.016(R -0.352, F 0.384)] [G loss: -0.391]\n",
      "Epoch 2597 -- [D loss: 0.007(R -0.378, F 0.391)] [G loss: -0.348]\n",
      "Epoch 2598 -- [D loss: -0.010(R -0.373, F 0.353)] [G loss: -0.294]\n",
      "Epoch 2599 -- [D loss: -0.019(R -0.357, F 0.318)] [G loss: -0.267]\n",
      "Epoch 2600 -- [D loss: -0.036(R -0.358, F 0.286)] [G loss: -0.233]\n",
      "INFO:tensorflow:Assets written to: ram://aee70eb4-e5d7-4c8f-bdca-fc9f109a249d/assets\n",
      "INFO:tensorflow:Assets written to: ram://51929461-8062-4c4c-b460-a05fe1b68b4c/assets\n",
      "INFO:tensorflow:Assets written to: ram://5a5c9b0c-f0c5-402d-93c5-f3f9760e1cb9/assets\n",
      "Epoch 2601 -- [D loss: -0.034(R -0.359, F 0.291)] [G loss: -0.223]\n",
      "Epoch 2602 -- [D loss: -0.026(R -0.351, F 0.300)] [G loss: -0.225]\n",
      "Epoch 2603 -- [D loss: -0.032(R -0.360, F 0.296)] [G loss: -0.234]\n",
      "Epoch 2604 -- [D loss: -0.057(R -0.326, F 0.211)] [G loss: -0.255]\n",
      "Epoch 2605 -- [D loss: -0.079(R -0.350, F 0.192)] [G loss: -0.271]\n",
      "Epoch 2606 -- [D loss: -0.094(R -0.387, F 0.199)] [G loss: -0.324]\n",
      "Epoch 2607 -- [D loss: -0.048(R -0.357, F 0.260)] [G loss: -0.374]\n",
      "Epoch 2608 -- [D loss: -0.003(R -0.398, F 0.392)] [G loss: -0.413]\n",
      "Epoch 2609 -- [D loss: -0.030(R -0.387, F 0.327)] [G loss: -0.457]\n",
      "Epoch 2610 -- [D loss: -0.062(R -0.471, F 0.347)] [G loss: -0.510]\n",
      "Epoch 2611 -- [D loss: -0.151(R -0.550, F 0.248)] [G loss: -0.599]\n",
      "Epoch 2612 -- [D loss: 0.007(R -0.412, F 0.427)] [G loss: -0.641]\n",
      "Epoch 2613 -- [D loss: 0.031(R -0.316, F 0.378)] [G loss: -0.644]\n",
      "Epoch 2614 -- [D loss: -0.007(R -0.463, F 0.449)] [G loss: -0.654]\n",
      "Epoch 2615 -- [D loss: 0.046(R -0.435, F 0.527)] [G loss: -0.595]\n",
      "Epoch 2616 -- [D loss: 0.066(R -0.365, F 0.497)] [G loss: -0.516]\n",
      "Epoch 2617 -- [D loss: 0.028(R -0.430, F 0.486)] [G loss: -0.470]\n",
      "Epoch 2618 -- [D loss: 0.016(R -0.438, F 0.471)] [G loss: -0.421]\n",
      "Epoch 2619 -- [D loss: 0.010(R -0.396, F 0.416)] [G loss: -0.387]\n",
      "Epoch 2620 -- [D loss: -0.003(R -0.418, F 0.412)] [G loss: -0.358]\n",
      "Epoch 2621 -- [D loss: -0.011(R -0.399, F 0.377)] [G loss: -0.283]\n",
      "Epoch 2622 -- [D loss: -0.045(R -0.369, F 0.279)] [G loss: -0.231]\n",
      "Epoch 2623 -- [D loss: -0.055(R -0.367, F 0.257)] [G loss: -0.194]\n",
      "Epoch 2624 -- [D loss: -0.028(R -0.327, F 0.270)] [G loss: -0.174]\n",
      "Epoch 2625 -- [D loss: -0.056(R -0.333, F 0.221)] [G loss: -0.152]\n",
      "Epoch 2626 -- [D loss: -0.095(R -0.378, F 0.187)] [G loss: -0.148]\n",
      "Epoch 2627 -- [D loss: -0.084(R -0.332, F 0.163)] [G loss: -0.134]\n",
      "Epoch 2628 -- [D loss: -0.112(R -0.293, F 0.070)] [G loss: -0.167]\n",
      "Epoch 2629 -- [D loss: -0.100(R -0.257, F 0.056)] [G loss: -0.191]\n",
      "Epoch 2630 -- [D loss: -0.115(R -0.376, F 0.147)] [G loss: -0.242]\n",
      "Epoch 2631 -- [D loss: -0.115(R -0.309, F 0.080)] [G loss: -0.251]\n",
      "Epoch 2632 -- [D loss: -0.112(R -0.337, F 0.113)] [G loss: -0.309]\n",
      "Epoch 2633 -- [D loss: -0.131(R -0.397, F 0.135)] [G loss: -0.352]\n",
      "Epoch 2634 -- [D loss: -0.144(R -0.425, F 0.138)] [G loss: -0.441]\n",
      "Epoch 2635 -- [D loss: -0.091(R -0.475, F 0.292)] [G loss: -0.547]\n",
      "Epoch 2636 -- [D loss: -0.006(R -0.435, F 0.422)] [G loss: -0.622]\n",
      "Epoch 2637 -- [D loss: -0.021(R -0.467, F 0.426)] [G loss: -0.702]\n",
      "Epoch 2638 -- [D loss: 0.030(R -0.484, F 0.544)] [G loss: -0.744]\n",
      "Epoch 2639 -- [D loss: 0.050(R -0.489, F 0.589)] [G loss: -0.764]\n",
      "Epoch 2640 -- [D loss: 0.102(R -0.498, F 0.701)] [G loss: -0.732]\n",
      "Epoch 2641 -- [D loss: 0.085(R -0.515, F 0.685)] [G loss: -0.707]\n",
      "Epoch 2642 -- [D loss: 0.061(R -0.521, F 0.643)] [G loss: -0.666]\n",
      "Epoch 2643 -- [D loss: 0.061(R -0.502, F 0.624)] [G loss: -0.617]\n",
      "Epoch 2644 -- [D loss: 0.040(R -0.505, F 0.584)] [G loss: -0.567]\n",
      "Epoch 2645 -- [D loss: 0.027(R -0.482, F 0.536)] [G loss: -0.538]\n",
      "Epoch 2646 -- [D loss: 0.014(R -0.478, F 0.507)] [G loss: -0.490]\n",
      "Epoch 2647 -- [D loss: -0.004(R -0.479, F 0.471)] [G loss: -0.448]\n",
      "Epoch 2648 -- [D loss: -0.004(R -0.473, F 0.465)] [G loss: -0.417]\n",
      "Epoch 2649 -- [D loss: -0.043(R -0.468, F 0.383)] [G loss: -0.376]\n",
      "Epoch 2650 -- [D loss: -0.065(R -0.461, F 0.330)] [G loss: -0.307]\n",
      "Epoch 2651 -- [D loss: -0.121(R -0.467, F 0.224)] [G loss: -0.233]\n",
      "Epoch 2652 -- [D loss: -0.181(R -0.521, F 0.158)] [G loss: -0.193]\n",
      "Epoch 2653 -- [D loss: -0.184(R -0.540, F 0.172)] [G loss: -0.175]\n",
      "Epoch 2654 -- [D loss: -0.158(R -0.504, F 0.188)] [G loss: -0.178]\n",
      "Epoch 2655 -- [D loss: -0.048(R -0.431, F 0.335)] [G loss: -0.174]\n",
      "Epoch 2656 -- [D loss: -0.047(R -0.487, F 0.394)] [G loss: -0.207]\n",
      "Epoch 2657 -- [D loss: 0.000(R -0.401, F 0.401)] [G loss: -0.221]\n",
      "Epoch 2658 -- [D loss: 0.001(R -0.358, F 0.359)] [G loss: -0.236]\n",
      "Epoch 2659 -- [D loss: -0.023(R -0.329, F 0.284)] [G loss: -0.238]\n",
      "Epoch 2660 -- [D loss: -0.050(R -0.346, F 0.246)] [G loss: -0.307]\n",
      "Epoch 2661 -- [D loss: -0.116(R -0.404, F 0.172)] [G loss: -0.402]\n",
      "Epoch 2662 -- [D loss: -0.048(R -0.366, F 0.270)] [G loss: -0.525]\n",
      "Epoch 2663 -- [D loss: -0.092(R -0.472, F 0.288)] [G loss: -0.580]\n",
      "Epoch 2664 -- [D loss: 0.062(R -0.337, F 0.460)] [G loss: -0.633]\n",
      "Epoch 2665 -- [D loss: 0.039(R -0.496, F 0.575)] [G loss: -0.629]\n",
      "Epoch 2666 -- [D loss: 0.099(R -0.455, F 0.653)] [G loss: -0.607]\n",
      "Epoch 2667 -- [D loss: 0.107(R -0.452, F 0.667)] [G loss: -0.606]\n",
      "Epoch 2668 -- [D loss: 0.077(R -0.445, F 0.600)] [G loss: -0.568]\n",
      "Epoch 2669 -- [D loss: 0.057(R -0.475, F 0.589)] [G loss: -0.533]\n",
      "Epoch 2670 -- [D loss: 0.014(R -0.485, F 0.512)] [G loss: -0.499]\n",
      "Epoch 2671 -- [D loss: 0.007(R -0.466, F 0.481)] [G loss: -0.479]\n",
      "Epoch 2672 -- [D loss: 0.008(R -0.458, F 0.475)] [G loss: -0.444]\n",
      "Epoch 2673 -- [D loss: -0.021(R -0.468, F 0.426)] [G loss: -0.427]\n",
      "Epoch 2674 -- [D loss: -0.023(R -0.460, F 0.414)] [G loss: -0.397]\n",
      "Epoch 2675 -- [D loss: -0.030(R -0.435, F 0.376)] [G loss: -0.334]\n",
      "Epoch 2676 -- [D loss: -0.010(R -0.381, F 0.361)] [G loss: -0.269]\n",
      "Epoch 2677 -- [D loss: -0.046(R -0.371, F 0.278)] [G loss: -0.181]\n",
      "Epoch 2678 -- [D loss: -0.065(R -0.316, F 0.185)] [G loss: -0.105]\n",
      "Epoch 2679 -- [D loss: -0.046(R -0.244, F 0.151)] [G loss: -0.076]\n",
      "Epoch 2680 -- [D loss: -0.025(R -0.242, F 0.191)] [G loss: -0.093]\n",
      "Epoch 2681 -- [D loss: -0.022(R -0.211, F 0.167)] [G loss: -0.099]\n",
      "Epoch 2682 -- [D loss: 0.006(R -0.191, F 0.203)] [G loss: -0.123]\n",
      "Epoch 2683 -- [D loss: -0.040(R -0.221, F 0.142)] [G loss: -0.147]\n",
      "Epoch 2684 -- [D loss: -0.050(R -0.200, F 0.101)] [G loss: -0.169]\n",
      "Epoch 2685 -- [D loss: -0.062(R -0.212, F 0.089)] [G loss: -0.205]\n",
      "Epoch 2686 -- [D loss: -0.102(R -0.191, F -0.013)] [G loss: -0.236]\n",
      "Epoch 2687 -- [D loss: -0.149(R -0.224, F -0.073)] [G loss: -0.253]\n",
      "Epoch 2688 -- [D loss: -0.073(R -0.237, F 0.092)] [G loss: -0.297]\n",
      "Epoch 2689 -- [D loss: 0.013(R -0.185, F 0.211)] [G loss: -0.347]\n",
      "Epoch 2690 -- [D loss: -0.002(R -0.161, F 0.156)] [G loss: -0.333]\n",
      "Epoch 2691 -- [D loss: -0.043(R -0.299, F 0.212)] [G loss: -0.359]\n",
      "Epoch 2692 -- [D loss: -0.070(R -0.245, F 0.105)] [G loss: -0.417]\n",
      "Epoch 2693 -- [D loss: -0.054(R -0.273, F 0.165)] [G loss: -0.408]\n",
      "Epoch 2694 -- [D loss: -0.070(R -0.299, F 0.159)] [G loss: -0.411]\n",
      "Epoch 2695 -- [D loss: -0.016(R -0.230, F 0.199)] [G loss: -0.389]\n",
      "Epoch 2696 -- [D loss: 0.000(R -0.204, F 0.205)] [G loss: -0.385]\n",
      "Epoch 2697 -- [D loss: -0.023(R -0.255, F 0.209)] [G loss: -0.369]\n",
      "Epoch 2698 -- [D loss: -0.009(R -0.247, F 0.230)] [G loss: -0.358]\n",
      "Epoch 2699 -- [D loss: -0.042(R -0.311, F 0.227)] [G loss: -0.348]\n",
      "Epoch 2700 -- [D loss: -0.012(R -0.285, F 0.260)] [G loss: -0.326]\n",
      "INFO:tensorflow:Assets written to: ram://7c893163-fff5-4ef7-a2e0-74b591524066/assets\n",
      "INFO:tensorflow:Assets written to: ram://ef66492b-0385-46d6-81b9-03572079c035/assets\n",
      "INFO:tensorflow:Assets written to: ram://6c67a97e-038e-4614-b633-f772423a36c3/assets\n",
      "Epoch 2701 -- [D loss: 0.004(R -0.281, F 0.289)] [G loss: -0.312]\n",
      "Epoch 2702 -- [D loss: 0.014(R -0.291, F 0.319)] [G loss: -0.301]\n",
      "Epoch 2703 -- [D loss: 0.018(R -0.313, F 0.349)] [G loss: -0.307]\n",
      "Epoch 2704 -- [D loss: 0.039(R -0.323, F 0.402)] [G loss: -0.335]\n",
      "Epoch 2705 -- [D loss: 0.024(R -0.357, F 0.406)] [G loss: -0.340]\n",
      "Epoch 2706 -- [D loss: 0.022(R -0.369, F 0.412)] [G loss: -0.338]\n",
      "Epoch 2707 -- [D loss: -0.027(R -0.424, F 0.370)] [G loss: -0.338]\n",
      "Epoch 2708 -- [D loss: -0.030(R -0.447, F 0.387)] [G loss: -0.328]\n",
      "Epoch 2709 -- [D loss: -0.110(R -0.493, F 0.273)] [G loss: -0.352]\n",
      "Epoch 2710 -- [D loss: -0.194(R -0.582, F 0.194)] [G loss: -0.415]\n",
      "Epoch 2711 -- [D loss: -0.160(R -0.614, F 0.293)] [G loss: -0.490]\n",
      "Epoch 2712 -- [D loss: -0.155(R -0.582, F 0.271)] [G loss: -0.643]\n",
      "Epoch 2713 -- [D loss: -0.121(R -0.675, F 0.433)] [G loss: -0.698]\n",
      "Epoch 2714 -- [D loss: -0.211(R -0.756, F 0.334)] [G loss: -0.800]\n",
      "Epoch 2715 -- [D loss: -0.161(R -0.825, F 0.502)] [G loss: -0.942]\n",
      "Epoch 2716 -- [D loss: -0.063(R -0.816, F 0.690)] [G loss: -0.955]\n",
      "Epoch 2717 -- [D loss: -0.048(R -0.817, F 0.722)] [G loss: -1.012]\n",
      "Epoch 2718 -- [D loss: -0.022(R -0.798, F 0.754)] [G loss: -0.953]\n",
      "Epoch 2719 -- [D loss: 0.000(R -0.824, F 0.824)] [G loss: -0.867]\n",
      "Epoch 2720 -- [D loss: -0.008(R -0.720, F 0.704)] [G loss: -0.867]\n",
      "Epoch 2721 -- [D loss: 0.044(R -0.611, F 0.698)] [G loss: -0.827]\n",
      "Epoch 2722 -- [D loss: -0.010(R -0.615, F 0.595)] [G loss: -0.818]\n",
      "Epoch 2723 -- [D loss: -0.096(R -0.739, F 0.546)] [G loss: -0.839]\n",
      "Epoch 2724 -- [D loss: -0.076(R -0.638, F 0.486)] [G loss: -0.819]\n",
      "Epoch 2725 -- [D loss: 0.062(R -0.592, F 0.715)] [G loss: -0.780]\n",
      "Epoch 2726 -- [D loss: 0.063(R -0.618, F 0.744)] [G loss: -0.728]\n",
      "Epoch 2727 -- [D loss: 0.035(R -0.642, F 0.713)] [G loss: -0.692]\n",
      "Epoch 2728 -- [D loss: 0.025(R -0.646, F 0.696)] [G loss: -0.664]\n",
      "Epoch 2729 -- [D loss: 0.022(R -0.651, F 0.695)] [G loss: -0.640]\n",
      "Epoch 2730 -- [D loss: 0.002(R -0.683, F 0.686)] [G loss: -0.636]\n",
      "Epoch 2731 -- [D loss: 0.014(R -0.665, F 0.693)] [G loss: -0.619]\n",
      "Epoch 2732 -- [D loss: 0.017(R -0.640, F 0.674)] [G loss: -0.594]\n",
      "Epoch 2733 -- [D loss: -0.017(R -0.652, F 0.619)] [G loss: -0.571]\n",
      "Epoch 2734 -- [D loss: -0.058(R -0.664, F 0.548)] [G loss: -0.534]\n",
      "Epoch 2735 -- [D loss: -0.049(R -0.591, F 0.492)] [G loss: -0.532]\n",
      "Epoch 2736 -- [D loss: -0.085(R -0.644, F 0.473)] [G loss: -0.498]\n",
      "Epoch 2737 -- [D loss: -0.232(R -0.722, F 0.259)] [G loss: -0.584]\n",
      "Epoch 2738 -- [D loss: -0.108(R -0.731, F 0.516)] [G loss: -0.600]\n",
      "Epoch 2739 -- [D loss: -0.035(R -0.626, F 0.555)] [G loss: -0.649]\n",
      "Epoch 2740 -- [D loss: -0.060(R -0.661, F 0.540)] [G loss: -0.701]\n",
      "Epoch 2741 -- [D loss: -0.090(R -0.684, F 0.505)] [G loss: -0.732]\n",
      "Epoch 2742 -- [D loss: -0.000(R -0.581, F 0.581)] [G loss: -0.693]\n",
      "Epoch 2743 -- [D loss: -0.104(R -0.537, F 0.329)] [G loss: -0.704]\n",
      "Epoch 2744 -- [D loss: -0.079(R -0.442, F 0.284)] [G loss: -0.719]\n",
      "Epoch 2745 -- [D loss: -0.173(R -0.500, F 0.154)] [G loss: -0.803]\n",
      "Epoch 2746 -- [D loss: 0.025(R -0.328, F 0.379)] [G loss: -0.763]\n",
      "Epoch 2747 -- [D loss: -0.109(R -0.448, F 0.231)] [G loss: -0.782]\n",
      "Epoch 2748 -- [D loss: 0.000(R -0.328, F 0.328)] [G loss: -0.711]\n",
      "Epoch 2749 -- [D loss: -0.032(R -0.343, F 0.280)] [G loss: -0.673]\n",
      "Epoch 2750 -- [D loss: 0.028(R -0.264, F 0.321)] [G loss: -0.664]\n",
      "Epoch 2751 -- [D loss: -0.038(R -0.304, F 0.228)] [G loss: -0.618]\n",
      "Epoch 2752 -- [D loss: 0.009(R -0.238, F 0.257)] [G loss: -0.589]\n",
      "Epoch 2753 -- [D loss: 0.015(R -0.173, F 0.203)] [G loss: -0.515]\n",
      "Epoch 2754 -- [D loss: 0.037(R -0.283, F 0.358)] [G loss: -0.461]\n",
      "Epoch 2755 -- [D loss: 0.064(R -0.208, F 0.336)] [G loss: -0.417]\n",
      "Epoch 2756 -- [D loss: 0.049(R -0.198, F 0.297)] [G loss: -0.354]\n",
      "Epoch 2757 -- [D loss: 0.033(R -0.241, F 0.307)] [G loss: -0.315]\n",
      "Epoch 2758 -- [D loss: 0.030(R -0.243, F 0.303)] [G loss: -0.235]\n",
      "Epoch 2759 -- [D loss: 0.029(R -0.205, F 0.263)] [G loss: -0.175]\n",
      "Epoch 2760 -- [D loss: -0.023(R -0.257, F 0.211)] [G loss: -0.103]\n",
      "Epoch 2761 -- [D loss: -0.081(R -0.298, F 0.136)] [G loss: -0.061]\n",
      "Epoch 2762 -- [D loss: -0.064(R -0.268, F 0.140)] [G loss: -0.000]\n",
      "Epoch 2763 -- [D loss: -0.072(R -0.249, F 0.105)] [G loss: 0.019]\n",
      "Epoch 2764 -- [D loss: -0.074(R -0.257, F 0.108)] [G loss: 0.043]\n",
      "Epoch 2765 -- [D loss: -0.068(R -0.214, F 0.077)] [G loss: 0.048]\n",
      "Epoch 2766 -- [D loss: -0.127(R -0.246, F -0.009)] [G loss: 0.023]\n",
      "Epoch 2767 -- [D loss: -0.196(R -0.270, F -0.122)] [G loss: -0.001]\n",
      "Epoch 2768 -- [D loss: -0.281(R -0.409, F -0.153)] [G loss: -0.072]\n",
      "Epoch 2769 -- [D loss: -0.305(R -0.421, F -0.189)] [G loss: -0.129]\n",
      "Epoch 2770 -- [D loss: -0.242(R -0.394, F -0.090)] [G loss: -0.224]\n",
      "Epoch 2771 -- [D loss: -0.174(R -0.402, F 0.054)] [G loss: -0.292]\n",
      "Epoch 2772 -- [D loss: -0.072(R -0.398, F 0.254)] [G loss: -0.309]\n",
      "Epoch 2773 -- [D loss: -0.144(R -0.504, F 0.216)] [G loss: -0.338]\n",
      "Epoch 2774 -- [D loss: -0.064(R -0.330, F 0.203)] [G loss: -0.357]\n",
      "Epoch 2775 -- [D loss: -0.067(R -0.406, F 0.272)] [G loss: -0.373]\n",
      "Epoch 2776 -- [D loss: -0.110(R -0.543, F 0.324)] [G loss: -0.493]\n",
      "Epoch 2777 -- [D loss: -0.007(R -0.322, F 0.309)] [G loss: -0.563]\n",
      "Epoch 2778 -- [D loss: -0.017(R -0.461, F 0.427)] [G loss: -0.581]\n",
      "Epoch 2779 -- [D loss: 0.025(R -0.484, F 0.534)] [G loss: -0.595]\n",
      "Epoch 2780 -- [D loss: 0.001(R -0.525, F 0.527)] [G loss: -0.629]\n",
      "Epoch 2781 -- [D loss: 0.050(R -0.525, F 0.625)] [G loss: -0.607]\n",
      "Epoch 2782 -- [D loss: 0.085(R -0.469, F 0.639)] [G loss: -0.632]\n",
      "Epoch 2783 -- [D loss: 0.055(R -0.460, F 0.571)] [G loss: -0.578]\n",
      "Epoch 2784 -- [D loss: 0.057(R -0.512, F 0.625)] [G loss: -0.584]\n",
      "Epoch 2785 -- [D loss: 0.002(R -0.531, F 0.534)] [G loss: -0.592]\n",
      "Epoch 2786 -- [D loss: 0.023(R -0.523, F 0.570)] [G loss: -0.595]\n",
      "Epoch 2787 -- [D loss: 0.013(R -0.557, F 0.584)] [G loss: -0.597]\n",
      "Epoch 2788 -- [D loss: 0.025(R -0.551, F 0.601)] [G loss: -0.568]\n",
      "Epoch 2789 -- [D loss: 0.014(R -0.561, F 0.589)] [G loss: -0.583]\n",
      "Epoch 2790 -- [D loss: -0.031(R -0.596, F 0.534)] [G loss: -0.570]\n",
      "Epoch 2791 -- [D loss: -0.017(R -0.585, F 0.550)] [G loss: -0.537]\n",
      "Epoch 2792 -- [D loss: -0.006(R -0.567, F 0.556)] [G loss: -0.512]\n",
      "Epoch 2793 -- [D loss: -0.003(R -0.571, F 0.564)] [G loss: -0.494]\n",
      "Epoch 2794 -- [D loss: -0.043(R -0.602, F 0.517)] [G loss: -0.480]\n",
      "Epoch 2795 -- [D loss: -0.002(R -0.541, F 0.536)] [G loss: -0.445]\n",
      "Epoch 2796 -- [D loss: -0.063(R -0.557, F 0.432)] [G loss: -0.442]\n",
      "Epoch 2797 -- [D loss: -0.094(R -0.551, F 0.363)] [G loss: -0.409]\n",
      "Epoch 2798 -- [D loss: -0.123(R -0.556, F 0.310)] [G loss: -0.406]\n",
      "Epoch 2799 -- [D loss: -0.048(R -0.359, F 0.264)] [G loss: -0.415]\n",
      "Epoch 2800 -- [D loss: -0.067(R -0.476, F 0.343)] [G loss: -0.417]\n",
      "INFO:tensorflow:Assets written to: ram://bea72715-60e8-4867-8edf-e79433562615/assets\n",
      "INFO:tensorflow:Assets written to: ram://90a23f96-6787-4ff7-931d-ece7c3851641/assets\n",
      "INFO:tensorflow:Assets written to: ram://c6015500-fcbd-4e48-9fbf-68cddb859373/assets\n",
      "Epoch 2801 -- [D loss: -0.076(R -0.455, F 0.303)] [G loss: -0.411]\n",
      "Epoch 2802 -- [D loss: -0.079(R -0.432, F 0.274)] [G loss: -0.394]\n",
      "Epoch 2803 -- [D loss: -0.143(R -0.472, F 0.186)] [G loss: -0.390]\n",
      "Epoch 2804 -- [D loss: -0.104(R -0.350, F 0.141)] [G loss: -0.364]\n",
      "Epoch 2805 -- [D loss: -0.083(R -0.307, F 0.142)] [G loss: -0.381]\n",
      "Epoch 2806 -- [D loss: -0.026(R -0.276, F 0.225)] [G loss: -0.371]\n",
      "Epoch 2807 -- [D loss: -0.066(R -0.238, F 0.105)] [G loss: -0.379]\n",
      "Epoch 2808 -- [D loss: -0.009(R -0.324, F 0.306)] [G loss: -0.384]\n",
      "Epoch 2809 -- [D loss: 0.034(R -0.221, F 0.288)] [G loss: -0.355]\n",
      "Epoch 2810 -- [D loss: 0.038(R -0.209, F 0.284)] [G loss: -0.326]\n",
      "Epoch 2811 -- [D loss: 0.031(R -0.144, F 0.205)] [G loss: -0.290]\n",
      "Epoch 2812 -- [D loss: 0.084(R -0.130, F 0.297)] [G loss: -0.260]\n",
      "Epoch 2813 -- [D loss: 0.046(R -0.103, F 0.194)] [G loss: -0.177]\n",
      "Epoch 2814 -- [D loss: 0.033(R -0.106, F 0.173)] [G loss: -0.142]\n",
      "Epoch 2815 -- [D loss: 0.036(R -0.087, F 0.160)] [G loss: -0.103]\n",
      "Epoch 2816 -- [D loss: 0.042(R -0.049, F 0.133)] [G loss: -0.072]\n",
      "Epoch 2817 -- [D loss: 0.027(R -0.039, F 0.092)] [G loss: -0.035]\n",
      "Epoch 2818 -- [D loss: -0.010(R -0.053, F 0.034)] [G loss: -0.000]\n",
      "Epoch 2819 -- [D loss: -0.007(R -0.035, F 0.021)] [G loss: 0.014]\n",
      "Epoch 2820 -- [D loss: -0.018(R -0.049, F 0.013)] [G loss: 0.017]\n",
      "Epoch 2821 -- [D loss: -0.073(R -0.114, F -0.031)] [G loss: -0.007]\n",
      "Epoch 2822 -- [D loss: -0.067(R -0.107, F -0.026)] [G loss: -0.026]\n",
      "Epoch 2823 -- [D loss: -0.048(R -0.130, F 0.034)] [G loss: -0.065]\n",
      "Epoch 2824 -- [D loss: -0.098(R -0.192, F -0.005)] [G loss: -0.134]\n",
      "Epoch 2825 -- [D loss: -0.084(R -0.143, F -0.025)] [G loss: -0.217]\n",
      "Epoch 2826 -- [D loss: -0.095(R -0.198, F 0.009)] [G loss: -0.289]\n",
      "Epoch 2827 -- [D loss: -0.105(R -0.366, F 0.157)] [G loss: -0.375]\n",
      "Epoch 2828 -- [D loss: -0.034(R -0.340, F 0.272)] [G loss: -0.431]\n",
      "Epoch 2829 -- [D loss: 0.059(R -0.401, F 0.520)] [G loss: -0.485]\n",
      "Epoch 2830 -- [D loss: 0.036(R -0.479, F 0.550)] [G loss: -0.513]\n",
      "Epoch 2831 -- [D loss: -0.012(R -0.482, F 0.458)] [G loss: -0.540]\n",
      "Epoch 2832 -- [D loss: 0.003(R -0.503, F 0.509)] [G loss: -0.568]\n",
      "Epoch 2833 -- [D loss: 0.023(R -0.512, F 0.557)] [G loss: -0.586]\n",
      "Epoch 2834 -- [D loss: -0.034(R -0.568, F 0.500)] [G loss: -0.583]\n",
      "Epoch 2835 -- [D loss: -0.017(R -0.571, F 0.537)] [G loss: -0.591]\n",
      "Epoch 2836 -- [D loss: -0.011(R -0.590, F 0.569)] [G loss: -0.591]\n",
      "Epoch 2837 -- [D loss: 0.008(R -0.593, F 0.610)] [G loss: -0.610]\n",
      "Epoch 2838 -- [D loss: 0.008(R -0.601, F 0.618)] [G loss: -0.582]\n",
      "Epoch 2839 -- [D loss: -0.019(R -0.638, F 0.599)] [G loss: -0.562]\n",
      "Epoch 2840 -- [D loss: 0.006(R -0.610, F 0.622)] [G loss: -0.568]\n",
      "Epoch 2841 -- [D loss: -0.012(R -0.624, F 0.599)] [G loss: -0.586]\n",
      "Epoch 2842 -- [D loss: 0.005(R -0.629, F 0.639)] [G loss: -0.579]\n",
      "Epoch 2843 -- [D loss: 0.023(R -0.597, F 0.643)] [G loss: -0.587]\n",
      "Epoch 2844 -- [D loss: -0.004(R -0.630, F 0.622)] [G loss: -0.569]\n",
      "Epoch 2845 -- [D loss: -0.043(R -0.638, F 0.553)] [G loss: -0.527]\n",
      "Epoch 2846 -- [D loss: -0.094(R -0.681, F 0.493)] [G loss: -0.502]\n",
      "Epoch 2847 -- [D loss: -0.102(R -0.672, F 0.467)] [G loss: -0.519]\n",
      "Epoch 2848 -- [D loss: -0.064(R -0.661, F 0.534)] [G loss: -0.541]\n",
      "Epoch 2849 -- [D loss: -0.034(R -0.648, F 0.581)] [G loss: -0.540]\n",
      "Epoch 2850 -- [D loss: -0.070(R -0.737, F 0.598)] [G loss: -0.595]\n",
      "Epoch 2851 -- [D loss: -0.027(R -0.697, F 0.644)] [G loss: -0.620]\n",
      "Epoch 2852 -- [D loss: -0.021(R -0.711, F 0.669)] [G loss: -0.678]\n",
      "Epoch 2853 -- [D loss: -0.033(R -0.698, F 0.632)] [G loss: -0.694]\n",
      "Epoch 2854 -- [D loss: -0.049(R -0.697, F 0.599)] [G loss: -0.711]\n",
      "Epoch 2855 -- [D loss: -0.045(R -0.657, F 0.566)] [G loss: -0.734]\n",
      "Epoch 2856 -- [D loss: -0.000(R -0.579, F 0.578)] [G loss: -0.747]\n",
      "Epoch 2857 -- [D loss: -0.003(R -0.607, F 0.601)] [G loss: -0.781]\n",
      "Epoch 2858 -- [D loss: -0.011(R -0.620, F 0.597)] [G loss: -0.811]\n",
      "Epoch 2859 -- [D loss: 0.032(R -0.507, F 0.570)] [G loss: -0.763]\n",
      "Epoch 2860 -- [D loss: 0.104(R -0.472, F 0.680)] [G loss: -0.705]\n",
      "Epoch 2861 -- [D loss: 0.128(R -0.345, F 0.600)] [G loss: -0.649]\n",
      "Epoch 2862 -- [D loss: 0.080(R -0.401, F 0.561)] [G loss: -0.549]\n",
      "Epoch 2863 -- [D loss: 0.032(R -0.355, F 0.419)] [G loss: -0.464]\n",
      "Epoch 2864 -- [D loss: 0.041(R -0.337, F 0.419)] [G loss: -0.384]\n",
      "Epoch 2865 -- [D loss: 0.025(R -0.259, F 0.308)] [G loss: -0.269]\n",
      "Epoch 2866 -- [D loss: -0.016(R -0.239, F 0.207)] [G loss: -0.158]\n",
      "Epoch 2867 -- [D loss: -0.037(R -0.204, F 0.129)] [G loss: -0.072]\n",
      "Epoch 2868 -- [D loss: -0.052(R -0.161, F 0.058)] [G loss: 0.023]\n",
      "Epoch 2869 -- [D loss: -0.079(R -0.120, F -0.037)] [G loss: 0.081]\n",
      "Epoch 2870 -- [D loss: -0.089(R -0.108, F -0.071)] [G loss: 0.143]\n",
      "Epoch 2871 -- [D loss: -0.085(R -0.089, F -0.082)] [G loss: 0.170]\n",
      "Epoch 2872 -- [D loss: -0.077(R -0.069, F -0.084)] [G loss: 0.185]\n",
      "Epoch 2873 -- [D loss: -0.054(R -0.006, F -0.101)] [G loss: 0.181]\n",
      "Epoch 2874 -- [D loss: -0.048(R -0.033, F -0.063)] [G loss: 0.178]\n",
      "Epoch 2875 -- [D loss: -0.027(R 0.024, F -0.078)] [G loss: 0.171]\n",
      "Epoch 2876 -- [D loss: -0.053(R 0.012, F -0.118)] [G loss: 0.129]\n",
      "Epoch 2877 -- [D loss: -0.050(R 0.005, F -0.106)] [G loss: 0.099]\n",
      "Epoch 2878 -- [D loss: -0.051(R 0.030, F -0.132)] [G loss: 0.069]\n",
      "Epoch 2879 -- [D loss: -0.061(R -0.030, F -0.092)] [G loss: 0.034]\n",
      "Epoch 2880 -- [D loss: -0.034(R 0.020, F -0.087)] [G loss: 0.014]\n",
      "Epoch 2881 -- [D loss: -0.047(R -0.068, F -0.026)] [G loss: -0.030]\n",
      "Epoch 2882 -- [D loss: -0.015(R -0.055, F 0.025)] [G loss: -0.052]\n",
      "Epoch 2883 -- [D loss: 0.024(R -0.002, F 0.049)] [G loss: -0.097]\n",
      "Epoch 2884 -- [D loss: 0.042(R -0.032, F 0.116)] [G loss: -0.131]\n",
      "Epoch 2885 -- [D loss: 0.026(R -0.123, F 0.174)] [G loss: -0.143]\n",
      "Epoch 2886 -- [D loss: 0.050(R -0.093, F 0.194)] [G loss: -0.179]\n",
      "Epoch 2887 -- [D loss: 0.038(R -0.136, F 0.212)] [G loss: -0.184]\n",
      "Epoch 2888 -- [D loss: 0.033(R -0.183, F 0.249)] [G loss: -0.228]\n",
      "Epoch 2889 -- [D loss: 0.049(R -0.166, F 0.264)] [G loss: -0.238]\n",
      "Epoch 2890 -- [D loss: 0.011(R -0.227, F 0.249)] [G loss: -0.247]\n",
      "Epoch 2891 -- [D loss: 0.006(R -0.246, F 0.258)] [G loss: -0.254]\n",
      "Epoch 2892 -- [D loss: 0.004(R -0.278, F 0.287)] [G loss: -0.258]\n",
      "Epoch 2893 -- [D loss: -0.004(R -0.314, F 0.306)] [G loss: -0.261]\n",
      "Epoch 2894 -- [D loss: -0.033(R -0.355, F 0.289)] [G loss: -0.260]\n",
      "Epoch 2895 -- [D loss: -0.030(R -0.377, F 0.318)] [G loss: -0.281]\n",
      "Epoch 2896 -- [D loss: -0.017(R -0.405, F 0.371)] [G loss: -0.315]\n",
      "Epoch 2897 -- [D loss: -0.006(R -0.410, F 0.398)] [G loss: -0.337]\n",
      "Epoch 2898 -- [D loss: -0.009(R -0.428, F 0.410)] [G loss: -0.351]\n",
      "Epoch 2899 -- [D loss: -0.011(R -0.442, F 0.419)] [G loss: -0.363]\n",
      "Epoch 2900 -- [D loss: -0.015(R -0.456, F 0.427)] [G loss: -0.392]\n",
      "INFO:tensorflow:Assets written to: ram://12874746-fe0b-47cb-9fb2-374189f7883e/assets\n",
      "INFO:tensorflow:Assets written to: ram://30e836e3-2f09-4973-bede-df2b1c336f72/assets\n",
      "INFO:tensorflow:Assets written to: ram://476428ac-4fe0-45b1-b6d1-c1c1a964ddbc/assets\n",
      "Epoch 2901 -- [D loss: -0.005(R -0.439, F 0.428)] [G loss: -0.404]\n",
      "Epoch 2902 -- [D loss: 0.027(R -0.427, F 0.481)] [G loss: -0.380]\n",
      "Epoch 2903 -- [D loss: -0.001(R -0.448, F 0.445)] [G loss: -0.386]\n",
      "Epoch 2904 -- [D loss: 0.022(R -0.457, F 0.501)] [G loss: -0.406]\n",
      "Epoch 2905 -- [D loss: 0.042(R -0.441, F 0.524)] [G loss: -0.402]\n",
      "Epoch 2906 -- [D loss: 0.029(R -0.405, F 0.463)] [G loss: -0.384]\n",
      "Epoch 2907 -- [D loss: 0.012(R -0.387, F 0.411)] [G loss: -0.367]\n",
      "Epoch 2908 -- [D loss: -0.003(R -0.400, F 0.393)] [G loss: -0.367]\n",
      "Epoch 2909 -- [D loss: 0.014(R -0.367, F 0.396)] [G loss: -0.382]\n",
      "Epoch 2910 -- [D loss: 0.016(R -0.360, F 0.391)] [G loss: -0.371]\n",
      "Epoch 2911 -- [D loss: 0.019(R -0.348, F 0.385)] [G loss: -0.343]\n",
      "Epoch 2912 -- [D loss: 0.015(R -0.334, F 0.363)] [G loss: -0.314]\n",
      "Epoch 2913 -- [D loss: 0.017(R -0.325, F 0.360)] [G loss: -0.312]\n",
      "Epoch 2914 -- [D loss: 0.012(R -0.312, F 0.335)] [G loss: -0.309]\n",
      "Epoch 2915 -- [D loss: 0.000(R -0.304, F 0.305)] [G loss: -0.282]\n",
      "Epoch 2916 -- [D loss: 0.003(R -0.303, F 0.309)] [G loss: -0.268]\n",
      "Epoch 2917 -- [D loss: -0.011(R -0.308, F 0.286)] [G loss: -0.281]\n",
      "Epoch 2918 -- [D loss: 0.010(R -0.300, F 0.321)] [G loss: -0.286]\n",
      "Epoch 2919 -- [D loss: 0.001(R -0.299, F 0.301)] [G loss: -0.281]\n",
      "Epoch 2920 -- [D loss: 0.002(R -0.287, F 0.292)] [G loss: -0.281]\n",
      "Epoch 2921 -- [D loss: 0.008(R -0.284, F 0.299)] [G loss: -0.280]\n",
      "Epoch 2922 -- [D loss: 0.006(R -0.277, F 0.290)] [G loss: -0.266]\n",
      "Epoch 2923 -- [D loss: 0.006(R -0.266, F 0.279)] [G loss: -0.247]\n",
      "Epoch 2924 -- [D loss: 0.000(R -0.262, F 0.262)] [G loss: -0.233]\n",
      "Epoch 2925 -- [D loss: -0.004(R -0.263, F 0.256)] [G loss: -0.226]\n",
      "Epoch 2926 -- [D loss: 0.000(R -0.249, F 0.250)] [G loss: -0.223]\n",
      "Epoch 2927 -- [D loss: 0.001(R -0.247, F 0.248)] [G loss: -0.218]\n",
      "Epoch 2928 -- [D loss: -0.000(R -0.244, F 0.244)] [G loss: -0.209]\n",
      "Epoch 2929 -- [D loss: -0.007(R -0.236, F 0.222)] [G loss: -0.195]\n",
      "Epoch 2930 -- [D loss: -0.004(R -0.234, F 0.225)] [G loss: -0.191]\n",
      "Epoch 2931 -- [D loss: -0.014(R -0.218, F 0.191)] [G loss: -0.171]\n",
      "Epoch 2932 -- [D loss: -0.016(R -0.209, F 0.178)] [G loss: -0.154]\n",
      "Epoch 2933 -- [D loss: -0.015(R -0.208, F 0.178)] [G loss: -0.161]\n",
      "Epoch 2934 -- [D loss: -0.031(R -0.233, F 0.171)] [G loss: -0.179]\n",
      "Epoch 2935 -- [D loss: -0.010(R -0.207, F 0.188)] [G loss: -0.187]\n",
      "Epoch 2936 -- [D loss: -0.006(R -0.197, F 0.186)] [G loss: -0.196]\n",
      "Epoch 2937 -- [D loss: -0.001(R -0.206, F 0.204)] [G loss: -0.207]\n",
      "Epoch 2938 -- [D loss: -0.004(R -0.217, F 0.208)] [G loss: -0.216]\n",
      "Epoch 2939 -- [D loss: 0.009(R -0.227, F 0.245)] [G loss: -0.241]\n",
      "Epoch 2940 -- [D loss: 0.008(R -0.229, F 0.246)] [G loss: -0.258]\n",
      "Epoch 2941 -- [D loss: 0.016(R -0.224, F 0.256)] [G loss: -0.259]\n",
      "Epoch 2942 -- [D loss: 0.009(R -0.237, F 0.254)] [G loss: -0.248]\n",
      "Epoch 2943 -- [D loss: 0.009(R -0.245, F 0.264)] [G loss: -0.243]\n",
      "Epoch 2944 -- [D loss: 0.010(R -0.244, F 0.264)] [G loss: -0.244]\n",
      "Epoch 2945 -- [D loss: 0.006(R -0.234, F 0.246)] [G loss: -0.225]\n",
      "Epoch 2946 -- [D loss: -0.006(R -0.251, F 0.239)] [G loss: -0.220]\n",
      "Epoch 2947 -- [D loss: -0.011(R -0.263, F 0.241)] [G loss: -0.213]\n",
      "Epoch 2948 -- [D loss: -0.018(R -0.270, F 0.235)] [G loss: -0.214]\n",
      "Epoch 2949 -- [D loss: -0.026(R -0.285, F 0.232)] [G loss: -0.207]\n",
      "Epoch 2950 -- [D loss: -0.020(R -0.288, F 0.247)] [G loss: -0.194]\n",
      "Epoch 2951 -- [D loss: -0.020(R -0.303, F 0.262)] [G loss: -0.217]\n",
      "Epoch 2952 -- [D loss: -0.026(R -0.307, F 0.255)] [G loss: -0.224]\n",
      "Epoch 2953 -- [D loss: -0.062(R -0.339, F 0.214)] [G loss: -0.227]\n",
      "Epoch 2954 -- [D loss: -0.057(R -0.371, F 0.257)] [G loss: -0.297]\n",
      "Epoch 2955 -- [D loss: -0.030(R -0.336, F 0.275)] [G loss: -0.346]\n",
      "Epoch 2956 -- [D loss: -0.009(R -0.348, F 0.330)] [G loss: -0.414]\n",
      "Epoch 2957 -- [D loss: -0.050(R -0.385, F 0.285)] [G loss: -0.487]\n",
      "Epoch 2958 -- [D loss: -0.013(R -0.369, F 0.343)] [G loss: -0.531]\n",
      "Epoch 2959 -- [D loss: -0.011(R -0.372, F 0.350)] [G loss: -0.539]\n",
      "Epoch 2960 -- [D loss: 0.028(R -0.353, F 0.409)] [G loss: -0.520]\n",
      "Epoch 2961 -- [D loss: 0.030(R -0.356, F 0.415)] [G loss: -0.490]\n",
      "Epoch 2962 -- [D loss: 0.031(R -0.328, F 0.390)] [G loss: -0.446]\n",
      "Epoch 2963 -- [D loss: 0.028(R -0.339, F 0.395)] [G loss: -0.410]\n",
      "Epoch 2964 -- [D loss: 0.033(R -0.304, F 0.371)] [G loss: -0.372]\n",
      "Epoch 2965 -- [D loss: 0.022(R -0.299, F 0.344)] [G loss: -0.343]\n",
      "Epoch 2966 -- [D loss: 0.006(R -0.307, F 0.319)] [G loss: -0.312]\n",
      "Epoch 2967 -- [D loss: 0.014(R -0.285, F 0.314)] [G loss: -0.282]\n",
      "Epoch 2968 -- [D loss: 0.011(R -0.269, F 0.291)] [G loss: -0.251]\n",
      "Epoch 2969 -- [D loss: 0.005(R -0.270, F 0.280)] [G loss: -0.202]\n",
      "Epoch 2970 -- [D loss: -0.011(R -0.252, F 0.230)] [G loss: -0.166]\n",
      "Epoch 2971 -- [D loss: -0.022(R -0.238, F 0.194)] [G loss: -0.120]\n",
      "Epoch 2972 -- [D loss: -0.025(R -0.208, F 0.159)] [G loss: -0.084]\n",
      "Epoch 2973 -- [D loss: -0.051(R -0.217, F 0.114)] [G loss: -0.064]\n",
      "Epoch 2974 -- [D loss: -0.052(R -0.209, F 0.104)] [G loss: -0.050]\n",
      "Epoch 2975 -- [D loss: -0.071(R -0.217, F 0.075)] [G loss: -0.054]\n",
      "Epoch 2976 -- [D loss: -0.071(R -0.202, F 0.060)] [G loss: -0.055]\n",
      "Epoch 2977 -- [D loss: -0.060(R -0.193, F 0.073)] [G loss: -0.086]\n",
      "Epoch 2978 -- [D loss: -0.069(R -0.205, F 0.066)] [G loss: -0.104]\n",
      "Epoch 2979 -- [D loss: -0.064(R -0.195, F 0.067)] [G loss: -0.131]\n",
      "Epoch 2980 -- [D loss: -0.094(R -0.248, F 0.060)] [G loss: -0.181]\n",
      "Epoch 2981 -- [D loss: -0.073(R -0.227, F 0.082)] [G loss: -0.223]\n",
      "Epoch 2982 -- [D loss: -0.042(R -0.206, F 0.121)] [G loss: -0.267]\n",
      "Epoch 2983 -- [D loss: -0.036(R -0.208, F 0.136)] [G loss: -0.304]\n",
      "Epoch 2984 -- [D loss: -0.020(R -0.217, F 0.177)] [G loss: -0.345]\n",
      "Epoch 2985 -- [D loss: -0.007(R -0.233, F 0.218)] [G loss: -0.333]\n",
      "Epoch 2986 -- [D loss: 0.002(R -0.237, F 0.240)] [G loss: -0.358]\n",
      "Epoch 2987 -- [D loss: -0.006(R -0.246, F 0.234)] [G loss: -0.371]\n",
      "Epoch 2988 -- [D loss: 0.000(R -0.268, F 0.269)] [G loss: -0.367]\n",
      "Epoch 2989 -- [D loss: 0.005(R -0.278, F 0.287)] [G loss: -0.382]\n",
      "Epoch 2990 -- [D loss: 0.017(R -0.301, F 0.334)] [G loss: -0.386]\n",
      "Epoch 2991 -- [D loss: 0.043(R -0.299, F 0.386)] [G loss: -0.375]\n",
      "Epoch 2992 -- [D loss: 0.016(R -0.352, F 0.384)] [G loss: -0.379]\n",
      "Epoch 2993 -- [D loss: 0.003(R -0.354, F 0.360)] [G loss: -0.362]\n",
      "Epoch 2994 -- [D loss: -0.009(R -0.382, F 0.365)] [G loss: -0.343]\n",
      "Epoch 2995 -- [D loss: -0.017(R -0.383, F 0.350)] [G loss: -0.329]\n",
      "Epoch 2996 -- [D loss: -0.021(R -0.384, F 0.341)] [G loss: -0.306]\n",
      "Epoch 2997 -- [D loss: -0.025(R -0.386, F 0.336)] [G loss: -0.299]\n",
      "Epoch 2998 -- [D loss: -0.051(R -0.419, F 0.316)] [G loss: -0.296]\n",
      "Epoch 2999 -- [D loss: -0.049(R -0.430, F 0.333)] [G loss: -0.307]\n",
      "Epoch 3000 -- [D loss: -0.054(R -0.463, F 0.355)] [G loss: -0.322]\n",
      "INFO:tensorflow:Assets written to: ram://c7a82ad0-8c82-4f86-9115-f9c480ee1251/assets\n",
      "INFO:tensorflow:Assets written to: ram://03383973-5d21-4d5b-96c6-9f3bfe67dbe8/assets\n",
      "INFO:tensorflow:Assets written to: ram://c2ae9845-45cc-4e30-8941-19bf97a50bac/assets\n",
      "Epoch 3001 -- [D loss: -0.045(R -0.499, F 0.408)] [G loss: -0.350]\n",
      "Epoch 3002 -- [D loss: -0.034(R -0.478, F 0.409)] [G loss: -0.371]\n",
      "Epoch 3003 -- [D loss: -0.050(R -0.529, F 0.429)] [G loss: -0.405]\n",
      "Epoch 3004 -- [D loss: -0.051(R -0.505, F 0.403)] [G loss: -0.415]\n",
      "Epoch 3005 -- [D loss: -0.031(R -0.536, F 0.473)] [G loss: -0.476]\n",
      "Epoch 3006 -- [D loss: -0.034(R -0.510, F 0.441)] [G loss: -0.504]\n",
      "Epoch 3007 -- [D loss: -0.028(R -0.524, F 0.469)] [G loss: -0.532]\n",
      "Epoch 3008 -- [D loss: -0.045(R -0.529, F 0.439)] [G loss: -0.637]\n",
      "Epoch 3009 -- [D loss: -0.092(R -0.562, F 0.379)] [G loss: -0.750]\n",
      "Epoch 3010 -- [D loss: -0.045(R -0.622, F 0.531)] [G loss: -0.820]\n",
      "Epoch 3011 -- [D loss: -0.038(R -0.577, F 0.502)] [G loss: -0.882]\n",
      "Epoch 3012 -- [D loss: 0.038(R -0.440, F 0.515)] [G loss: -0.927]\n",
      "Epoch 3013 -- [D loss: -0.018(R -0.537, F 0.501)] [G loss: -0.908]\n",
      "Epoch 3014 -- [D loss: 0.086(R -0.453, F 0.625)] [G loss: -0.852]\n",
      "Epoch 3015 -- [D loss: 0.070(R -0.415, F 0.555)] [G loss: -0.753]\n",
      "Epoch 3016 -- [D loss: 0.081(R -0.353, F 0.515)] [G loss: -0.560]\n",
      "Epoch 3017 -- [D loss: 0.041(R -0.320, F 0.402)] [G loss: -0.372]\n",
      "Epoch 3018 -- [D loss: 0.021(R -0.265, F 0.307)] [G loss: -0.249]\n",
      "Epoch 3019 -- [D loss: 0.022(R -0.197, F 0.241)] [G loss: -0.134]\n",
      "Epoch 3020 -- [D loss: 0.006(R -0.151, F 0.162)] [G loss: -0.036]\n",
      "Epoch 3021 -- [D loss: -0.025(R -0.130, F 0.080)] [G loss: 0.037]\n",
      "Epoch 3022 -- [D loss: -0.032(R -0.096, F 0.032)] [G loss: 0.102]\n",
      "Epoch 3023 -- [D loss: -0.072(R -0.052, F -0.092)] [G loss: 0.166]\n",
      "Epoch 3024 -- [D loss: -0.074(R 0.001, F -0.149)] [G loss: 0.215]\n",
      "Epoch 3025 -- [D loss: -0.099(R 0.022, F -0.219)] [G loss: 0.236]\n",
      "Epoch 3026 -- [D loss: -0.133(R -0.016, F -0.251)] [G loss: 0.231]\n",
      "Epoch 3027 -- [D loss: -0.113(R 0.031, F -0.257)] [G loss: 0.219]\n",
      "Epoch 3028 -- [D loss: -0.120(R -0.001, F -0.239)] [G loss: 0.185]\n",
      "Epoch 3029 -- [D loss: -0.144(R -0.008, F -0.280)] [G loss: 0.162]\n",
      "Epoch 3030 -- [D loss: -0.150(R -0.041, F -0.260)] [G loss: 0.116]\n",
      "Epoch 3031 -- [D loss: -0.152(R -0.010, F -0.293)] [G loss: 0.077]\n",
      "Epoch 3032 -- [D loss: -0.098(R -0.074, F -0.122)] [G loss: 0.014]\n",
      "Epoch 3033 -- [D loss: -0.073(R 0.021, F -0.166)] [G loss: -0.037]\n",
      "Epoch 3034 -- [D loss: -0.069(R -0.077, F -0.062)] [G loss: -0.080]\n",
      "Epoch 3035 -- [D loss: -0.035(R -0.051, F -0.018)] [G loss: -0.134]\n",
      "Epoch 3036 -- [D loss: -0.045(R -0.048, F -0.042)] [G loss: -0.199]\n",
      "Epoch 3037 -- [D loss: 0.002(R -0.126, F 0.129)] [G loss: -0.210]\n",
      "Epoch 3038 -- [D loss: 0.065(R -0.050, F 0.181)] [G loss: -0.252]\n",
      "Epoch 3039 -- [D loss: 0.014(R -0.184, F 0.211)] [G loss: -0.301]\n",
      "Epoch 3040 -- [D loss: 0.051(R -0.195, F 0.296)] [G loss: -0.311]\n",
      "Epoch 3041 -- [D loss: 0.015(R -0.317, F 0.347)] [G loss: -0.331]\n",
      "Epoch 3042 -- [D loss: 0.051(R -0.338, F 0.440)] [G loss: -0.391]\n",
      "Epoch 3043 -- [D loss: 0.027(R -0.393, F 0.448)] [G loss: -0.428]\n",
      "Epoch 3044 -- [D loss: 0.026(R -0.423, F 0.475)] [G loss: -0.458]\n",
      "Epoch 3045 -- [D loss: 0.036(R -0.424, F 0.496)] [G loss: -0.470]\n",
      "Epoch 3046 -- [D loss: 0.047(R -0.437, F 0.531)] [G loss: -0.474]\n",
      "Epoch 3047 -- [D loss: 0.033(R -0.454, F 0.520)] [G loss: -0.465]\n",
      "Epoch 3048 -- [D loss: 0.020(R -0.488, F 0.529)] [G loss: -0.464]\n",
      "Epoch 3049 -- [D loss: -0.001(R -0.484, F 0.482)] [G loss: -0.460]\n",
      "Epoch 3050 -- [D loss: -0.003(R -0.468, F 0.462)] [G loss: -0.433]\n",
      "Epoch 3051 -- [D loss: 0.006(R -0.493, F 0.506)] [G loss: -0.406]\n",
      "Epoch 3052 -- [D loss: -0.022(R -0.483, F 0.440)] [G loss: -0.391]\n",
      "Epoch 3053 -- [D loss: -0.017(R -0.488, F 0.455)] [G loss: -0.381]\n",
      "Epoch 3054 -- [D loss: 0.008(R -0.444, F 0.460)] [G loss: -0.350]\n",
      "Epoch 3055 -- [D loss: -0.015(R -0.424, F 0.394)] [G loss: -0.334]\n",
      "Epoch 3056 -- [D loss: -0.038(R -0.464, F 0.389)] [G loss: -0.344]\n",
      "Epoch 3057 -- [D loss: -0.033(R -0.437, F 0.371)] [G loss: -0.340]\n",
      "Epoch 3058 -- [D loss: -0.026(R -0.449, F 0.397)] [G loss: -0.359]\n",
      "Epoch 3059 -- [D loss: -0.042(R -0.447, F 0.364)] [G loss: -0.403]\n",
      "Epoch 3060 -- [D loss: -0.042(R -0.432, F 0.347)] [G loss: -0.447]\n",
      "Epoch 3061 -- [D loss: -0.059(R -0.486, F 0.368)] [G loss: -0.500]\n",
      "Epoch 3062 -- [D loss: -0.032(R -0.492, F 0.427)] [G loss: -0.591]\n",
      "Epoch 3063 -- [D loss: -0.030(R -0.529, F 0.469)] [G loss: -0.660]\n",
      "Epoch 3064 -- [D loss: -0.011(R -0.502, F 0.480)] [G loss: -0.721]\n",
      "Epoch 3065 -- [D loss: 0.004(R -0.515, F 0.523)] [G loss: -0.760]\n",
      "Epoch 3066 -- [D loss: -0.030(R -0.537, F 0.477)] [G loss: -0.780]\n",
      "Epoch 3067 -- [D loss: 0.014(R -0.560, F 0.589)] [G loss: -0.777]\n",
      "Epoch 3068 -- [D loss: 0.014(R -0.550, F 0.577)] [G loss: -0.747]\n",
      "Epoch 3069 -- [D loss: 0.061(R -0.463, F 0.585)] [G loss: -0.666]\n",
      "Epoch 3070 -- [D loss: 0.035(R -0.465, F 0.535)] [G loss: -0.586]\n",
      "Epoch 3071 -- [D loss: 0.041(R -0.424, F 0.506)] [G loss: -0.478]\n",
      "Epoch 3072 -- [D loss: 0.016(R -0.390, F 0.421)] [G loss: -0.385]\n",
      "Epoch 3073 -- [D loss: -0.017(R -0.354, F 0.320)] [G loss: -0.295]\n",
      "Epoch 3074 -- [D loss: -0.030(R -0.338, F 0.278)] [G loss: -0.218]\n",
      "Epoch 3075 -- [D loss: -0.046(R -0.312, F 0.219)] [G loss: -0.163]\n",
      "Epoch 3076 -- [D loss: -0.048(R -0.278, F 0.182)] [G loss: -0.108]\n",
      "Epoch 3077 -- [D loss: -0.058(R -0.238, F 0.123)] [G loss: -0.041]\n",
      "Epoch 3078 -- [D loss: -0.065(R -0.188, F 0.057)] [G loss: 0.029]\n",
      "Epoch 3079 -- [D loss: -0.094(R -0.137, F -0.051)] [G loss: 0.113]\n",
      "Epoch 3080 -- [D loss: -0.128(R -0.097, F -0.158)] [G loss: 0.152]\n",
      "Epoch 3081 -- [D loss: -0.158(R -0.112, F -0.203)] [G loss: 0.177]\n",
      "Epoch 3082 -- [D loss: -0.119(R -0.026, F -0.212)] [G loss: 0.157]\n",
      "Epoch 3083 -- [D loss: -0.107(R 0.018, F -0.233)] [G loss: 0.161]\n",
      "Epoch 3084 -- [D loss: -0.111(R 0.064, F -0.286)] [G loss: 0.112]\n",
      "Epoch 3085 -- [D loss: -0.125(R -0.009, F -0.242)] [G loss: 0.072]\n",
      "Epoch 3086 -- [D loss: -0.055(R 0.007, F -0.117)] [G loss: 0.012]\n",
      "Epoch 3087 -- [D loss: -0.070(R -0.008, F -0.132)] [G loss: -0.066]\n",
      "Epoch 3088 -- [D loss: -0.069(R -0.074, F -0.064)] [G loss: -0.130]\n",
      "Epoch 3089 -- [D loss: -0.018(R -0.130, F 0.094)] [G loss: -0.205]\n",
      "Epoch 3090 -- [D loss: 0.018(R -0.058, F 0.093)] [G loss: -0.267]\n",
      "Epoch 3091 -- [D loss: 0.041(R -0.103, F 0.184)] [G loss: -0.362]\n",
      "Epoch 3092 -- [D loss: 0.017(R -0.189, F 0.222)] [G loss: -0.436]\n",
      "Epoch 3093 -- [D loss: 0.022(R -0.247, F 0.290)] [G loss: -0.462]\n",
      "Epoch 3094 -- [D loss: 0.031(R -0.323, F 0.384)] [G loss: -0.496]\n",
      "Epoch 3095 -- [D loss: 0.073(R -0.303, F 0.448)] [G loss: -0.518]\n",
      "Epoch 3096 -- [D loss: 0.047(R -0.345, F 0.438)] [G loss: -0.507]\n",
      "Epoch 3097 -- [D loss: 0.049(R -0.361, F 0.459)] [G loss: -0.519]\n",
      "Epoch 3098 -- [D loss: 0.041(R -0.375, F 0.457)] [G loss: -0.491]\n",
      "Epoch 3099 -- [D loss: 0.039(R -0.381, F 0.459)] [G loss: -0.451]\n",
      "Epoch 3100 -- [D loss: 0.042(R -0.370, F 0.455)] [G loss: -0.438]\n",
      "INFO:tensorflow:Assets written to: ram://111e675b-e9eb-4361-9306-a9b3b238739d/assets\n",
      "INFO:tensorflow:Assets written to: ram://613b4869-901a-4e89-af31-f9ecc3be09e7/assets\n",
      "INFO:tensorflow:Assets written to: ram://f2b96170-6b91-43f2-9bc7-fb883e9902c8/assets\n",
      "Epoch 3101 -- [D loss: 0.001(R -0.411, F 0.413)] [G loss: -0.396]\n",
      "Epoch 3102 -- [D loss: -0.016(R -0.412, F 0.380)] [G loss: -0.348]\n",
      "Epoch 3103 -- [D loss: -0.047(R -0.441, F 0.347)] [G loss: -0.316]\n",
      "Epoch 3104 -- [D loss: -0.043(R -0.441, F 0.356)] [G loss: -0.301]\n",
      "Epoch 3105 -- [D loss: -0.057(R -0.455, F 0.341)] [G loss: -0.267]\n",
      "Epoch 3106 -- [D loss: -0.085(R -0.500, F 0.331)] [G loss: -0.252]\n",
      "Epoch 3107 -- [D loss: -0.076(R -0.510, F 0.357)] [G loss: -0.272]\n",
      "Epoch 3108 -- [D loss: -0.090(R -0.528, F 0.348)] [G loss: -0.283]\n",
      "Epoch 3109 -- [D loss: -0.058(R -0.558, F 0.441)] [G loss: -0.313]\n",
      "Epoch 3110 -- [D loss: -0.004(R -0.483, F 0.474)] [G loss: -0.297]\n",
      "Epoch 3111 -- [D loss: -0.007(R -0.494, F 0.480)] [G loss: -0.311]\n",
      "Epoch 3112 -- [D loss: -0.023(R -0.448, F 0.403)] [G loss: -0.324]\n",
      "Epoch 3113 -- [D loss: -0.040(R -0.479, F 0.400)] [G loss: -0.377]\n",
      "Epoch 3114 -- [D loss: 0.014(R -0.416, F 0.445)] [G loss: -0.389]\n",
      "Epoch 3115 -- [D loss: 0.019(R -0.435, F 0.473)] [G loss: -0.404]\n",
      "Epoch 3116 -- [D loss: -0.050(R -0.466, F 0.366)] [G loss: -0.452]\n",
      "Epoch 3117 -- [D loss: -0.007(R -0.403, F 0.389)] [G loss: -0.501]\n",
      "Epoch 3118 -- [D loss: 0.007(R -0.406, F 0.419)] [G loss: -0.540]\n",
      "Epoch 3119 -- [D loss: 0.003(R -0.413, F 0.420)] [G loss: -0.547]\n",
      "Epoch 3120 -- [D loss: 0.000(R -0.425, F 0.425)] [G loss: -0.542]\n",
      "Epoch 3121 -- [D loss: 0.003(R -0.452, F 0.458)] [G loss: -0.579]\n",
      "Epoch 3122 -- [D loss: 0.026(R -0.375, F 0.427)] [G loss: -0.548]\n",
      "Epoch 3123 -- [D loss: 0.033(R -0.407, F 0.473)] [G loss: -0.520]\n",
      "Epoch 3124 -- [D loss: 0.052(R -0.358, F 0.462)] [G loss: -0.463]\n",
      "Epoch 3125 -- [D loss: 0.058(R -0.347, F 0.463)] [G loss: -0.409]\n",
      "Epoch 3126 -- [D loss: 0.032(R -0.336, F 0.400)] [G loss: -0.345]\n",
      "Epoch 3127 -- [D loss: 0.019(R -0.304, F 0.343)] [G loss: -0.295]\n",
      "Epoch 3128 -- [D loss: -0.003(R -0.286, F 0.280)] [G loss: -0.210]\n",
      "Epoch 3129 -- [D loss: -0.003(R -0.273, F 0.267)] [G loss: -0.166]\n",
      "Epoch 3130 -- [D loss: -0.008(R -0.223, F 0.208)] [G loss: -0.118]\n",
      "Epoch 3131 -- [D loss: -0.019(R -0.221, F 0.182)] [G loss: -0.092]\n",
      "Epoch 3132 -- [D loss: -0.006(R -0.199, F 0.188)] [G loss: -0.060]\n",
      "Epoch 3133 -- [D loss: -0.044(R -0.222, F 0.133)] [G loss: -0.039]\n",
      "Epoch 3134 -- [D loss: -0.049(R -0.153, F 0.056)] [G loss: -0.031]\n",
      "Epoch 3135 -- [D loss: -0.049(R -0.170, F 0.073)] [G loss: -0.024]\n",
      "Epoch 3136 -- [D loss: -0.032(R -0.125, F 0.061)] [G loss: -0.021]\n",
      "Epoch 3137 -- [D loss: -0.048(R -0.113, F 0.017)] [G loss: -0.041]\n",
      "Epoch 3138 -- [D loss: -0.057(R -0.104, F -0.010)] [G loss: -0.036]\n",
      "Epoch 3139 -- [D loss: -0.080(R -0.107, F -0.054)] [G loss: -0.036]\n",
      "Epoch 3140 -- [D loss: -0.005(R -0.084, F 0.074)] [G loss: -0.071]\n",
      "Epoch 3141 -- [D loss: -0.006(R -0.040, F 0.029)] [G loss: -0.082]\n",
      "Epoch 3142 -- [D loss: 0.033(R -0.059, F 0.125)] [G loss: -0.121]\n",
      "Epoch 3143 -- [D loss: 0.053(R -0.082, F 0.188)] [G loss: -0.148]\n",
      "Epoch 3144 -- [D loss: 0.057(R -0.097, F 0.210)] [G loss: -0.172]\n",
      "Epoch 3145 -- [D loss: 0.056(R -0.145, F 0.258)] [G loss: -0.201]\n",
      "Epoch 3146 -- [D loss: 0.044(R -0.168, F 0.257)] [G loss: -0.214]\n",
      "Epoch 3147 -- [D loss: 0.018(R -0.211, F 0.248)] [G loss: -0.225]\n",
      "Epoch 3148 -- [D loss: 0.012(R -0.221, F 0.245)] [G loss: -0.231]\n",
      "Epoch 3149 -- [D loss: -0.004(R -0.247, F 0.238)] [G loss: -0.219]\n",
      "Epoch 3150 -- [D loss: -0.008(R -0.239, F 0.223)] [G loss: -0.213]\n",
      "Epoch 3151 -- [D loss: -0.006(R -0.235, F 0.223)] [G loss: -0.202]\n",
      "Epoch 3152 -- [D loss: -0.022(R -0.257, F 0.213)] [G loss: -0.202]\n",
      "Epoch 3153 -- [D loss: -0.010(R -0.258, F 0.238)] [G loss: -0.203]\n",
      "Epoch 3154 -- [D loss: -0.021(R -0.267, F 0.224)] [G loss: -0.205]\n",
      "Epoch 3155 -- [D loss: -0.022(R -0.270, F 0.226)] [G loss: -0.203]\n",
      "Epoch 3156 -- [D loss: -0.025(R -0.271, F 0.222)] [G loss: -0.224]\n",
      "Epoch 3157 -- [D loss: -0.028(R -0.289, F 0.233)] [G loss: -0.237]\n",
      "Epoch 3158 -- [D loss: -0.025(R -0.306, F 0.255)] [G loss: -0.248]\n",
      "Epoch 3159 -- [D loss: -0.010(R -0.314, F 0.294)] [G loss: -0.254]\n",
      "Epoch 3160 -- [D loss: -0.019(R -0.326, F 0.287)] [G loss: -0.267]\n",
      "Epoch 3161 -- [D loss: -0.006(R -0.305, F 0.294)] [G loss: -0.285]\n",
      "Epoch 3162 -- [D loss: -0.002(R -0.315, F 0.310)] [G loss: -0.298]\n",
      "Epoch 3163 -- [D loss: -0.009(R -0.311, F 0.294)] [G loss: -0.305]\n",
      "Epoch 3164 -- [D loss: -0.017(R -0.346, F 0.313)] [G loss: -0.339]\n",
      "Epoch 3165 -- [D loss: -0.009(R -0.343, F 0.325)] [G loss: -0.361]\n",
      "Epoch 3166 -- [D loss: -0.009(R -0.383, F 0.365)] [G loss: -0.397]\n",
      "Epoch 3167 -- [D loss: -0.002(R -0.368, F 0.363)] [G loss: -0.412]\n",
      "Epoch 3168 -- [D loss: 0.000(R -0.376, F 0.377)] [G loss: -0.415]\n",
      "Epoch 3169 -- [D loss: -0.003(R -0.383, F 0.376)] [G loss: -0.419]\n",
      "Epoch 3170 -- [D loss: 0.025(R -0.354, F 0.403)] [G loss: -0.422]\n",
      "Epoch 3171 -- [D loss: 0.025(R -0.353, F 0.404)] [G loss: -0.407]\n",
      "Epoch 3172 -- [D loss: 0.022(R -0.347, F 0.391)] [G loss: -0.378]\n",
      "Epoch 3173 -- [D loss: 0.010(R -0.356, F 0.376)] [G loss: -0.352]\n",
      "Epoch 3174 -- [D loss: -0.021(R -0.395, F 0.352)] [G loss: -0.345]\n",
      "Epoch 3175 -- [D loss: -0.004(R -0.333, F 0.324)] [G loss: -0.343]\n",
      "Epoch 3176 -- [D loss: 0.021(R -0.339, F 0.381)] [G loss: -0.322]\n",
      "Epoch 3177 -- [D loss: 0.027(R -0.322, F 0.376)] [G loss: -0.313]\n",
      "Epoch 3178 -- [D loss: 0.008(R -0.282, F 0.299)] [G loss: -0.293]\n",
      "Epoch 3179 -- [D loss: 0.017(R -0.295, F 0.330)] [G loss: -0.267]\n",
      "Epoch 3180 -- [D loss: 0.026(R -0.261, F 0.313)] [G loss: -0.240]\n",
      "Epoch 3181 -- [D loss: -0.005(R -0.261, F 0.251)] [G loss: -0.196]\n",
      "Epoch 3182 -- [D loss: -0.025(R -0.225, F 0.176)] [G loss: -0.156]\n",
      "Epoch 3183 -- [D loss: -0.024(R -0.208, F 0.159)] [G loss: -0.107]\n",
      "Epoch 3184 -- [D loss: -0.020(R -0.146, F 0.106)] [G loss: -0.083]\n",
      "Epoch 3185 -- [D loss: -0.025(R -0.138, F 0.088)] [G loss: -0.063]\n",
      "Epoch 3186 -- [D loss: -0.035(R -0.121, F 0.050)] [G loss: -0.074]\n",
      "Epoch 3187 -- [D loss: -0.044(R -0.133, F 0.045)] [G loss: -0.075]\n",
      "Epoch 3188 -- [D loss: -0.012(R -0.112, F 0.088)] [G loss: -0.081]\n",
      "Epoch 3189 -- [D loss: -0.002(R -0.133, F 0.128)] [G loss: -0.095]\n",
      "Epoch 3190 -- [D loss: -0.003(R -0.135, F 0.129)] [G loss: -0.101]\n",
      "Epoch 3191 -- [D loss: -0.006(R -0.127, F 0.115)] [G loss: -0.112]\n",
      "Epoch 3192 -- [D loss: -0.004(R -0.130, F 0.123)] [G loss: -0.128]\n",
      "Epoch 3193 -- [D loss: -0.023(R -0.140, F 0.094)] [G loss: -0.145]\n",
      "Epoch 3194 -- [D loss: -0.004(R -0.132, F 0.125)] [G loss: -0.167]\n",
      "Epoch 3195 -- [D loss: -0.014(R -0.191, F 0.163)] [G loss: -0.200]\n",
      "Epoch 3196 -- [D loss: 0.003(R -0.204, F 0.210)] [G loss: -0.221]\n",
      "Epoch 3197 -- [D loss: -0.003(R -0.208, F 0.203)] [G loss: -0.253]\n",
      "Epoch 3198 -- [D loss: -0.014(R -0.259, F 0.230)] [G loss: -0.274]\n",
      "Epoch 3199 -- [D loss: -0.004(R -0.208, F 0.199)] [G loss: -0.275]\n",
      "Epoch 3200 -- [D loss: -0.000(R -0.244, F 0.243)] [G loss: -0.260]\n",
      "INFO:tensorflow:Assets written to: ram://2b2499d1-5e2a-4b67-91da-9badea421834/assets\n",
      "INFO:tensorflow:Assets written to: ram://d223af9a-f7f1-4077-b775-be5ca1ba1fa7/assets\n",
      "INFO:tensorflow:Assets written to: ram://63b1b46f-3be2-4d84-bbb3-8f91ff6459e6/assets\n",
      "Epoch 3201 -- [D loss: 0.046(R -0.230, F 0.323)] [G loss: -0.280]\n",
      "Epoch 3202 -- [D loss: 0.023(R -0.272, F 0.317)] [G loss: -0.261]\n",
      "Epoch 3203 -- [D loss: 0.018(R -0.251, F 0.287)] [G loss: -0.251]\n",
      "Epoch 3204 -- [D loss: 0.002(R -0.259, F 0.264)] [G loss: -0.247]\n",
      "Epoch 3205 -- [D loss: 0.002(R -0.255, F 0.258)] [G loss: -0.241]\n",
      "Epoch 3206 -- [D loss: 0.007(R -0.256, F 0.269)] [G loss: -0.231]\n",
      "Epoch 3207 -- [D loss: 0.001(R -0.253, F 0.256)] [G loss: -0.226]\n",
      "Epoch 3208 -- [D loss: -0.008(R -0.239, F 0.223)] [G loss: -0.201]\n",
      "Epoch 3209 -- [D loss: -0.016(R -0.246, F 0.214)] [G loss: -0.182]\n",
      "Epoch 3210 -- [D loss: -0.010(R -0.229, F 0.210)] [G loss: -0.185]\n",
      "Epoch 3211 -- [D loss: -0.015(R -0.243, F 0.213)] [G loss: -0.186]\n",
      "Epoch 3212 -- [D loss: -0.029(R -0.246, F 0.189)] [G loss: -0.186]\n",
      "Epoch 3213 -- [D loss: -0.015(R -0.248, F 0.218)] [G loss: -0.203]\n",
      "Epoch 3214 -- [D loss: -0.009(R -0.264, F 0.246)] [G loss: -0.211]\n",
      "Epoch 3215 -- [D loss: -0.035(R -0.275, F 0.205)] [G loss: -0.207]\n",
      "Epoch 3216 -- [D loss: -0.028(R -0.284, F 0.228)] [G loss: -0.232]\n",
      "Epoch 3217 -- [D loss: -0.018(R -0.274, F 0.237)] [G loss: -0.243]\n",
      "Epoch 3218 -- [D loss: -0.033(R -0.268, F 0.201)] [G loss: -0.234]\n",
      "Epoch 3219 -- [D loss: 0.006(R -0.251, F 0.264)] [G loss: -0.230]\n",
      "Epoch 3220 -- [D loss: 0.003(R -0.266, F 0.271)] [G loss: -0.246]\n",
      "Epoch 3221 -- [D loss: 0.020(R -0.240, F 0.280)] [G loss: -0.242]\n",
      "Epoch 3222 -- [D loss: 0.007(R -0.245, F 0.259)] [G loss: -0.224]\n",
      "Epoch 3223 -- [D loss: -0.001(R -0.221, F 0.218)] [G loss: -0.210]\n",
      "Epoch 3224 -- [D loss: 0.000(R -0.202, F 0.203)] [G loss: -0.192]\n",
      "Epoch 3225 -- [D loss: 0.007(R -0.189, F 0.203)] [G loss: -0.183]\n",
      "Epoch 3226 -- [D loss: -0.001(R -0.181, F 0.179)] [G loss: -0.169]\n",
      "Epoch 3227 -- [D loss: 0.006(R -0.151, F 0.163)] [G loss: -0.162]\n",
      "Epoch 3228 -- [D loss: 0.014(R -0.132, F 0.160)] [G loss: -0.150]\n",
      "Epoch 3229 -- [D loss: 0.005(R -0.137, F 0.147)] [G loss: -0.151]\n",
      "Epoch 3230 -- [D loss: 0.009(R -0.124, F 0.143)] [G loss: -0.134]\n",
      "Epoch 3231 -- [D loss: 0.012(R -0.116, F 0.139)] [G loss: -0.136]\n",
      "Epoch 3232 -- [D loss: -0.000(R -0.136, F 0.135)] [G loss: -0.127]\n",
      "Epoch 3233 -- [D loss: 0.011(R -0.117, F 0.139)] [G loss: -0.118]\n",
      "Epoch 3234 -- [D loss: 0.003(R -0.137, F 0.143)] [G loss: -0.112]\n",
      "Epoch 3235 -- [D loss: -0.008(R -0.128, F 0.113)] [G loss: -0.093]\n",
      "Epoch 3236 -- [D loss: -0.029(R -0.128, F 0.071)] [G loss: -0.082]\n",
      "Epoch 3237 -- [D loss: -0.046(R -0.122, F 0.031)] [G loss: -0.062]\n",
      "Epoch 3238 -- [D loss: -0.038(R -0.108, F 0.031)] [G loss: -0.055]\n",
      "Epoch 3239 -- [D loss: -0.050(R -0.119, F 0.019)] [G loss: -0.056]\n",
      "Epoch 3240 -- [D loss: -0.056(R -0.146, F 0.034)] [G loss: -0.075]\n",
      "Epoch 3241 -- [D loss: -0.045(R -0.133, F 0.043)] [G loss: -0.097]\n",
      "Epoch 3242 -- [D loss: -0.018(R -0.134, F 0.098)] [G loss: -0.123]\n",
      "Epoch 3243 -- [D loss: -0.020(R -0.156, F 0.116)] [G loss: -0.148]\n",
      "Epoch 3244 -- [D loss: -0.008(R -0.165, F 0.148)] [G loss: -0.170]\n",
      "Epoch 3245 -- [D loss: 0.004(R -0.178, F 0.186)] [G loss: -0.197]\n",
      "Epoch 3246 -- [D loss: 0.022(R -0.181, F 0.224)] [G loss: -0.211]\n",
      "Epoch 3247 -- [D loss: 0.029(R -0.180, F 0.238)] [G loss: -0.216]\n",
      "Epoch 3248 -- [D loss: 0.016(R -0.201, F 0.234)] [G loss: -0.215]\n",
      "Epoch 3249 -- [D loss: 0.012(R -0.205, F 0.229)] [G loss: -0.204]\n",
      "Epoch 3250 -- [D loss: 0.002(R -0.207, F 0.212)] [G loss: -0.196]\n",
      "Epoch 3251 -- [D loss: -0.010(R -0.222, F 0.203)] [G loss: -0.190]\n",
      "Epoch 3252 -- [D loss: -0.015(R -0.238, F 0.208)] [G loss: -0.199]\n",
      "Epoch 3253 -- [D loss: -0.027(R -0.255, F 0.201)] [G loss: -0.202]\n",
      "Epoch 3254 -- [D loss: -0.042(R -0.288, F 0.203)] [G loss: -0.217]\n",
      "Epoch 3255 -- [D loss: -0.047(R -0.317, F 0.223)] [G loss: -0.233]\n",
      "Epoch 3256 -- [D loss: -0.020(R -0.320, F 0.279)] [G loss: -0.264]\n",
      "Epoch 3257 -- [D loss: 0.012(R -0.307, F 0.332)] [G loss: -0.257]\n",
      "Epoch 3258 -- [D loss: -0.008(R -0.306, F 0.289)] [G loss: -0.249]\n",
      "Epoch 3259 -- [D loss: -0.012(R -0.302, F 0.278)] [G loss: -0.251]\n",
      "Epoch 3260 -- [D loss: 0.002(R -0.262, F 0.266)] [G loss: -0.248]\n",
      "Epoch 3261 -- [D loss: -0.008(R -0.239, F 0.223)] [G loss: -0.242]\n",
      "Epoch 3262 -- [D loss: -0.009(R -0.260, F 0.242)] [G loss: -0.236]\n",
      "Epoch 3263 -- [D loss: 0.005(R -0.255, F 0.266)] [G loss: -0.229]\n",
      "Epoch 3264 -- [D loss: 0.006(R -0.244, F 0.255)] [G loss: -0.228]\n",
      "Epoch 3265 -- [D loss: 0.016(R -0.216, F 0.248)] [G loss: -0.219]\n",
      "Epoch 3266 -- [D loss: 0.013(R -0.213, F 0.240)] [G loss: -0.229]\n",
      "Epoch 3267 -- [D loss: 0.015(R -0.210, F 0.241)] [G loss: -0.216]\n",
      "Epoch 3268 -- [D loss: 0.008(R -0.210, F 0.227)] [G loss: -0.219]\n",
      "Epoch 3269 -- [D loss: 0.005(R -0.212, F 0.221)] [G loss: -0.208]\n",
      "Epoch 3270 -- [D loss: 0.009(R -0.212, F 0.230)] [G loss: -0.215]\n",
      "Epoch 3271 -- [D loss: -0.001(R -0.207, F 0.206)] [G loss: -0.198]\n",
      "Epoch 3272 -- [D loss: -0.001(R -0.208, F 0.206)] [G loss: -0.189]\n",
      "Epoch 3273 -- [D loss: -0.003(R -0.209, F 0.202)] [G loss: -0.179]\n",
      "Epoch 3274 -- [D loss: -0.013(R -0.211, F 0.185)] [G loss: -0.161]\n",
      "Epoch 3275 -- [D loss: -0.004(R -0.199, F 0.191)] [G loss: -0.169]\n",
      "Epoch 3276 -- [D loss: -0.007(R -0.202, F 0.187)] [G loss: -0.169]\n",
      "Epoch 3277 -- [D loss: 0.001(R -0.196, F 0.197)] [G loss: -0.175]\n",
      "Epoch 3278 -- [D loss: 0.001(R -0.202, F 0.204)] [G loss: -0.166]\n",
      "Epoch 3279 -- [D loss: -0.004(R -0.198, F 0.190)] [G loss: -0.158]\n",
      "Epoch 3280 -- [D loss: 0.004(R -0.183, F 0.190)] [G loss: -0.159]\n",
      "Epoch 3281 -- [D loss: -0.003(R -0.185, F 0.178)] [G loss: -0.156]\n",
      "Epoch 3282 -- [D loss: -0.005(R -0.171, F 0.161)] [G loss: -0.138]\n",
      "Epoch 3283 -- [D loss: -0.006(R -0.175, F 0.164)] [G loss: -0.139]\n",
      "Epoch 3284 -- [D loss: -0.002(R -0.173, F 0.169)] [G loss: -0.144]\n",
      "Epoch 3285 -- [D loss: -0.005(R -0.167, F 0.157)] [G loss: -0.148]\n",
      "Epoch 3286 -- [D loss: -0.009(R -0.185, F 0.168)] [G loss: -0.148]\n",
      "Epoch 3287 -- [D loss: -0.002(R -0.176, F 0.172)] [G loss: -0.155]\n",
      "Epoch 3288 -- [D loss: -0.000(R -0.168, F 0.167)] [G loss: -0.168]\n",
      "Epoch 3289 -- [D loss: -0.012(R -0.190, F 0.166)] [G loss: -0.172]\n",
      "Epoch 3290 -- [D loss: -0.005(R -0.169, F 0.158)] [G loss: -0.160]\n",
      "Epoch 3291 -- [D loss: -0.008(R -0.177, F 0.161)] [G loss: -0.153]\n",
      "Epoch 3292 -- [D loss: -0.009(R -0.179, F 0.161)] [G loss: -0.166]\n",
      "Epoch 3293 -- [D loss: 0.014(R -0.165, F 0.194)] [G loss: -0.181]\n",
      "Epoch 3294 -- [D loss: 0.004(R -0.184, F 0.192)] [G loss: -0.174]\n",
      "Epoch 3295 -- [D loss: -0.003(R -0.183, F 0.178)] [G loss: -0.172]\n",
      "Epoch 3296 -- [D loss: -0.010(R -0.191, F 0.171)] [G loss: -0.168]\n",
      "Epoch 3297 -- [D loss: -0.013(R -0.194, F 0.168)] [G loss: -0.166]\n",
      "Epoch 3298 -- [D loss: -0.008(R -0.187, F 0.170)] [G loss: -0.160]\n",
      "Epoch 3299 -- [D loss: -0.005(R -0.178, F 0.168)] [G loss: -0.157]\n",
      "Epoch 3300 -- [D loss: -0.007(R -0.183, F 0.168)] [G loss: -0.153]\n",
      "INFO:tensorflow:Assets written to: ram://91431dea-fb0b-4963-97c1-9f56025fe18b/assets\n",
      "INFO:tensorflow:Assets written to: ram://9bceed9d-3d4d-4cde-ad51-e761912e0e39/assets\n",
      "INFO:tensorflow:Assets written to: ram://189feea1-88e2-4ddd-b9b0-490f6dfe866d/assets\n",
      "Epoch 3301 -- [D loss: -0.006(R -0.187, F 0.176)] [G loss: -0.166]\n",
      "Epoch 3302 -- [D loss: -0.000(R -0.188, F 0.188)] [G loss: -0.175]\n",
      "Epoch 3303 -- [D loss: -0.007(R -0.198, F 0.184)] [G loss: -0.166]\n",
      "Epoch 3304 -- [D loss: -0.010(R -0.205, F 0.184)] [G loss: -0.166]\n",
      "Epoch 3305 -- [D loss: -0.004(R -0.199, F 0.191)] [G loss: -0.170]\n",
      "Epoch 3306 -- [D loss: 0.002(R -0.199, F 0.202)] [G loss: -0.181]\n",
      "Epoch 3307 -- [D loss: -0.003(R -0.200, F 0.195)] [G loss: -0.178]\n",
      "Epoch 3308 -- [D loss: -0.004(R -0.194, F 0.187)] [G loss: -0.169]\n",
      "Epoch 3309 -- [D loss: -0.007(R -0.190, F 0.176)] [G loss: -0.161]\n",
      "Epoch 3310 -- [D loss: -0.007(R -0.192, F 0.178)] [G loss: -0.167]\n",
      "Epoch 3311 -- [D loss: -0.001(R -0.189, F 0.187)] [G loss: -0.174]\n",
      "Epoch 3312 -- [D loss: -0.006(R -0.189, F 0.178)] [G loss: -0.172]\n",
      "Epoch 3313 -- [D loss: -0.004(R -0.192, F 0.183)] [G loss: -0.172]\n",
      "Epoch 3314 -- [D loss: 0.005(R -0.181, F 0.191)] [G loss: -0.182]\n",
      "Epoch 3315 -- [D loss: 0.000(R -0.189, F 0.190)] [G loss: -0.185]\n",
      "Epoch 3316 -- [D loss: 0.005(R -0.184, F 0.194)] [G loss: -0.174]\n",
      "Epoch 3317 -- [D loss: -0.001(R -0.187, F 0.186)] [G loss: -0.176]\n",
      "Epoch 3318 -- [D loss: 0.000(R -0.179, F 0.180)] [G loss: -0.167]\n",
      "Epoch 3319 -- [D loss: -0.002(R -0.179, F 0.175)] [G loss: -0.162]\n",
      "Epoch 3320 -- [D loss: -0.004(R -0.179, F 0.172)] [G loss: -0.156]\n",
      "Epoch 3321 -- [D loss: -0.005(R -0.171, F 0.162)] [G loss: -0.147]\n",
      "Epoch 3322 -- [D loss: -0.004(R -0.165, F 0.156)] [G loss: -0.144]\n",
      "Epoch 3323 -- [D loss: -0.005(R -0.163, F 0.154)] [G loss: -0.137]\n",
      "Epoch 3324 -- [D loss: -0.000(R -0.155, F 0.155)] [G loss: -0.142]\n",
      "Epoch 3325 -- [D loss: 0.002(R -0.157, F 0.161)] [G loss: -0.142]\n",
      "Epoch 3326 -- [D loss: 0.003(R -0.159, F 0.166)] [G loss: -0.151]\n",
      "Epoch 3327 -- [D loss: -0.005(R -0.165, F 0.156)] [G loss: -0.145]\n",
      "Epoch 3328 -- [D loss: -0.009(R -0.162, F 0.144)] [G loss: -0.135]\n",
      "Epoch 3329 -- [D loss: -0.008(R -0.163, F 0.147)] [G loss: -0.137]\n",
      "Epoch 3330 -- [D loss: -0.005(R -0.156, F 0.146)] [G loss: -0.131]\n",
      "Epoch 3331 -- [D loss: -0.007(R -0.164, F 0.150)] [G loss: -0.139]\n",
      "Epoch 3332 -- [D loss: -0.007(R -0.173, F 0.158)] [G loss: -0.144]\n",
      "Epoch 3333 -- [D loss: -0.009(R -0.170, F 0.152)] [G loss: -0.149]\n",
      "Epoch 3334 -- [D loss: -0.005(R -0.167, F 0.157)] [G loss: -0.149]\n",
      "Epoch 3335 -- [D loss: -0.004(R -0.165, F 0.158)] [G loss: -0.148]\n",
      "Epoch 3336 -- [D loss: -0.001(R -0.165, F 0.164)] [G loss: -0.155]\n",
      "Epoch 3337 -- [D loss: -0.001(R -0.170, F 0.169)] [G loss: -0.150]\n",
      "Epoch 3338 -- [D loss: -0.003(R -0.172, F 0.166)] [G loss: -0.157]\n",
      "Epoch 3339 -- [D loss: 0.000(R -0.173, F 0.174)] [G loss: -0.161]\n",
      "Epoch 3340 -- [D loss: -0.004(R -0.178, F 0.171)] [G loss: -0.161]\n",
      "Epoch 3341 -- [D loss: -0.005(R -0.181, F 0.172)] [G loss: -0.174]\n",
      "Epoch 3342 -- [D loss: -0.008(R -0.189, F 0.173)] [G loss: -0.185]\n",
      "Epoch 3343 -- [D loss: -0.010(R -0.197, F 0.176)] [G loss: -0.184]\n",
      "Epoch 3344 -- [D loss: -0.011(R -0.187, F 0.164)] [G loss: -0.183]\n",
      "Epoch 3345 -- [D loss: -0.000(R -0.179, F 0.179)] [G loss: -0.173]\n",
      "Epoch 3346 -- [D loss: -0.001(R -0.183, F 0.180)] [G loss: -0.164]\n",
      "Epoch 3347 -- [D loss: -0.008(R -0.175, F 0.159)] [G loss: -0.152]\n",
      "Epoch 3348 -- [D loss: -0.006(R -0.173, F 0.161)] [G loss: -0.143]\n",
      "Epoch 3349 -- [D loss: -0.014(R -0.182, F 0.155)] [G loss: -0.155]\n",
      "Epoch 3350 -- [D loss: -0.003(R -0.159, F 0.154)] [G loss: -0.153]\n",
      "Epoch 3351 -- [D loss: -0.001(R -0.154, F 0.151)] [G loss: -0.139]\n",
      "Epoch 3352 -- [D loss: -0.004(R -0.157, F 0.148)] [G loss: -0.134]\n",
      "Epoch 3353 -- [D loss: 0.002(R -0.139, F 0.142)] [G loss: -0.138]\n",
      "Epoch 3354 -- [D loss: 0.007(R -0.131, F 0.146)] [G loss: -0.123]\n",
      "Epoch 3355 -- [D loss: 0.001(R -0.118, F 0.121)] [G loss: -0.103]\n",
      "Epoch 3356 -- [D loss: -0.013(R -0.113, F 0.087)] [G loss: -0.078]\n",
      "Epoch 3357 -- [D loss: -0.006(R -0.106, F 0.094)] [G loss: -0.070]\n",
      "Epoch 3358 -- [D loss: -0.004(R -0.113, F 0.104)] [G loss: -0.085]\n",
      "Epoch 3359 -- [D loss: 0.004(R -0.112, F 0.120)] [G loss: -0.098]\n",
      "Epoch 3360 -- [D loss: -0.009(R -0.130, F 0.112)] [G loss: -0.099]\n",
      "Epoch 3361 -- [D loss: -0.001(R -0.118, F 0.115)] [G loss: -0.096]\n",
      "Epoch 3362 -- [D loss: -0.011(R -0.136, F 0.114)] [G loss: -0.102]\n",
      "Epoch 3363 -- [D loss: -0.006(R -0.137, F 0.124)] [G loss: -0.122]\n",
      "Epoch 3364 -- [D loss: -0.005(R -0.142, F 0.132)] [G loss: -0.126]\n",
      "Epoch 3365 -- [D loss: -0.004(R -0.145, F 0.137)] [G loss: -0.125]\n",
      "Epoch 3366 -- [D loss: -0.012(R -0.148, F 0.124)] [G loss: -0.123]\n",
      "Epoch 3367 -- [D loss: -0.013(R -0.155, F 0.129)] [G loss: -0.124]\n",
      "Epoch 3368 -- [D loss: -0.008(R -0.150, F 0.135)] [G loss: -0.135]\n",
      "Epoch 3369 -- [D loss: -0.004(R -0.162, F 0.154)] [G loss: -0.142]\n",
      "Epoch 3370 -- [D loss: -0.001(R -0.164, F 0.162)] [G loss: -0.148]\n",
      "Epoch 3371 -- [D loss: -0.007(R -0.164, F 0.149)] [G loss: -0.145]\n",
      "Epoch 3372 -- [D loss: -0.007(R -0.171, F 0.158)] [G loss: -0.147]\n",
      "Epoch 3373 -- [D loss: -0.004(R -0.163, F 0.155)] [G loss: -0.144]\n",
      "Epoch 3374 -- [D loss: 0.003(R -0.161, F 0.167)] [G loss: -0.150]\n",
      "Epoch 3375 -- [D loss: -0.004(R -0.164, F 0.157)] [G loss: -0.144]\n",
      "Epoch 3376 -- [D loss: -0.008(R -0.177, F 0.160)] [G loss: -0.151]\n",
      "Epoch 3377 -- [D loss: -0.011(R -0.181, F 0.159)] [G loss: -0.160]\n",
      "Epoch 3378 -- [D loss: -0.008(R -0.185, F 0.170)] [G loss: -0.159]\n",
      "Epoch 3379 -- [D loss: -0.009(R -0.193, F 0.175)] [G loss: -0.172]\n",
      "Epoch 3380 -- [D loss: -0.013(R -0.195, F 0.169)] [G loss: -0.175]\n",
      "Epoch 3381 -- [D loss: -0.004(R -0.191, F 0.182)] [G loss: -0.178]\n",
      "Epoch 3382 -- [D loss: 0.002(R -0.196, F 0.200)] [G loss: -0.187]\n",
      "Epoch 3383 -- [D loss: -0.001(R -0.192, F 0.191)] [G loss: -0.187]\n",
      "Epoch 3384 -- [D loss: -0.001(R -0.190, F 0.188)] [G loss: -0.187]\n",
      "Epoch 3385 -- [D loss: 0.005(R -0.179, F 0.189)] [G loss: -0.179]\n",
      "Epoch 3386 -- [D loss: 0.001(R -0.179, F 0.182)] [G loss: -0.169]\n",
      "Epoch 3387 -- [D loss: 0.007(R -0.157, F 0.170)] [G loss: -0.150]\n",
      "Epoch 3388 -- [D loss: -0.003(R -0.151, F 0.145)] [G loss: -0.124]\n",
      "Epoch 3389 -- [D loss: -0.016(R -0.148, F 0.115)] [G loss: -0.100]\n",
      "Epoch 3390 -- [D loss: -0.018(R -0.139, F 0.102)] [G loss: -0.086]\n",
      "Epoch 3391 -- [D loss: -0.026(R -0.144, F 0.093)] [G loss: -0.093]\n",
      "Epoch 3392 -- [D loss: -0.025(R -0.145, F 0.096)] [G loss: -0.103]\n",
      "Epoch 3393 -- [D loss: -0.017(R -0.143, F 0.109)] [G loss: -0.117]\n",
      "Epoch 3394 -- [D loss: -0.004(R -0.144, F 0.136)] [G loss: -0.127]\n",
      "Epoch 3395 -- [D loss: -0.002(R -0.149, F 0.144)] [G loss: -0.135]\n",
      "Epoch 3396 -- [D loss: 0.005(R -0.145, F 0.155)] [G loss: -0.146]\n",
      "Epoch 3397 -- [D loss: 0.002(R -0.158, F 0.163)] [G loss: -0.155]\n",
      "Epoch 3398 -- [D loss: 0.002(R -0.166, F 0.170)] [G loss: -0.160]\n",
      "Epoch 3399 -- [D loss: 0.003(R -0.175, F 0.181)] [G loss: -0.171]\n",
      "Epoch 3400 -- [D loss: -0.005(R -0.180, F 0.170)] [G loss: -0.169]\n",
      "INFO:tensorflow:Assets written to: ram://ebbb7955-b502-4f13-a7d6-9496407404ab/assets\n",
      "INFO:tensorflow:Assets written to: ram://96c6b66b-3ea2-4e2b-8c68-5d225d0ca6ea/assets\n",
      "INFO:tensorflow:Assets written to: ram://900b2947-667f-450c-b138-0145ba60c03e/assets\n",
      "Epoch 3401 -- [D loss: -0.000(R -0.181, F 0.181)] [G loss: -0.168]\n",
      "Epoch 3402 -- [D loss: -0.001(R -0.180, F 0.178)] [G loss: -0.169]\n",
      "Epoch 3403 -- [D loss: -0.006(R -0.186, F 0.175)] [G loss: -0.164]\n",
      "Epoch 3404 -- [D loss: -0.004(R -0.180, F 0.172)] [G loss: -0.162]\n",
      "Epoch 3405 -- [D loss: -0.005(R -0.178, F 0.168)] [G loss: -0.148]\n",
      "Epoch 3406 -- [D loss: -0.007(R -0.180, F 0.166)] [G loss: -0.147]\n",
      "Epoch 3407 -- [D loss: -0.010(R -0.176, F 0.156)] [G loss: -0.141]\n",
      "Epoch 3408 -- [D loss: -0.011(R -0.179, F 0.158)] [G loss: -0.134]\n",
      "Epoch 3409 -- [D loss: -0.013(R -0.177, F 0.151)] [G loss: -0.138]\n",
      "Epoch 3410 -- [D loss: -0.010(R -0.180, F 0.159)] [G loss: -0.154]\n",
      "Epoch 3411 -- [D loss: -0.006(R -0.183, F 0.172)] [G loss: -0.164]\n",
      "Epoch 3412 -- [D loss: -0.005(R -0.191, F 0.180)] [G loss: -0.185]\n",
      "Epoch 3413 -- [D loss: -0.009(R -0.180, F 0.163)] [G loss: -0.193]\n",
      "Epoch 3414 -- [D loss: -0.006(R -0.195, F 0.184)] [G loss: -0.209]\n",
      "Epoch 3415 -- [D loss: 0.004(R -0.197, F 0.205)] [G loss: -0.213]\n",
      "Epoch 3416 -- [D loss: 0.001(R -0.196, F 0.198)] [G loss: -0.194]\n",
      "Epoch 3417 -- [D loss: 0.005(R -0.194, F 0.205)] [G loss: -0.197]\n",
      "Epoch 3418 -- [D loss: 0.007(R -0.182, F 0.196)] [G loss: -0.181]\n",
      "Epoch 3419 -- [D loss: -0.002(R -0.180, F 0.176)] [G loss: -0.163]\n",
      "Epoch 3420 -- [D loss: -0.006(R -0.159, F 0.147)] [G loss: -0.134]\n",
      "Epoch 3421 -- [D loss: -0.016(R -0.149, F 0.117)] [G loss: -0.103]\n",
      "Epoch 3422 -- [D loss: -0.025(R -0.147, F 0.096)] [G loss: -0.088]\n",
      "Epoch 3423 -- [D loss: -0.020(R -0.136, F 0.096)] [G loss: -0.077]\n",
      "Epoch 3424 -- [D loss: -0.008(R -0.133, F 0.117)] [G loss: -0.091]\n",
      "Epoch 3425 -- [D loss: -0.002(R -0.132, F 0.128)] [G loss: -0.102]\n",
      "Epoch 3426 -- [D loss: -0.002(R -0.138, F 0.134)] [G loss: -0.114]\n",
      "Epoch 3427 -- [D loss: -0.007(R -0.151, F 0.137)] [G loss: -0.126]\n",
      "Epoch 3428 -- [D loss: -0.009(R -0.156, F 0.138)] [G loss: -0.136]\n",
      "Epoch 3429 -- [D loss: -0.010(R -0.165, F 0.146)] [G loss: -0.146]\n",
      "Epoch 3430 -- [D loss: -0.005(R -0.168, F 0.158)] [G loss: -0.165]\n",
      "Epoch 3431 -- [D loss: 0.005(R -0.162, F 0.173)] [G loss: -0.172]\n",
      "Epoch 3432 -- [D loss: 0.004(R -0.176, F 0.185)] [G loss: -0.176]\n",
      "Epoch 3433 -- [D loss: 0.004(R -0.176, F 0.184)] [G loss: -0.173]\n",
      "Epoch 3434 -- [D loss: 0.004(R -0.180, F 0.188)] [G loss: -0.177]\n",
      "Epoch 3435 -- [D loss: 0.000(R -0.179, F 0.180)] [G loss: -0.173]\n",
      "Epoch 3436 -- [D loss: -0.004(R -0.184, F 0.176)] [G loss: -0.172]\n",
      "Epoch 3437 -- [D loss: -0.005(R -0.188, F 0.177)] [G loss: -0.174]\n",
      "Epoch 3438 -- [D loss: -0.001(R -0.187, F 0.184)] [G loss: -0.174]\n",
      "Epoch 3439 -- [D loss: -0.009(R -0.196, F 0.178)] [G loss: -0.168]\n",
      "Epoch 3440 -- [D loss: -0.003(R -0.198, F 0.191)] [G loss: -0.162]\n",
      "Epoch 3441 -- [D loss: -0.002(R -0.188, F 0.184)] [G loss: -0.163]\n",
      "Epoch 3442 -- [D loss: -0.003(R -0.196, F 0.190)] [G loss: -0.167]\n",
      "Epoch 3443 -- [D loss: -0.008(R -0.198, F 0.182)] [G loss: -0.171]\n",
      "Epoch 3444 -- [D loss: -0.006(R -0.194, F 0.183)] [G loss: -0.170]\n",
      "Epoch 3445 -- [D loss: 0.003(R -0.180, F 0.185)] [G loss: -0.173]\n",
      "Epoch 3446 -- [D loss: 0.001(R -0.186, F 0.188)] [G loss: -0.178]\n",
      "Epoch 3447 -- [D loss: 0.004(R -0.184, F 0.192)] [G loss: -0.180]\n",
      "Epoch 3448 -- [D loss: 0.001(R -0.179, F 0.182)] [G loss: -0.176]\n",
      "Epoch 3449 -- [D loss: -0.004(R -0.187, F 0.178)] [G loss: -0.175]\n",
      "Epoch 3450 -- [D loss: -0.011(R -0.192, F 0.170)] [G loss: -0.167]\n",
      "Epoch 3451 -- [D loss: -0.004(R -0.191, F 0.182)] [G loss: -0.169]\n",
      "Epoch 3452 -- [D loss: -0.004(R -0.178, F 0.170)] [G loss: -0.150]\n",
      "Epoch 3453 -- [D loss: -0.006(R -0.170, F 0.157)] [G loss: -0.146]\n",
      "Epoch 3454 -- [D loss: -0.006(R -0.166, F 0.154)] [G loss: -0.139]\n",
      "Epoch 3455 -- [D loss: -0.009(R -0.163, F 0.146)] [G loss: -0.130]\n",
      "Epoch 3456 -- [D loss: -0.010(R -0.162, F 0.142)] [G loss: -0.128]\n",
      "Epoch 3457 -- [D loss: -0.009(R -0.156, F 0.139)] [G loss: -0.125]\n",
      "Epoch 3458 -- [D loss: -0.012(R -0.160, F 0.136)] [G loss: -0.123]\n",
      "Epoch 3459 -- [D loss: -0.015(R -0.165, F 0.135)] [G loss: -0.141]\n",
      "Epoch 3460 -- [D loss: -0.019(R -0.182, F 0.143)] [G loss: -0.151]\n",
      "Epoch 3461 -- [D loss: -0.016(R -0.173, F 0.142)] [G loss: -0.164]\n",
      "Epoch 3462 -- [D loss: -0.012(R -0.194, F 0.169)] [G loss: -0.166]\n",
      "Epoch 3463 -- [D loss: 0.001(R -0.193, F 0.195)] [G loss: -0.177]\n",
      "Epoch 3464 -- [D loss: 0.004(R -0.201, F 0.209)] [G loss: -0.176]\n",
      "Epoch 3465 -- [D loss: -0.000(R -0.193, F 0.193)] [G loss: -0.175]\n",
      "Epoch 3466 -- [D loss: -0.004(R -0.188, F 0.180)] [G loss: -0.170]\n",
      "Epoch 3467 -- [D loss: -0.004(R -0.176, F 0.167)] [G loss: -0.161]\n",
      "Epoch 3468 -- [D loss: -0.014(R -0.175, F 0.147)] [G loss: -0.136]\n",
      "Epoch 3469 -- [D loss: -0.018(R -0.169, F 0.132)] [G loss: -0.132]\n",
      "Epoch 3470 -- [D loss: -0.009(R -0.173, F 0.156)] [G loss: -0.139]\n",
      "Epoch 3471 -- [D loss: -0.003(R -0.172, F 0.166)] [G loss: -0.159]\n",
      "Epoch 3472 -- [D loss: 0.005(R -0.172, F 0.182)] [G loss: -0.165]\n",
      "Epoch 3473 -- [D loss: -0.001(R -0.180, F 0.178)] [G loss: -0.174]\n",
      "Epoch 3474 -- [D loss: 0.004(R -0.180, F 0.189)] [G loss: -0.178]\n",
      "Epoch 3475 -- [D loss: 0.007(R -0.175, F 0.190)] [G loss: -0.185]\n",
      "Epoch 3476 -- [D loss: 0.004(R -0.171, F 0.178)] [G loss: -0.174]\n",
      "Epoch 3477 -- [D loss: 0.005(R -0.168, F 0.178)] [G loss: -0.165]\n",
      "Epoch 3478 -- [D loss: 0.001(R -0.164, F 0.166)] [G loss: -0.156]\n",
      "Epoch 3479 -- [D loss: -0.000(R -0.162, F 0.162)] [G loss: -0.150]\n",
      "Epoch 3480 -- [D loss: -0.000(R -0.155, F 0.155)] [G loss: -0.144]\n",
      "Epoch 3481 -- [D loss: -0.006(R -0.155, F 0.143)] [G loss: -0.140]\n",
      "Epoch 3482 -- [D loss: -0.007(R -0.156, F 0.142)] [G loss: -0.126]\n",
      "Epoch 3483 -- [D loss: -0.012(R -0.159, F 0.135)] [G loss: -0.117]\n",
      "Epoch 3484 -- [D loss: -0.015(R -0.157, F 0.127)] [G loss: -0.111]\n",
      "Epoch 3485 -- [D loss: -0.025(R -0.169, F 0.119)] [G loss: -0.119]\n",
      "Epoch 3486 -- [D loss: -0.009(R -0.154, F 0.135)] [G loss: -0.130]\n",
      "Epoch 3487 -- [D loss: -0.012(R -0.141, F 0.117)] [G loss: -0.149]\n",
      "Epoch 3488 -- [D loss: -0.009(R -0.149, F 0.130)] [G loss: -0.171]\n",
      "Epoch 3489 -- [D loss: 0.004(R -0.154, F 0.162)] [G loss: -0.178]\n",
      "Epoch 3490 -- [D loss: 0.006(R -0.146, F 0.158)] [G loss: -0.169]\n",
      "Epoch 3491 -- [D loss: 0.003(R -0.151, F 0.157)] [G loss: -0.164]\n",
      "Epoch 3492 -- [D loss: -0.002(R -0.150, F 0.147)] [G loss: -0.158]\n",
      "Epoch 3493 -- [D loss: 0.005(R -0.146, F 0.155)] [G loss: -0.146]\n",
      "Epoch 3494 -- [D loss: 0.000(R -0.150, F 0.151)] [G loss: -0.137]\n",
      "Epoch 3495 -- [D loss: -0.006(R -0.153, F 0.140)] [G loss: -0.123]\n",
      "Epoch 3496 -- [D loss: -0.009(R -0.143, F 0.125)] [G loss: -0.114]\n",
      "Epoch 3497 -- [D loss: -0.017(R -0.160, F 0.127)] [G loss: -0.114]\n",
      "Epoch 3498 -- [D loss: -0.012(R -0.160, F 0.136)] [G loss: -0.109]\n",
      "Epoch 3499 -- [D loss: -0.022(R -0.168, F 0.124)] [G loss: -0.112]\n",
      "Epoch 3500 -- [D loss: -0.017(R -0.189, F 0.155)] [G loss: -0.123]\n",
      "INFO:tensorflow:Assets written to: ram://65543bdb-03b3-4588-b474-81e34660f203/assets\n",
      "INFO:tensorflow:Assets written to: ram://d582bb2d-3010-4fc0-bce5-f7a29ddd6030/assets\n",
      "INFO:tensorflow:Assets written to: ram://3aad04e8-1276-481a-a87c-0ea936131e25/assets\n",
      "Epoch 3501 -- [D loss: -0.003(R -0.164, F 0.159)] [G loss: -0.147]\n",
      "Epoch 3502 -- [D loss: -0.018(R -0.192, F 0.156)] [G loss: -0.163]\n",
      "Epoch 3503 -- [D loss: -0.019(R -0.186, F 0.149)] [G loss: -0.161]\n",
      "Epoch 3504 -- [D loss: -0.006(R -0.170, F 0.158)] [G loss: -0.172]\n",
      "Epoch 3505 -- [D loss: -0.002(R -0.163, F 0.158)] [G loss: -0.174]\n",
      "Epoch 3506 -- [D loss: -0.002(R -0.147, F 0.142)] [G loss: -0.174]\n",
      "Epoch 3507 -- [D loss: -0.027(R -0.167, F 0.114)] [G loss: -0.191]\n",
      "Epoch 3508 -- [D loss: -0.017(R -0.155, F 0.122)] [G loss: -0.189]\n",
      "Epoch 3509 -- [D loss: -0.008(R -0.157, F 0.141)] [G loss: -0.197]\n",
      "Epoch 3510 -- [D loss: 0.004(R -0.141, F 0.149)] [G loss: -0.185]\n",
      "Epoch 3511 -- [D loss: 0.007(R -0.144, F 0.158)] [G loss: -0.160]\n",
      "Epoch 3512 -- [D loss: 0.010(R -0.142, F 0.161)] [G loss: -0.145]\n",
      "Epoch 3513 -- [D loss: -0.001(R -0.144, F 0.142)] [G loss: -0.118]\n",
      "Epoch 3514 -- [D loss: -0.011(R -0.145, F 0.123)] [G loss: -0.093]\n",
      "Epoch 3515 -- [D loss: -0.012(R -0.151, F 0.128)] [G loss: -0.085]\n",
      "Epoch 3516 -- [D loss: -0.020(R -0.150, F 0.111)] [G loss: -0.090]\n",
      "Epoch 3517 -- [D loss: -0.021(R -0.155, F 0.113)] [G loss: -0.091]\n",
      "Epoch 3518 -- [D loss: -0.030(R -0.172, F 0.111)] [G loss: -0.102]\n",
      "Epoch 3519 -- [D loss: -0.043(R -0.186, F 0.100)] [G loss: -0.110]\n",
      "Epoch 3520 -- [D loss: -0.043(R -0.210, F 0.123)] [G loss: -0.139]\n",
      "Epoch 3521 -- [D loss: -0.059(R -0.199, F 0.081)] [G loss: -0.159]\n",
      "Epoch 3522 -- [D loss: -0.015(R -0.199, F 0.170)] [G loss: -0.187]\n",
      "Epoch 3523 -- [D loss: -0.028(R -0.221, F 0.165)] [G loss: -0.204]\n",
      "Epoch 3524 -- [D loss: -0.004(R -0.190, F 0.182)] [G loss: -0.220]\n",
      "Epoch 3525 -- [D loss: 0.016(R -0.180, F 0.212)] [G loss: -0.231]\n",
      "Epoch 3526 -- [D loss: 0.007(R -0.180, F 0.195)] [G loss: -0.240]\n",
      "Epoch 3527 -- [D loss: 0.007(R -0.184, F 0.198)] [G loss: -0.255]\n",
      "Epoch 3528 -- [D loss: -0.015(R -0.194, F 0.165)] [G loss: -0.254]\n",
      "Epoch 3529 -- [D loss: -0.010(R -0.206, F 0.186)] [G loss: -0.249]\n",
      "Epoch 3530 -- [D loss: 0.012(R -0.183, F 0.207)] [G loss: -0.244]\n",
      "Epoch 3531 -- [D loss: 0.024(R -0.193, F 0.242)] [G loss: -0.244]\n",
      "Epoch 3532 -- [D loss: 0.016(R -0.206, F 0.238)] [G loss: -0.230]\n",
      "Epoch 3533 -- [D loss: 0.009(R -0.211, F 0.228)] [G loss: -0.228]\n",
      "Epoch 3534 -- [D loss: -0.010(R -0.229, F 0.209)] [G loss: -0.223]\n",
      "Epoch 3535 -- [D loss: -0.009(R -0.224, F 0.205)] [G loss: -0.216]\n",
      "Epoch 3536 -- [D loss: -0.008(R -0.225, F 0.209)] [G loss: -0.195]\n",
      "Epoch 3537 -- [D loss: -0.011(R -0.228, F 0.206)] [G loss: -0.173]\n",
      "Epoch 3538 -- [D loss: -0.017(R -0.211, F 0.178)] [G loss: -0.159]\n",
      "Epoch 3539 -- [D loss: -0.029(R -0.221, F 0.163)] [G loss: -0.156]\n",
      "Epoch 3540 -- [D loss: -0.023(R -0.221, F 0.175)] [G loss: -0.141]\n",
      "Epoch 3541 -- [D loss: -0.017(R -0.221, F 0.187)] [G loss: -0.146]\n",
      "Epoch 3542 -- [D loss: -0.016(R -0.213, F 0.181)] [G loss: -0.136]\n",
      "Epoch 3543 -- [D loss: -0.008(R -0.205, F 0.190)] [G loss: -0.135]\n",
      "Epoch 3544 -- [D loss: -0.041(R -0.235, F 0.152)] [G loss: -0.118]\n",
      "Epoch 3545 -- [D loss: -0.039(R -0.203, F 0.124)] [G loss: -0.108]\n",
      "Epoch 3546 -- [D loss: -0.053(R -0.228, F 0.123)] [G loss: -0.133]\n",
      "Epoch 3547 -- [D loss: -0.052(R -0.228, F 0.124)] [G loss: -0.178]\n",
      "Epoch 3548 -- [D loss: -0.051(R -0.250, F 0.149)] [G loss: -0.232]\n",
      "Epoch 3549 -- [D loss: -0.042(R -0.258, F 0.174)] [G loss: -0.263]\n",
      "Epoch 3550 -- [D loss: 0.002(R -0.248, F 0.252)] [G loss: -0.292]\n",
      "Epoch 3551 -- [D loss: 0.019(R -0.266, F 0.305)] [G loss: -0.318]\n",
      "Epoch 3552 -- [D loss: 0.042(R -0.244, F 0.328)] [G loss: -0.321]\n",
      "Epoch 3553 -- [D loss: 0.072(R -0.207, F 0.350)] [G loss: -0.310]\n",
      "Epoch 3554 -- [D loss: 0.041(R -0.212, F 0.293)] [G loss: -0.271]\n",
      "Epoch 3555 -- [D loss: 0.014(R -0.191, F 0.219)] [G loss: -0.207]\n",
      "Epoch 3556 -- [D loss: -0.006(R -0.189, F 0.178)] [G loss: -0.153]\n",
      "Epoch 3557 -- [D loss: -0.010(R -0.175, F 0.154)] [G loss: -0.137]\n",
      "Epoch 3558 -- [D loss: -0.001(R -0.172, F 0.170)] [G loss: -0.161]\n",
      "Epoch 3559 -- [D loss: 0.005(R -0.176, F 0.185)] [G loss: -0.175]\n",
      "Epoch 3560 -- [D loss: 0.004(R -0.177, F 0.185)] [G loss: -0.163]\n",
      "Epoch 3561 -- [D loss: -0.009(R -0.172, F 0.153)] [G loss: -0.119]\n",
      "Epoch 3562 -- [D loss: -0.027(R -0.162, F 0.108)] [G loss: -0.074]\n",
      "Epoch 3563 -- [D loss: -0.046(R -0.173, F 0.081)] [G loss: -0.054]\n",
      "Epoch 3564 -- [D loss: -0.069(R -0.164, F 0.025)] [G loss: -0.065]\n",
      "Epoch 3565 -- [D loss: -0.058(R -0.145, F 0.030)] [G loss: -0.076]\n",
      "Epoch 3566 -- [D loss: -0.061(R -0.156, F 0.034)] [G loss: -0.090]\n",
      "Epoch 3567 -- [D loss: -0.050(R -0.149, F 0.049)] [G loss: -0.090]\n",
      "Epoch 3568 -- [D loss: -0.066(R -0.186, F 0.055)] [G loss: -0.099]\n",
      "Epoch 3569 -- [D loss: -0.027(R -0.152, F 0.097)] [G loss: -0.116]\n",
      "Epoch 3570 -- [D loss: 0.006(R -0.143, F 0.154)] [G loss: -0.133]\n",
      "Epoch 3571 -- [D loss: 0.031(R -0.149, F 0.212)] [G loss: -0.149]\n",
      "Epoch 3572 -- [D loss: 0.017(R -0.171, F 0.206)] [G loss: -0.179]\n",
      "Epoch 3573 -- [D loss: 0.007(R -0.189, F 0.203)] [G loss: -0.179]\n",
      "Epoch 3574 -- [D loss: 0.010(R -0.183, F 0.202)] [G loss: -0.169]\n",
      "Epoch 3575 -- [D loss: -0.013(R -0.196, F 0.170)] [G loss: -0.156]\n",
      "Epoch 3576 -- [D loss: -0.017(R -0.183, F 0.148)] [G loss: -0.164]\n",
      "Epoch 3577 -- [D loss: -0.012(R -0.180, F 0.156)] [G loss: -0.187]\n",
      "Epoch 3578 -- [D loss: -0.010(R -0.172, F 0.152)] [G loss: -0.224]\n",
      "Epoch 3579 -- [D loss: -0.007(R -0.180, F 0.165)] [G loss: -0.221]\n",
      "Epoch 3580 -- [D loss: 0.005(R -0.172, F 0.182)] [G loss: -0.239]\n",
      "Epoch 3581 -- [D loss: 0.010(R -0.170, F 0.190)] [G loss: -0.211]\n",
      "Epoch 3582 -- [D loss: 0.011(R -0.174, F 0.196)] [G loss: -0.203]\n",
      "Epoch 3583 -- [D loss: 0.018(R -0.176, F 0.212)] [G loss: -0.193]\n",
      "Epoch 3584 -- [D loss: 0.010(R -0.184, F 0.204)] [G loss: -0.193]\n",
      "Epoch 3585 -- [D loss: 0.002(R -0.184, F 0.187)] [G loss: -0.179]\n",
      "Epoch 3586 -- [D loss: -0.019(R -0.220, F 0.182)] [G loss: -0.186]\n",
      "Epoch 3587 -- [D loss: -0.036(R -0.228, F 0.157)] [G loss: -0.189]\n",
      "Epoch 3588 -- [D loss: -0.059(R -0.260, F 0.141)] [G loss: -0.192]\n",
      "Epoch 3589 -- [D loss: -0.079(R -0.306, F 0.149)] [G loss: -0.212]\n",
      "Epoch 3590 -- [D loss: -0.044(R -0.314, F 0.226)] [G loss: -0.205]\n",
      "Epoch 3591 -- [D loss: -0.002(R -0.267, F 0.263)] [G loss: -0.197]\n",
      "Epoch 3592 -- [D loss: 0.038(R -0.232, F 0.307)] [G loss: -0.193]\n",
      "Epoch 3593 -- [D loss: 0.030(R -0.211, F 0.271)] [G loss: -0.183]\n",
      "Epoch 3594 -- [D loss: 0.021(R -0.194, F 0.236)] [G loss: -0.150]\n",
      "Epoch 3595 -- [D loss: -0.014(R -0.192, F 0.165)] [G loss: -0.129]\n",
      "Epoch 3596 -- [D loss: -0.036(R -0.191, F 0.119)] [G loss: -0.104]\n",
      "Epoch 3597 -- [D loss: -0.045(R -0.207, F 0.117)] [G loss: -0.154]\n",
      "Epoch 3598 -- [D loss: -0.037(R -0.211, F 0.137)] [G loss: -0.224]\n",
      "Epoch 3599 -- [D loss: -0.027(R -0.233, F 0.180)] [G loss: -0.290]\n",
      "Epoch 3600 -- [D loss: -0.025(R -0.244, F 0.193)] [G loss: -0.332]\n",
      "INFO:tensorflow:Assets written to: ram://570bb06a-eee5-41d1-b5d1-9658f34f87fe/assets\n",
      "INFO:tensorflow:Assets written to: ram://2c93cbef-9f86-4991-991c-5db25655243f/assets\n",
      "INFO:tensorflow:Assets written to: ram://dd803c87-1699-4ed2-a183-6493c4acce1e/assets\n",
      "Epoch 3601 -- [D loss: 0.012(R -0.232, F 0.257)] [G loss: -0.331]\n",
      "Epoch 3602 -- [D loss: 0.007(R -0.239, F 0.254)] [G loss: -0.297]\n",
      "Epoch 3603 -- [D loss: 0.014(R -0.220, F 0.248)] [G loss: -0.263]\n",
      "Epoch 3604 -- [D loss: 0.028(R -0.190, F 0.247)] [G loss: -0.237]\n",
      "Epoch 3605 -- [D loss: 0.020(R -0.170, F 0.211)] [G loss: -0.195]\n",
      "Epoch 3606 -- [D loss: 0.003(R -0.163, F 0.168)] [G loss: -0.159]\n",
      "Epoch 3607 -- [D loss: -0.015(R -0.159, F 0.129)] [G loss: -0.125]\n",
      "Epoch 3608 -- [D loss: -0.042(R -0.165, F 0.081)] [G loss: -0.092]\n",
      "Epoch 3609 -- [D loss: -0.040(R -0.173, F 0.093)] [G loss: -0.079]\n",
      "Epoch 3610 -- [D loss: -0.052(R -0.186, F 0.082)] [G loss: -0.074]\n",
      "Epoch 3611 -- [D loss: -0.031(R -0.200, F 0.138)] [G loss: -0.093]\n",
      "Epoch 3612 -- [D loss: -0.017(R -0.200, F 0.167)] [G loss: -0.124]\n",
      "Epoch 3613 -- [D loss: 0.006(R -0.201, F 0.212)] [G loss: -0.167]\n",
      "Epoch 3614 -- [D loss: 0.014(R -0.217, F 0.245)] [G loss: -0.203]\n",
      "Epoch 3615 -- [D loss: 0.010(R -0.214, F 0.235)] [G loss: -0.220]\n",
      "Epoch 3616 -- [D loss: -0.001(R -0.222, F 0.220)] [G loss: -0.229]\n",
      "Epoch 3617 -- [D loss: 0.000(R -0.209, F 0.210)] [G loss: -0.214]\n",
      "Epoch 3618 -- [D loss: -0.006(R -0.196, F 0.184)] [G loss: -0.166]\n",
      "Epoch 3619 -- [D loss: -0.018(R -0.195, F 0.159)] [G loss: -0.118]\n",
      "Epoch 3620 -- [D loss: -0.030(R -0.177, F 0.118)] [G loss: -0.087]\n",
      "Epoch 3621 -- [D loss: -0.040(R -0.145, F 0.066)] [G loss: -0.059]\n",
      "Epoch 3622 -- [D loss: -0.033(R -0.135, F 0.068)] [G loss: -0.076]\n",
      "Epoch 3623 -- [D loss: -0.034(R -0.127, F 0.059)] [G loss: -0.099]\n",
      "Epoch 3624 -- [D loss: -0.023(R -0.120, F 0.074)] [G loss: -0.131]\n",
      "Epoch 3625 -- [D loss: -0.012(R -0.125, F 0.100)] [G loss: -0.146]\n",
      "Epoch 3626 -- [D loss: -0.009(R -0.129, F 0.111)] [G loss: -0.154]\n",
      "Epoch 3627 -- [D loss: 0.003(R -0.126, F 0.131)] [G loss: -0.154]\n",
      "Epoch 3628 -- [D loss: 0.001(R -0.136, F 0.138)] [G loss: -0.151]\n",
      "Epoch 3629 -- [D loss: 0.004(R -0.132, F 0.139)] [G loss: -0.140]\n",
      "Epoch 3630 -- [D loss: -0.000(R -0.141, F 0.140)] [G loss: -0.139]\n",
      "Epoch 3631 -- [D loss: -0.007(R -0.140, F 0.126)] [G loss: -0.123]\n",
      "Epoch 3632 -- [D loss: -0.006(R -0.134, F 0.122)] [G loss: -0.129]\n",
      "Epoch 3633 -- [D loss: -0.003(R -0.127, F 0.121)] [G loss: -0.115]\n",
      "Epoch 3634 -- [D loss: -0.019(R -0.132, F 0.093)] [G loss: -0.091]\n",
      "Epoch 3635 -- [D loss: -0.004(R -0.106, F 0.098)] [G loss: -0.085]\n",
      "Epoch 3636 -- [D loss: -0.010(R -0.095, F 0.074)] [G loss: -0.073]\n",
      "Epoch 3637 -- [D loss: -0.000(R -0.100, F 0.099)] [G loss: -0.062]\n",
      "Epoch 3638 -- [D loss: 0.005(R -0.093, F 0.104)] [G loss: -0.057]\n",
      "Epoch 3639 -- [D loss: 0.011(R -0.071, F 0.092)] [G loss: -0.049]\n",
      "Epoch 3640 -- [D loss: -0.002(R -0.075, F 0.071)] [G loss: -0.047]\n",
      "Epoch 3641 -- [D loss: -0.005(R -0.078, F 0.069)] [G loss: -0.043]\n",
      "Epoch 3642 -- [D loss: -0.012(R -0.084, F 0.059)] [G loss: -0.043]\n",
      "Epoch 3643 -- [D loss: -0.016(R -0.099, F 0.066)] [G loss: -0.046]\n",
      "Epoch 3644 -- [D loss: -0.020(R -0.113, F 0.073)] [G loss: -0.062]\n",
      "Epoch 3645 -- [D loss: -0.007(R -0.119, F 0.106)] [G loss: -0.086]\n",
      "Epoch 3646 -- [D loss: -0.011(R -0.129, F 0.108)] [G loss: -0.109]\n",
      "Epoch 3647 -- [D loss: -0.004(R -0.120, F 0.112)] [G loss: -0.130]\n",
      "Epoch 3648 -- [D loss: -0.008(R -0.130, F 0.114)] [G loss: -0.145]\n",
      "Epoch 3649 -- [D loss: 0.002(R -0.125, F 0.128)] [G loss: -0.149]\n",
      "Epoch 3650 -- [D loss: -0.008(R -0.139, F 0.124)] [G loss: -0.163]\n",
      "Epoch 3651 -- [D loss: -0.005(R -0.140, F 0.131)] [G loss: -0.154]\n",
      "Epoch 3652 -- [D loss: 0.018(R -0.113, F 0.150)] [G loss: -0.143]\n",
      "Epoch 3653 -- [D loss: 0.020(R -0.101, F 0.142)] [G loss: -0.132]\n",
      "Epoch 3654 -- [D loss: 0.019(R -0.092, F 0.130)] [G loss: -0.120]\n",
      "Epoch 3655 -- [D loss: 0.012(R -0.094, F 0.119)] [G loss: -0.107]\n",
      "Epoch 3656 -- [D loss: 0.005(R -0.098, F 0.108)] [G loss: -0.094]\n",
      "Epoch 3657 -- [D loss: -0.003(R -0.096, F 0.090)] [G loss: -0.079]\n",
      "Epoch 3658 -- [D loss: -0.009(R -0.098, F 0.080)] [G loss: -0.066]\n",
      "Epoch 3659 -- [D loss: -0.025(R -0.119, F 0.068)] [G loss: -0.058]\n",
      "Epoch 3660 -- [D loss: -0.017(R -0.118, F 0.085)] [G loss: -0.062]\n",
      "Epoch 3661 -- [D loss: -0.014(R -0.115, F 0.087)] [G loss: -0.072]\n",
      "Epoch 3662 -- [D loss: -0.004(R -0.111, F 0.103)] [G loss: -0.085]\n",
      "Epoch 3663 -- [D loss: -0.010(R -0.115, F 0.094)] [G loss: -0.091]\n",
      "Epoch 3664 -- [D loss: -0.010(R -0.113, F 0.094)] [G loss: -0.098]\n",
      "Epoch 3665 -- [D loss: -0.001(R -0.108, F 0.106)] [G loss: -0.100]\n",
      "Epoch 3666 -- [D loss: -0.009(R -0.123, F 0.105)] [G loss: -0.101]\n",
      "Epoch 3667 -- [D loss: -0.015(R -0.119, F 0.089)] [G loss: -0.100]\n",
      "Epoch 3668 -- [D loss: -0.021(R -0.121, F 0.079)] [G loss: -0.103]\n",
      "Epoch 3669 -- [D loss: -0.020(R -0.123, F 0.082)] [G loss: -0.101]\n",
      "Epoch 3670 -- [D loss: -0.018(R -0.123, F 0.088)] [G loss: -0.108]\n",
      "Epoch 3671 -- [D loss: -0.008(R -0.123, F 0.107)] [G loss: -0.113]\n",
      "Epoch 3672 -- [D loss: 0.009(R -0.113, F 0.131)] [G loss: -0.126]\n",
      "Epoch 3673 -- [D loss: -0.006(R -0.122, F 0.111)] [G loss: -0.142]\n",
      "Epoch 3674 -- [D loss: 0.010(R -0.122, F 0.141)] [G loss: -0.169]\n",
      "Epoch 3675 -- [D loss: 0.014(R -0.124, F 0.152)] [G loss: -0.179]\n",
      "Epoch 3676 -- [D loss: 0.015(R -0.126, F 0.156)] [G loss: -0.182]\n",
      "Epoch 3677 -- [D loss: 0.006(R -0.140, F 0.152)] [G loss: -0.171]\n",
      "Epoch 3678 -- [D loss: 0.008(R -0.134, F 0.149)] [G loss: -0.158]\n",
      "Epoch 3679 -- [D loss: -0.001(R -0.139, F 0.136)] [G loss: -0.144]\n",
      "Epoch 3680 -- [D loss: 0.002(R -0.133, F 0.137)] [G loss: -0.139]\n",
      "Epoch 3681 -- [D loss: 0.004(R -0.142, F 0.150)] [G loss: -0.126]\n",
      "Epoch 3682 -- [D loss: -0.003(R -0.138, F 0.133)] [G loss: -0.123]\n",
      "Epoch 3683 -- [D loss: -0.000(R -0.132, F 0.131)] [G loss: -0.110]\n",
      "Epoch 3684 -- [D loss: -0.006(R -0.135, F 0.122)] [G loss: -0.108]\n",
      "Epoch 3685 -- [D loss: -0.024(R -0.158, F 0.111)] [G loss: -0.095]\n",
      "Epoch 3686 -- [D loss: -0.017(R -0.149, F 0.115)] [G loss: -0.096]\n",
      "Epoch 3687 -- [D loss: -0.017(R -0.158, F 0.125)] [G loss: -0.096]\n",
      "Epoch 3688 -- [D loss: -0.013(R -0.164, F 0.138)] [G loss: -0.101]\n",
      "Epoch 3689 -- [D loss: -0.002(R -0.157, F 0.152)] [G loss: -0.115]\n",
      "Epoch 3690 -- [D loss: -0.003(R -0.157, F 0.152)] [G loss: -0.124]\n",
      "Epoch 3691 -- [D loss: 0.001(R -0.157, F 0.160)] [G loss: -0.126]\n",
      "Epoch 3692 -- [D loss: -0.001(R -0.154, F 0.152)] [G loss: -0.130]\n",
      "Epoch 3693 -- [D loss: -0.007(R -0.162, F 0.147)] [G loss: -0.137]\n",
      "Epoch 3694 -- [D loss: -0.015(R -0.160, F 0.129)] [G loss: -0.146]\n",
      "Epoch 3695 -- [D loss: -0.003(R -0.148, F 0.142)] [G loss: -0.157]\n",
      "Epoch 3696 -- [D loss: -0.006(R -0.158, F 0.146)] [G loss: -0.169]\n",
      "Epoch 3697 -- [D loss: -0.007(R -0.157, F 0.143)] [G loss: -0.183]\n",
      "Epoch 3698 -- [D loss: 0.006(R -0.156, F 0.168)] [G loss: -0.194]\n",
      "Epoch 3699 -- [D loss: 0.007(R -0.149, F 0.163)] [G loss: -0.199]\n",
      "Epoch 3700 -- [D loss: 0.018(R -0.151, F 0.187)] [G loss: -0.196]\n",
      "INFO:tensorflow:Assets written to: ram://9b14fce9-e093-443d-a8bd-58bd8c108c74/assets\n",
      "INFO:tensorflow:Assets written to: ram://625bfac6-5273-4dd6-9b72-032b2a10bfe2/assets\n",
      "INFO:tensorflow:Assets written to: ram://557160d5-ee99-4572-ae38-de03b2217236/assets\n",
      "Epoch 3701 -- [D loss: 0.011(R -0.147, F 0.170)] [G loss: -0.184]\n",
      "Epoch 3702 -- [D loss: 0.015(R -0.137, F 0.166)] [G loss: -0.167]\n",
      "Epoch 3703 -- [D loss: 0.011(R -0.131, F 0.153)] [G loss: -0.146]\n",
      "Epoch 3704 -- [D loss: 0.006(R -0.132, F 0.143)] [G loss: -0.126]\n",
      "Epoch 3705 -- [D loss: -0.001(R -0.129, F 0.128)] [G loss: -0.108]\n",
      "Epoch 3706 -- [D loss: -0.010(R -0.130, F 0.111)] [G loss: -0.092]\n",
      "Epoch 3707 -- [D loss: -0.011(R -0.127, F 0.105)] [G loss: -0.081]\n",
      "Epoch 3708 -- [D loss: -0.019(R -0.135, F 0.097)] [G loss: -0.078]\n",
      "Epoch 3709 -- [D loss: -0.012(R -0.128, F 0.105)] [G loss: -0.077]\n",
      "Epoch 3710 -- [D loss: -0.009(R -0.121, F 0.103)] [G loss: -0.078]\n",
      "Epoch 3711 -- [D loss: -0.020(R -0.147, F 0.106)] [G loss: -0.085]\n",
      "Epoch 3712 -- [D loss: -0.014(R -0.132, F 0.105)] [G loss: -0.093]\n",
      "Epoch 3713 -- [D loss: -0.015(R -0.135, F 0.106)] [G loss: -0.100]\n",
      "Epoch 3714 -- [D loss: -0.028(R -0.152, F 0.096)] [G loss: -0.106]\n",
      "Epoch 3715 -- [D loss: -0.013(R -0.151, F 0.124)] [G loss: -0.116]\n",
      "Epoch 3716 -- [D loss: -0.010(R -0.137, F 0.117)] [G loss: -0.122]\n",
      "Epoch 3717 -- [D loss: -0.005(R -0.140, F 0.129)] [G loss: -0.131]\n",
      "Epoch 3718 -- [D loss: 0.006(R -0.146, F 0.158)] [G loss: -0.140]\n",
      "Epoch 3719 -- [D loss: 0.019(R -0.122, F 0.160)] [G loss: -0.148]\n",
      "Epoch 3720 -- [D loss: 0.008(R -0.142, F 0.159)] [G loss: -0.151]\n",
      "Epoch 3721 -- [D loss: 0.009(R -0.139, F 0.156)] [G loss: -0.140]\n",
      "Epoch 3722 -- [D loss: 0.007(R -0.131, F 0.146)] [G loss: -0.133]\n",
      "Epoch 3723 -- [D loss: 0.000(R -0.132, F 0.133)] [G loss: -0.127]\n",
      "Epoch 3724 -- [D loss: -0.003(R -0.134, F 0.128)] [G loss: -0.124]\n",
      "Epoch 3725 -- [D loss: -0.007(R -0.140, F 0.127)] [G loss: -0.124]\n",
      "Epoch 3726 -- [D loss: -0.001(R -0.130, F 0.128)] [G loss: -0.118]\n",
      "Epoch 3727 -- [D loss: -0.001(R -0.135, F 0.133)] [G loss: -0.123]\n",
      "Epoch 3728 -- [D loss: -0.011(R -0.148, F 0.125)] [G loss: -0.124]\n",
      "Epoch 3729 -- [D loss: -0.011(R -0.146, F 0.124)] [G loss: -0.128]\n",
      "Epoch 3730 -- [D loss: -0.013(R -0.162, F 0.136)] [G loss: -0.141]\n",
      "Epoch 3731 -- [D loss: -0.004(R -0.158, F 0.150)] [G loss: -0.159]\n",
      "Epoch 3732 -- [D loss: -0.005(R -0.168, F 0.157)] [G loss: -0.170]\n",
      "Epoch 3733 -- [D loss: 0.003(R -0.166, F 0.173)] [G loss: -0.182]\n",
      "Epoch 3734 -- [D loss: 0.009(R -0.167, F 0.185)] [G loss: -0.187]\n",
      "Epoch 3735 -- [D loss: 0.010(R -0.163, F 0.183)] [G loss: -0.184]\n",
      "Epoch 3736 -- [D loss: 0.007(R -0.153, F 0.168)] [G loss: -0.171]\n",
      "Epoch 3737 -- [D loss: 0.002(R -0.162, F 0.165)] [G loss: -0.172]\n",
      "Epoch 3738 -- [D loss: 0.005(R -0.156, F 0.165)] [G loss: -0.167]\n",
      "Epoch 3739 -- [D loss: 0.001(R -0.163, F 0.165)] [G loss: -0.160]\n",
      "Epoch 3740 -- [D loss: -0.000(R -0.163, F 0.163)] [G loss: -0.144]\n",
      "Epoch 3741 -- [D loss: 0.005(R -0.148, F 0.158)] [G loss: -0.130]\n",
      "Epoch 3742 -- [D loss: -0.002(R -0.151, F 0.148)] [G loss: -0.117]\n",
      "Epoch 3743 -- [D loss: -0.006(R -0.145, F 0.133)] [G loss: -0.113]\n",
      "Epoch 3744 -- [D loss: -0.011(R -0.142, F 0.121)] [G loss: -0.107]\n",
      "Epoch 3745 -- [D loss: -0.013(R -0.141, F 0.116)] [G loss: -0.106]\n",
      "Epoch 3746 -- [D loss: -0.007(R -0.148, F 0.135)] [G loss: -0.111]\n",
      "Epoch 3747 -- [D loss: 0.001(R -0.136, F 0.138)] [G loss: -0.116]\n",
      "Epoch 3748 -- [D loss: 0.001(R -0.135, F 0.137)] [G loss: -0.120]\n",
      "Epoch 3749 -- [D loss: 0.004(R -0.137, F 0.145)] [G loss: -0.128]\n",
      "Epoch 3750 -- [D loss: -0.002(R -0.133, F 0.130)] [G loss: -0.129]\n",
      "Epoch 3751 -- [D loss: 0.004(R -0.129, F 0.137)] [G loss: -0.129]\n",
      "Epoch 3752 -- [D loss: 0.002(R -0.130, F 0.135)] [G loss: -0.133]\n",
      "Epoch 3753 -- [D loss: 0.001(R -0.130, F 0.132)] [G loss: -0.131]\n",
      "Epoch 3754 -- [D loss: 0.011(R -0.116, F 0.139)] [G loss: -0.133]\n",
      "Epoch 3755 -- [D loss: -0.007(R -0.132, F 0.117)] [G loss: -0.133]\n",
      "Epoch 3756 -- [D loss: 0.000(R -0.127, F 0.128)] [G loss: -0.137]\n",
      "Epoch 3757 -- [D loss: -0.007(R -0.131, F 0.117)] [G loss: -0.140]\n",
      "Epoch 3758 -- [D loss: 0.008(R -0.114, F 0.130)] [G loss: -0.137]\n",
      "Epoch 3759 -- [D loss: 0.006(R -0.127, F 0.139)] [G loss: -0.132]\n",
      "Epoch 3760 -- [D loss: 0.002(R -0.134, F 0.138)] [G loss: -0.130]\n",
      "Epoch 3761 -- [D loss: -0.001(R -0.141, F 0.140)] [G loss: -0.128]\n",
      "Epoch 3762 -- [D loss: -0.002(R -0.141, F 0.138)] [G loss: -0.128]\n",
      "Epoch 3763 -- [D loss: -0.008(R -0.153, F 0.138)] [G loss: -0.128]\n",
      "Epoch 3764 -- [D loss: -0.013(R -0.163, F 0.137)] [G loss: -0.129]\n",
      "Epoch 3765 -- [D loss: -0.013(R -0.162, F 0.137)] [G loss: -0.130]\n",
      "Epoch 3766 -- [D loss: 0.001(R -0.160, F 0.162)] [G loss: -0.138]\n",
      "Epoch 3767 -- [D loss: 0.012(R -0.150, F 0.174)] [G loss: -0.139]\n",
      "Epoch 3768 -- [D loss: 0.012(R -0.147, F 0.170)] [G loss: -0.136]\n",
      "Epoch 3769 -- [D loss: 0.008(R -0.140, F 0.156)] [G loss: -0.131]\n",
      "Epoch 3770 -- [D loss: 0.004(R -0.134, F 0.141)] [G loss: -0.130]\n",
      "Epoch 3771 -- [D loss: -0.001(R -0.140, F 0.138)] [G loss: -0.128]\n",
      "Epoch 3772 -- [D loss: -0.001(R -0.140, F 0.137)] [G loss: -0.128]\n",
      "Epoch 3773 -- [D loss: -0.005(R -0.145, F 0.135)] [G loss: -0.138]\n",
      "Epoch 3774 -- [D loss: -0.006(R -0.147, F 0.134)] [G loss: -0.144]\n",
      "Epoch 3775 -- [D loss: -0.002(R -0.153, F 0.149)] [G loss: -0.159]\n",
      "Epoch 3776 -- [D loss: 0.008(R -0.149, F 0.164)] [G loss: -0.158]\n",
      "Epoch 3777 -- [D loss: 0.004(R -0.152, F 0.159)] [G loss: -0.157]\n",
      "Epoch 3778 -- [D loss: 0.003(R -0.155, F 0.161)] [G loss: -0.152]\n",
      "Epoch 3779 -- [D loss: 0.009(R -0.143, F 0.161)] [G loss: -0.141]\n",
      "Epoch 3780 -- [D loss: -0.002(R -0.148, F 0.144)] [G loss: -0.137]\n",
      "Epoch 3781 -- [D loss: -0.001(R -0.138, F 0.136)] [G loss: -0.130]\n",
      "Epoch 3782 -- [D loss: -0.002(R -0.136, F 0.133)] [G loss: -0.124]\n",
      "Epoch 3783 -- [D loss: -0.001(R -0.134, F 0.132)] [G loss: -0.120]\n",
      "Epoch 3784 -- [D loss: -0.000(R -0.133, F 0.133)] [G loss: -0.118]\n",
      "Epoch 3785 -- [D loss: -0.001(R -0.129, F 0.128)] [G loss: -0.114]\n",
      "Epoch 3786 -- [D loss: -0.004(R -0.126, F 0.118)] [G loss: -0.111]\n",
      "Epoch 3787 -- [D loss: -0.004(R -0.125, F 0.116)] [G loss: -0.108]\n",
      "Epoch 3788 -- [D loss: -0.013(R -0.124, F 0.099)] [G loss: -0.104]\n",
      "Epoch 3789 -- [D loss: -0.006(R -0.113, F 0.101)] [G loss: -0.104]\n",
      "Epoch 3790 -- [D loss: -0.006(R -0.115, F 0.103)] [G loss: -0.102]\n",
      "Epoch 3791 -- [D loss: 0.001(R -0.110, F 0.112)] [G loss: -0.109]\n",
      "Epoch 3792 -- [D loss: 0.002(R -0.114, F 0.118)] [G loss: -0.112]\n",
      "Epoch 3793 -- [D loss: 0.007(R -0.115, F 0.130)] [G loss: -0.118]\n",
      "Epoch 3794 -- [D loss: 0.008(R -0.119, F 0.134)] [G loss: -0.121]\n",
      "Epoch 3795 -- [D loss: 0.003(R -0.126, F 0.132)] [G loss: -0.121]\n",
      "Epoch 3796 -- [D loss: -0.006(R -0.135, F 0.124)] [G loss: -0.122]\n",
      "Epoch 3797 -- [D loss: -0.010(R -0.143, F 0.123)] [G loss: -0.120]\n",
      "Epoch 3798 -- [D loss: -0.011(R -0.147, F 0.125)] [G loss: -0.128]\n",
      "Epoch 3799 -- [D loss: -0.014(R -0.149, F 0.121)] [G loss: -0.136]\n",
      "Epoch 3800 -- [D loss: -0.013(R -0.142, F 0.116)] [G loss: -0.145]\n",
      "INFO:tensorflow:Assets written to: ram://c02a9a55-72d9-4a4b-8d67-275c93cdb4b0/assets\n",
      "INFO:tensorflow:Assets written to: ram://4c87a85d-237b-4ffc-8b28-72aaea0ec796/assets\n",
      "INFO:tensorflow:Assets written to: ram://82c754bc-6a39-41d7-a9ee-881befa84495/assets\n",
      "Epoch 3801 -- [D loss: -0.006(R -0.147, F 0.136)] [G loss: -0.153]\n",
      "Epoch 3802 -- [D loss: -0.003(R -0.150, F 0.143)] [G loss: -0.150]\n",
      "Epoch 3803 -- [D loss: 0.000(R -0.154, F 0.154)] [G loss: -0.146]\n",
      "Epoch 3804 -- [D loss: 0.012(R -0.134, F 0.157)] [G loss: -0.138]\n",
      "Epoch 3805 -- [D loss: 0.005(R -0.137, F 0.147)] [G loss: -0.132]\n",
      "Epoch 3806 -- [D loss: 0.010(R -0.125, F 0.145)] [G loss: -0.122]\n",
      "Epoch 3807 -- [D loss: -0.000(R -0.127, F 0.126)] [G loss: -0.117]\n",
      "Epoch 3808 -- [D loss: 0.000(R -0.121, F 0.121)] [G loss: -0.109]\n",
      "Epoch 3809 -- [D loss: -0.011(R -0.123, F 0.101)] [G loss: -0.103]\n",
      "Epoch 3810 -- [D loss: -0.005(R -0.124, F 0.113)] [G loss: -0.100]\n",
      "Epoch 3811 -- [D loss: -0.006(R -0.126, F 0.115)] [G loss: -0.103]\n",
      "Epoch 3812 -- [D loss: -0.007(R -0.126, F 0.112)] [G loss: -0.109]\n",
      "Epoch 3813 -- [D loss: -0.006(R -0.124, F 0.111)] [G loss: -0.117]\n",
      "Epoch 3814 -- [D loss: 0.002(R -0.125, F 0.129)] [G loss: -0.123]\n",
      "Epoch 3815 -- [D loss: 0.003(R -0.125, F 0.131)] [G loss: -0.123]\n",
      "Epoch 3816 -- [D loss: 0.005(R -0.122, F 0.131)] [G loss: -0.126]\n",
      "Epoch 3817 -- [D loss: 0.010(R -0.117, F 0.136)] [G loss: -0.122]\n",
      "Epoch 3818 -- [D loss: 0.004(R -0.122, F 0.130)] [G loss: -0.120]\n",
      "Epoch 3819 -- [D loss: 0.002(R -0.123, F 0.127)] [G loss: -0.116]\n",
      "Epoch 3820 -- [D loss: -0.002(R -0.126, F 0.123)] [G loss: -0.112]\n",
      "Epoch 3821 -- [D loss: -0.002(R -0.127, F 0.123)] [G loss: -0.112]\n",
      "Epoch 3822 -- [D loss: -0.007(R -0.134, F 0.119)] [G loss: -0.109]\n",
      "Epoch 3823 -- [D loss: -0.010(R -0.135, F 0.115)] [G loss: -0.107]\n",
      "Epoch 3824 -- [D loss: -0.009(R -0.142, F 0.123)] [G loss: -0.113]\n",
      "Epoch 3825 -- [D loss: -0.005(R -0.142, F 0.132)] [G loss: -0.122]\n",
      "Epoch 3826 -- [D loss: -0.011(R -0.148, F 0.126)] [G loss: -0.128]\n",
      "Epoch 3827 -- [D loss: -0.013(R -0.156, F 0.130)] [G loss: -0.136]\n",
      "Epoch 3828 -- [D loss: -0.014(R -0.152, F 0.125)] [G loss: -0.143]\n",
      "Epoch 3829 -- [D loss: -0.003(R -0.138, F 0.132)] [G loss: -0.144]\n",
      "Epoch 3830 -- [D loss: 0.011(R -0.127, F 0.150)] [G loss: -0.143]\n",
      "Epoch 3831 -- [D loss: 0.023(R -0.124, F 0.171)] [G loss: -0.134]\n",
      "Epoch 3832 -- [D loss: 0.010(R -0.125, F 0.146)] [G loss: -0.126]\n",
      "Epoch 3833 -- [D loss: 0.009(R -0.117, F 0.134)] [G loss: -0.118]\n",
      "Epoch 3834 -- [D loss: 0.003(R -0.111, F 0.116)] [G loss: -0.108]\n",
      "Epoch 3835 -- [D loss: -0.002(R -0.112, F 0.108)] [G loss: -0.095]\n",
      "Epoch 3836 -- [D loss: -0.005(R -0.108, F 0.097)] [G loss: -0.087]\n",
      "Epoch 3837 -- [D loss: -0.001(R -0.102, F 0.100)] [G loss: -0.084]\n",
      "Epoch 3838 -- [D loss: -0.004(R -0.104, F 0.097)] [G loss: -0.090]\n",
      "Epoch 3839 -- [D loss: -0.003(R -0.103, F 0.096)] [G loss: -0.092]\n",
      "Epoch 3840 -- [D loss: -0.003(R -0.104, F 0.099)] [G loss: -0.093]\n",
      "Epoch 3841 -- [D loss: -0.004(R -0.107, F 0.099)] [G loss: -0.090]\n",
      "Epoch 3842 -- [D loss: -0.006(R -0.105, F 0.093)] [G loss: -0.090]\n",
      "Epoch 3843 -- [D loss: -0.010(R -0.107, F 0.088)] [G loss: -0.091]\n",
      "Epoch 3844 -- [D loss: -0.002(R -0.099, F 0.095)] [G loss: -0.093]\n",
      "Epoch 3845 -- [D loss: 0.005(R -0.093, F 0.103)] [G loss: -0.097]\n",
      "Epoch 3846 -- [D loss: 0.004(R -0.097, F 0.105)] [G loss: -0.099]\n",
      "Epoch 3847 -- [D loss: 0.004(R -0.098, F 0.106)] [G loss: -0.104]\n",
      "Epoch 3848 -- [D loss: 0.005(R -0.103, F 0.112)] [G loss: -0.100]\n",
      "Epoch 3849 -- [D loss: 0.004(R -0.102, F 0.110)] [G loss: -0.100]\n",
      "Epoch 3850 -- [D loss: 0.002(R -0.105, F 0.110)] [G loss: -0.098]\n",
      "Epoch 3851 -- [D loss: -0.002(R -0.107, F 0.102)] [G loss: -0.092]\n",
      "Epoch 3852 -- [D loss: -0.004(R -0.107, F 0.099)] [G loss: -0.086]\n",
      "Epoch 3853 -- [D loss: -0.005(R -0.104, F 0.094)] [G loss: -0.085]\n",
      "Epoch 3854 -- [D loss: -0.010(R -0.113, F 0.092)] [G loss: -0.085]\n",
      "Epoch 3855 -- [D loss: -0.010(R -0.109, F 0.090)] [G loss: -0.093]\n",
      "Epoch 3856 -- [D loss: -0.012(R -0.117, F 0.093)] [G loss: -0.100]\n",
      "Epoch 3857 -- [D loss: -0.000(R -0.110, F 0.110)] [G loss: -0.106]\n",
      "Epoch 3858 -- [D loss: -0.003(R -0.115, F 0.110)] [G loss: -0.110]\n",
      "Epoch 3859 -- [D loss: 0.002(R -0.111, F 0.116)] [G loss: -0.113]\n",
      "Epoch 3860 -- [D loss: 0.006(R -0.106, F 0.118)] [G loss: -0.111]\n",
      "Epoch 3861 -- [D loss: 0.006(R -0.107, F 0.118)] [G loss: -0.108]\n",
      "Epoch 3862 -- [D loss: 0.002(R -0.107, F 0.111)] [G loss: -0.100]\n",
      "Epoch 3863 -- [D loss: -0.001(R -0.106, F 0.103)] [G loss: -0.093]\n",
      "Epoch 3864 -- [D loss: -0.005(R -0.103, F 0.093)] [G loss: -0.087]\n",
      "Epoch 3865 -- [D loss: -0.005(R -0.104, F 0.093)] [G loss: -0.084]\n",
      "Epoch 3866 -- [D loss: -0.005(R -0.099, F 0.090)] [G loss: -0.080]\n",
      "Epoch 3867 -- [D loss: -0.002(R -0.098, F 0.094)] [G loss: -0.086]\n",
      "Epoch 3868 -- [D loss: -0.001(R -0.096, F 0.093)] [G loss: -0.085]\n",
      "Epoch 3869 -- [D loss: -0.003(R -0.097, F 0.090)] [G loss: -0.091]\n",
      "Epoch 3870 -- [D loss: 0.001(R -0.094, F 0.095)] [G loss: -0.095]\n",
      "Epoch 3871 -- [D loss: 0.002(R -0.096, F 0.099)] [G loss: -0.097]\n",
      "Epoch 3872 -- [D loss: 0.004(R -0.089, F 0.096)] [G loss: -0.104]\n",
      "Epoch 3873 -- [D loss: 0.008(R -0.089, F 0.106)] [G loss: -0.104]\n",
      "Epoch 3874 -- [D loss: 0.005(R -0.097, F 0.107)] [G loss: -0.106]\n",
      "Epoch 3875 -- [D loss: 0.001(R -0.095, F 0.098)] [G loss: -0.098]\n",
      "Epoch 3876 -- [D loss: -0.000(R -0.098, F 0.098)] [G loss: -0.094]\n",
      "Epoch 3877 -- [D loss: -0.004(R -0.106, F 0.098)] [G loss: -0.090]\n",
      "Epoch 3878 -- [D loss: -0.010(R -0.106, F 0.086)] [G loss: -0.083]\n",
      "Epoch 3879 -- [D loss: -0.016(R -0.108, F 0.076)] [G loss: -0.075]\n",
      "Epoch 3880 -- [D loss: -0.011(R -0.108, F 0.086)] [G loss: -0.080]\n",
      "Epoch 3881 -- [D loss: -0.011(R -0.106, F 0.083)] [G loss: -0.080]\n",
      "Epoch 3882 -- [D loss: 0.001(R -0.100, F 0.103)] [G loss: -0.087]\n",
      "Epoch 3883 -- [D loss: 0.005(R -0.095, F 0.105)] [G loss: -0.089]\n",
      "Epoch 3884 -- [D loss: 0.005(R -0.090, F 0.099)] [G loss: -0.094]\n",
      "Epoch 3885 -- [D loss: 0.000(R -0.096, F 0.096)] [G loss: -0.092]\n",
      "Epoch 3886 -- [D loss: 0.005(R -0.094, F 0.104)] [G loss: -0.093]\n",
      "Epoch 3887 -- [D loss: 0.003(R -0.095, F 0.101)] [G loss: -0.091]\n",
      "Epoch 3888 -- [D loss: 0.003(R -0.094, F 0.100)] [G loss: -0.090]\n",
      "Epoch 3889 -- [D loss: 0.001(R -0.097, F 0.099)] [G loss: -0.089]\n",
      "Epoch 3890 -- [D loss: -0.001(R -0.097, F 0.096)] [G loss: -0.090]\n",
      "Epoch 3891 -- [D loss: -0.002(R -0.101, F 0.097)] [G loss: -0.087]\n",
      "Epoch 3892 -- [D loss: -0.004(R -0.103, F 0.095)] [G loss: -0.088]\n",
      "Epoch 3893 -- [D loss: -0.001(R -0.100, F 0.098)] [G loss: -0.089]\n",
      "Epoch 3894 -- [D loss: -0.003(R -0.103, F 0.096)] [G loss: -0.093]\n",
      "Epoch 3895 -- [D loss: -0.009(R -0.112, F 0.094)] [G loss: -0.094]\n",
      "Epoch 3896 -- [D loss: -0.005(R -0.113, F 0.102)] [G loss: -0.095]\n",
      "Epoch 3897 -- [D loss: -0.009(R -0.120, F 0.102)] [G loss: -0.095]\n",
      "Epoch 3898 -- [D loss: -0.004(R -0.114, F 0.107)] [G loss: -0.100]\n",
      "Epoch 3899 -- [D loss: 0.000(R -0.114, F 0.115)] [G loss: -0.109]\n",
      "Epoch 3900 -- [D loss: 0.000(R -0.118, F 0.119)] [G loss: -0.115]\n",
      "INFO:tensorflow:Assets written to: ram://30f13b54-6626-4d7b-896c-2370a02125e1/assets\n",
      "INFO:tensorflow:Assets written to: ram://e7977c22-622c-4c4a-82fc-6243682e9cd3/assets\n",
      "INFO:tensorflow:Assets written to: ram://cdf9b26b-6096-4891-af65-06576d9b0e01/assets\n",
      "Epoch 3901 -- [D loss: 0.004(R -0.115, F 0.124)] [G loss: -0.116]\n",
      "Epoch 3902 -- [D loss: 0.006(R -0.112, F 0.124)] [G loss: -0.118]\n",
      "Epoch 3903 -- [D loss: 0.004(R -0.113, F 0.121)] [G loss: -0.116]\n",
      "Epoch 3904 -- [D loss: 0.006(R -0.109, F 0.122)] [G loss: -0.108]\n",
      "Epoch 3905 -- [D loss: 0.002(R -0.110, F 0.114)] [G loss: -0.104]\n",
      "Epoch 3906 -- [D loss: 0.001(R -0.109, F 0.111)] [G loss: -0.098]\n",
      "Epoch 3907 -- [D loss: -0.003(R -0.107, F 0.101)] [G loss: -0.096]\n",
      "Epoch 3908 -- [D loss: -0.004(R -0.103, F 0.096)] [G loss: -0.092]\n",
      "Epoch 3909 -- [D loss: -0.004(R -0.107, F 0.098)] [G loss: -0.092]\n",
      "Epoch 3910 -- [D loss: -0.002(R -0.102, F 0.098)] [G loss: -0.089]\n",
      "Epoch 3911 -- [D loss: 0.002(R -0.097, F 0.101)] [G loss: -0.087]\n",
      "Epoch 3912 -- [D loss: 0.001(R -0.092, F 0.094)] [G loss: -0.085]\n",
      "Epoch 3913 -- [D loss: 0.000(R -0.090, F 0.091)] [G loss: -0.083]\n",
      "Epoch 3914 -- [D loss: -0.001(R -0.092, F 0.089)] [G loss: -0.079]\n",
      "Epoch 3915 -- [D loss: -0.004(R -0.090, F 0.082)] [G loss: -0.080]\n",
      "Epoch 3916 -- [D loss: -0.009(R -0.097, F 0.079)] [G loss: -0.079]\n",
      "Epoch 3917 -- [D loss: -0.003(R -0.091, F 0.084)] [G loss: -0.080]\n",
      "Epoch 3918 -- [D loss: -0.009(R -0.098, F 0.079)] [G loss: -0.086]\n",
      "Epoch 3919 -- [D loss: 0.001(R -0.092, F 0.095)] [G loss: -0.089]\n",
      "Epoch 3920 -- [D loss: 0.004(R -0.094, F 0.102)] [G loss: -0.087]\n",
      "Epoch 3921 -- [D loss: 0.002(R -0.092, F 0.097)] [G loss: -0.086]\n",
      "Epoch 3922 -- [D loss: 0.002(R -0.090, F 0.094)] [G loss: -0.083]\n",
      "Epoch 3923 -- [D loss: -0.001(R -0.088, F 0.087)] [G loss: -0.079]\n",
      "Epoch 3924 -- [D loss: -0.002(R -0.085, F 0.081)] [G loss: -0.077]\n",
      "Epoch 3925 -- [D loss: -0.001(R -0.085, F 0.083)] [G loss: -0.070]\n",
      "Epoch 3926 -- [D loss: -0.003(R -0.081, F 0.075)] [G loss: -0.066]\n",
      "Epoch 3927 -- [D loss: -0.006(R -0.085, F 0.074)] [G loss: -0.067]\n",
      "Epoch 3928 -- [D loss: -0.006(R -0.085, F 0.074)] [G loss: -0.066]\n",
      "Epoch 3929 -- [D loss: -0.005(R -0.082, F 0.072)] [G loss: -0.067]\n",
      "Epoch 3930 -- [D loss: -0.006(R -0.088, F 0.076)] [G loss: -0.072]\n",
      "Epoch 3931 -- [D loss: -0.001(R -0.083, F 0.081)] [G loss: -0.073]\n",
      "Epoch 3932 -- [D loss: -0.006(R -0.090, F 0.078)] [G loss: -0.078]\n",
      "Epoch 3933 -- [D loss: -0.004(R -0.088, F 0.081)] [G loss: -0.077]\n",
      "Epoch 3934 -- [D loss: 0.001(R -0.086, F 0.088)] [G loss: -0.079]\n",
      "Epoch 3935 -- [D loss: -0.001(R -0.086, F 0.083)] [G loss: -0.077]\n",
      "Epoch 3936 -- [D loss: -0.001(R -0.083, F 0.082)] [G loss: -0.075]\n",
      "Epoch 3937 -- [D loss: -0.002(R -0.084, F 0.079)] [G loss: -0.070]\n",
      "Epoch 3938 -- [D loss: -0.003(R -0.085, F 0.079)] [G loss: -0.067]\n",
      "Epoch 3939 -- [D loss: -0.001(R -0.081, F 0.080)] [G loss: -0.070]\n",
      "Epoch 3940 -- [D loss: -0.002(R -0.081, F 0.078)] [G loss: -0.072]\n",
      "Epoch 3941 -- [D loss: 0.004(R -0.081, F 0.088)] [G loss: -0.078]\n",
      "Epoch 3942 -- [D loss: 0.003(R -0.086, F 0.092)] [G loss: -0.082]\n",
      "Epoch 3943 -- [D loss: 0.002(R -0.089, F 0.092)] [G loss: -0.085]\n",
      "Epoch 3944 -- [D loss: 0.000(R -0.089, F 0.090)] [G loss: -0.085]\n",
      "Epoch 3945 -- [D loss: 0.000(R -0.089, F 0.090)] [G loss: -0.086]\n",
      "Epoch 3946 -- [D loss: -0.003(R -0.089, F 0.084)] [G loss: -0.084]\n",
      "Epoch 3947 -- [D loss: -0.003(R -0.093, F 0.086)] [G loss: -0.081]\n",
      "Epoch 3948 -- [D loss: -0.006(R -0.097, F 0.085)] [G loss: -0.078]\n",
      "Epoch 3949 -- [D loss: -0.003(R -0.094, F 0.087)] [G loss: -0.076]\n",
      "Epoch 3950 -- [D loss: -0.001(R -0.093, F 0.092)] [G loss: -0.081]\n",
      "Epoch 3951 -- [D loss: -0.003(R -0.094, F 0.089)] [G loss: -0.082]\n",
      "Epoch 3952 -- [D loss: -0.003(R -0.093, F 0.087)] [G loss: -0.081]\n",
      "Epoch 3953 -- [D loss: -0.004(R -0.089, F 0.081)] [G loss: -0.080]\n",
      "Epoch 3954 -- [D loss: -0.004(R -0.088, F 0.081)] [G loss: -0.081]\n",
      "Epoch 3955 -- [D loss: -0.006(R -0.088, F 0.076)] [G loss: -0.082]\n",
      "Epoch 3956 -- [D loss: -0.001(R -0.081, F 0.078)] [G loss: -0.079]\n",
      "Epoch 3957 -- [D loss: 0.000(R -0.083, F 0.084)] [G loss: -0.079]\n",
      "Epoch 3958 -- [D loss: -0.001(R -0.083, F 0.081)] [G loss: -0.078]\n",
      "Epoch 3959 -- [D loss: 0.001(R -0.079, F 0.082)] [G loss: -0.077]\n",
      "Epoch 3960 -- [D loss: -0.002(R -0.083, F 0.080)] [G loss: -0.077]\n",
      "Epoch 3961 -- [D loss: -0.002(R -0.082, F 0.079)] [G loss: -0.074]\n",
      "Epoch 3962 -- [D loss: -0.003(R -0.082, F 0.075)] [G loss: -0.074]\n",
      "Epoch 3963 -- [D loss: -0.002(R -0.082, F 0.077)] [G loss: -0.070]\n",
      "Epoch 3964 -- [D loss: -0.002(R -0.081, F 0.077)] [G loss: -0.070]\n",
      "Epoch 3965 -- [D loss: -0.007(R -0.085, F 0.071)] [G loss: -0.069]\n",
      "Epoch 3966 -- [D loss: -0.005(R -0.086, F 0.076)] [G loss: -0.065]\n",
      "Epoch 3967 -- [D loss: -0.006(R -0.088, F 0.076)] [G loss: -0.066]\n",
      "Epoch 3968 -- [D loss: -0.007(R -0.089, F 0.075)] [G loss: -0.069]\n",
      "Epoch 3969 -- [D loss: -0.004(R -0.090, F 0.082)] [G loss: -0.077]\n",
      "Epoch 3970 -- [D loss: -0.004(R -0.093, F 0.084)] [G loss: -0.080]\n",
      "Epoch 3971 -- [D loss: -0.001(R -0.088, F 0.085)] [G loss: -0.088]\n",
      "Epoch 3972 -- [D loss: -0.001(R -0.087, F 0.084)] [G loss: -0.093]\n",
      "Epoch 3973 -- [D loss: -0.004(R -0.092, F 0.083)] [G loss: -0.092]\n",
      "Epoch 3974 -- [D loss: -0.000(R -0.089, F 0.088)] [G loss: -0.097]\n",
      "Epoch 3975 -- [D loss: -0.000(R -0.084, F 0.083)] [G loss: -0.098]\n",
      "Epoch 3976 -- [D loss: -0.000(R -0.087, F 0.086)] [G loss: -0.091]\n",
      "Epoch 3977 -- [D loss: -0.000(R -0.081, F 0.080)] [G loss: -0.084]\n",
      "Epoch 3978 -- [D loss: 0.002(R -0.076, F 0.079)] [G loss: -0.076]\n",
      "Epoch 3979 -- [D loss: -0.001(R -0.081, F 0.079)] [G loss: -0.067]\n",
      "Epoch 3980 -- [D loss: -0.005(R -0.084, F 0.073)] [G loss: -0.065]\n",
      "Epoch 3981 -- [D loss: -0.007(R -0.079, F 0.066)] [G loss: -0.056]\n",
      "Epoch 3982 -- [D loss: -0.014(R -0.087, F 0.058)] [G loss: -0.055]\n",
      "Epoch 3983 -- [D loss: -0.017(R -0.085, F 0.051)] [G loss: -0.056]\n",
      "Epoch 3984 -- [D loss: -0.019(R -0.094, F 0.056)] [G loss: -0.064]\n",
      "Epoch 3985 -- [D loss: -0.012(R -0.092, F 0.068)] [G loss: -0.074]\n",
      "Epoch 3986 -- [D loss: -0.008(R -0.094, F 0.077)] [G loss: -0.085]\n",
      "Epoch 3987 -- [D loss: 0.001(R -0.087, F 0.088)] [G loss: -0.090]\n",
      "Epoch 3988 -- [D loss: 0.001(R -0.089, F 0.091)] [G loss: -0.100]\n",
      "Epoch 3989 -- [D loss: -0.002(R -0.084, F 0.079)] [G loss: -0.104]\n",
      "Epoch 3990 -- [D loss: -0.011(R -0.095, F 0.072)] [G loss: -0.109]\n",
      "Epoch 3991 -- [D loss: 0.005(R -0.078, F 0.089)] [G loss: -0.109]\n",
      "Epoch 3992 -- [D loss: 0.001(R -0.084, F 0.087)] [G loss: -0.109]\n",
      "Epoch 3993 -- [D loss: 0.006(R -0.077, F 0.089)] [G loss: -0.099]\n",
      "Epoch 3994 -- [D loss: 0.010(R -0.076, F 0.097)] [G loss: -0.095]\n",
      "Epoch 3995 -- [D loss: 0.003(R -0.082, F 0.089)] [G loss: -0.086]\n",
      "Epoch 3996 -- [D loss: 0.004(R -0.080, F 0.088)] [G loss: -0.075]\n",
      "Epoch 3997 -- [D loss: -0.005(R -0.084, F 0.075)] [G loss: -0.064]\n",
      "Epoch 3998 -- [D loss: -0.009(R -0.081, F 0.063)] [G loss: -0.049]\n",
      "Epoch 3999 -- [D loss: -0.011(R -0.078, F 0.055)] [G loss: -0.039]\n",
      "Epoch 4000 -- [D loss: -0.015(R -0.082, F 0.053)] [G loss: -0.042]\n",
      "INFO:tensorflow:Assets written to: ram://ce7a3976-2d16-483b-be34-3a6cfe38a260/assets\n",
      "INFO:tensorflow:Assets written to: ram://0f364867-6236-41d3-a55c-7066e98ea32c/assets\n",
      "INFO:tensorflow:Assets written to: ram://8ee7bfde-d7a0-4233-93fe-fe81e12db671/assets\n",
      "Epoch 4001 -- [D loss: -0.013(R -0.083, F 0.058)] [G loss: -0.040]\n",
      "Epoch 4002 -- [D loss: -0.019(R -0.085, F 0.047)] [G loss: -0.040]\n",
      "Epoch 4003 -- [D loss: -0.022(R -0.087, F 0.042)] [G loss: -0.044]\n",
      "Epoch 4004 -- [D loss: -0.020(R -0.089, F 0.049)] [G loss: -0.059]\n",
      "Epoch 4005 -- [D loss: -0.015(R -0.090, F 0.060)] [G loss: -0.070]\n",
      "Epoch 4006 -- [D loss: -0.007(R -0.087, F 0.073)] [G loss: -0.072]\n",
      "Epoch 4007 -- [D loss: 0.008(R -0.067, F 0.083)] [G loss: -0.076]\n",
      "Epoch 4008 -- [D loss: 0.003(R -0.083, F 0.088)] [G loss: -0.080]\n",
      "Epoch 4009 -- [D loss: 0.007(R -0.077, F 0.092)] [G loss: -0.088]\n",
      "Epoch 4010 -- [D loss: 0.012(R -0.080, F 0.103)] [G loss: -0.095]\n",
      "Epoch 4011 -- [D loss: 0.009(R -0.085, F 0.104)] [G loss: -0.099]\n",
      "Epoch 4012 -- [D loss: 0.011(R -0.074, F 0.096)] [G loss: -0.100]\n",
      "Epoch 4013 -- [D loss: 0.001(R -0.090, F 0.091)] [G loss: -0.096]\n",
      "Epoch 4014 -- [D loss: -0.002(R -0.088, F 0.084)] [G loss: -0.085]\n",
      "Epoch 4015 -- [D loss: -0.003(R -0.094, F 0.088)] [G loss: -0.088]\n",
      "Epoch 4016 -- [D loss: -0.003(R -0.096, F 0.089)] [G loss: -0.086]\n",
      "Epoch 4017 -- [D loss: 0.001(R -0.089, F 0.091)] [G loss: -0.084]\n",
      "Epoch 4018 -- [D loss: -0.002(R -0.089, F 0.085)] [G loss: -0.084]\n",
      "Epoch 4019 -- [D loss: -0.004(R -0.096, F 0.089)] [G loss: -0.078]\n",
      "Epoch 4020 -- [D loss: -0.008(R -0.096, F 0.080)] [G loss: -0.074]\n",
      "Epoch 4021 -- [D loss: -0.006(R -0.096, F 0.083)] [G loss: -0.073]\n",
      "Epoch 4022 -- [D loss: -0.008(R -0.099, F 0.083)] [G loss: -0.071]\n",
      "Epoch 4023 -- [D loss: -0.011(R -0.099, F 0.078)] [G loss: -0.074]\n",
      "Epoch 4024 -- [D loss: -0.011(R -0.103, F 0.081)] [G loss: -0.073]\n",
      "Epoch 4025 -- [D loss: -0.008(R -0.099, F 0.082)] [G loss: -0.077]\n",
      "Epoch 4026 -- [D loss: -0.002(R -0.093, F 0.089)] [G loss: -0.083]\n",
      "Epoch 4027 -- [D loss: -0.004(R -0.096, F 0.087)] [G loss: -0.087]\n",
      "Epoch 4028 -- [D loss: -0.000(R -0.098, F 0.097)] [G loss: -0.091]\n",
      "Epoch 4029 -- [D loss: 0.003(R -0.094, F 0.101)] [G loss: -0.093]\n",
      "Epoch 4030 -- [D loss: 0.005(R -0.098, F 0.109)] [G loss: -0.095]\n",
      "Epoch 4031 -- [D loss: 0.007(R -0.090, F 0.103)] [G loss: -0.097]\n",
      "Epoch 4032 -- [D loss: 0.003(R -0.099, F 0.105)] [G loss: -0.097]\n",
      "Epoch 4033 -- [D loss: 0.005(R -0.095, F 0.105)] [G loss: -0.098]\n",
      "Epoch 4034 -- [D loss: 0.001(R -0.088, F 0.090)] [G loss: -0.096]\n",
      "Epoch 4035 -- [D loss: -0.003(R -0.097, F 0.090)] [G loss: -0.093]\n",
      "Epoch 4036 -- [D loss: 0.004(R -0.083, F 0.091)] [G loss: -0.086]\n",
      "Epoch 4037 -- [D loss: 0.004(R -0.079, F 0.087)] [G loss: -0.081]\n",
      "Epoch 4038 -- [D loss: 0.003(R -0.079, F 0.084)] [G loss: -0.072]\n",
      "Epoch 4039 -- [D loss: -0.002(R -0.076, F 0.073)] [G loss: -0.064]\n",
      "Epoch 4040 -- [D loss: -0.007(R -0.075, F 0.062)] [G loss: -0.054]\n",
      "Epoch 4041 -- [D loss: -0.006(R -0.072, F 0.059)] [G loss: -0.046]\n",
      "Epoch 4042 -- [D loss: -0.005(R -0.070, F 0.059)] [G loss: -0.041]\n",
      "Epoch 4043 -- [D loss: -0.010(R -0.068, F 0.047)] [G loss: -0.041]\n",
      "Epoch 4044 -- [D loss: -0.010(R -0.071, F 0.050)] [G loss: -0.045]\n",
      "Epoch 4045 -- [D loss: -0.012(R -0.073, F 0.049)] [G loss: -0.048]\n",
      "Epoch 4046 -- [D loss: -0.012(R -0.069, F 0.045)] [G loss: -0.049]\n",
      "Epoch 4047 -- [D loss: -0.007(R -0.064, F 0.051)] [G loss: -0.053]\n",
      "Epoch 4048 -- [D loss: -0.008(R -0.068, F 0.053)] [G loss: -0.058]\n",
      "Epoch 4049 -- [D loss: -0.004(R -0.063, F 0.055)] [G loss: -0.061]\n",
      "Epoch 4050 -- [D loss: 0.008(R -0.052, F 0.069)] [G loss: -0.065]\n",
      "Epoch 4051 -- [D loss: 0.004(R -0.070, F 0.077)] [G loss: -0.071]\n",
      "Epoch 4052 -- [D loss: 0.011(R -0.062, F 0.084)] [G loss: -0.078]\n",
      "Epoch 4053 -- [D loss: 0.008(R -0.068, F 0.084)] [G loss: -0.079]\n",
      "Epoch 4054 -- [D loss: 0.004(R -0.073, F 0.081)] [G loss: -0.080]\n",
      "Epoch 4055 -- [D loss: 0.003(R -0.073, F 0.078)] [G loss: -0.076]\n",
      "Epoch 4056 -- [D loss: -0.001(R -0.077, F 0.075)] [G loss: -0.068]\n",
      "Epoch 4057 -- [D loss: -0.003(R -0.079, F 0.073)] [G loss: -0.065]\n",
      "Epoch 4058 -- [D loss: -0.003(R -0.076, F 0.070)] [G loss: -0.063]\n",
      "Epoch 4059 -- [D loss: -0.006(R -0.085, F 0.072)] [G loss: -0.063]\n",
      "Epoch 4060 -- [D loss: -0.007(R -0.083, F 0.069)] [G loss: -0.062]\n",
      "Epoch 4061 -- [D loss: -0.014(R -0.089, F 0.060)] [G loss: -0.061]\n",
      "Epoch 4062 -- [D loss: -0.015(R -0.091, F 0.061)] [G loss: -0.065]\n",
      "Epoch 4063 -- [D loss: -0.014(R -0.087, F 0.058)] [G loss: -0.068]\n",
      "Epoch 4064 -- [D loss: -0.015(R -0.090, F 0.060)] [G loss: -0.079]\n",
      "Epoch 4065 -- [D loss: -0.005(R -0.092, F 0.081)] [G loss: -0.084]\n",
      "Epoch 4066 -- [D loss: -0.001(R -0.089, F 0.087)] [G loss: -0.092]\n",
      "Epoch 4067 -- [D loss: 0.008(R -0.093, F 0.110)] [G loss: -0.107]\n",
      "Epoch 4068 -- [D loss: 0.009(R -0.093, F 0.110)] [G loss: -0.112]\n",
      "Epoch 4069 -- [D loss: 0.006(R -0.092, F 0.104)] [G loss: -0.115]\n",
      "Epoch 4070 -- [D loss: 0.003(R -0.095, F 0.101)] [G loss: -0.109]\n",
      "Epoch 4071 -- [D loss: 0.006(R -0.092, F 0.104)] [G loss: -0.100]\n",
      "Epoch 4072 -- [D loss: -0.001(R -0.095, F 0.093)] [G loss: -0.088]\n",
      "Epoch 4073 -- [D loss: -0.002(R -0.095, F 0.090)] [G loss: -0.076]\n",
      "Epoch 4074 -- [D loss: -0.007(R -0.088, F 0.075)] [G loss: -0.069]\n",
      "Epoch 4075 -- [D loss: -0.009(R -0.089, F 0.072)] [G loss: -0.064]\n",
      "Epoch 4076 -- [D loss: -0.014(R -0.094, F 0.065)] [G loss: -0.060]\n",
      "Epoch 4077 -- [D loss: -0.022(R -0.097, F 0.054)] [G loss: -0.063]\n",
      "Epoch 4078 -- [D loss: -0.023(R -0.113, F 0.068)] [G loss: -0.070]\n",
      "Epoch 4079 -- [D loss: -0.010(R -0.109, F 0.088)] [G loss: -0.080]\n",
      "Epoch 4080 -- [D loss: 0.013(R -0.081, F 0.108)] [G loss: -0.086]\n",
      "Epoch 4081 -- [D loss: 0.008(R -0.093, F 0.109)] [G loss: -0.088]\n",
      "Epoch 4082 -- [D loss: 0.002(R -0.101, F 0.104)] [G loss: -0.091]\n",
      "Epoch 4083 -- [D loss: 0.001(R -0.091, F 0.094)] [G loss: -0.094]\n",
      "Epoch 4084 -- [D loss: 0.005(R -0.088, F 0.098)] [G loss: -0.100]\n",
      "Epoch 4085 -- [D loss: -0.000(R -0.092, F 0.092)] [G loss: -0.108]\n",
      "Epoch 4086 -- [D loss: 0.002(R -0.095, F 0.099)] [G loss: -0.113]\n",
      "Epoch 4087 -- [D loss: -0.001(R -0.096, F 0.093)] [G loss: -0.114]\n",
      "Epoch 4088 -- [D loss: 0.004(R -0.095, F 0.102)] [G loss: -0.108]\n",
      "Epoch 4089 -- [D loss: 0.004(R -0.095, F 0.103)] [G loss: -0.100]\n",
      "Epoch 4090 -- [D loss: -0.001(R -0.098, F 0.097)] [G loss: -0.089]\n",
      "Epoch 4091 -- [D loss: -0.003(R -0.101, F 0.094)] [G loss: -0.088]\n",
      "Epoch 4092 -- [D loss: -0.010(R -0.108, F 0.089)] [G loss: -0.082]\n",
      "Epoch 4093 -- [D loss: -0.015(R -0.109, F 0.079)] [G loss: -0.076]\n",
      "Epoch 4094 -- [D loss: -0.024(R -0.115, F 0.066)] [G loss: -0.072]\n",
      "Epoch 4095 -- [D loss: -0.020(R -0.123, F 0.083)] [G loss: -0.080]\n",
      "Epoch 4096 -- [D loss: -0.009(R -0.113, F 0.095)] [G loss: -0.090]\n",
      "Epoch 4097 -- [D loss: 0.001(R -0.130, F 0.132)] [G loss: -0.103]\n",
      "Epoch 4098 -- [D loss: 0.002(R -0.121, F 0.125)] [G loss: -0.108]\n",
      "Epoch 4099 -- [D loss: 0.008(R -0.106, F 0.123)] [G loss: -0.099]\n",
      "Epoch 4100 -- [D loss: 0.010(R -0.103, F 0.122)] [G loss: -0.095]\n",
      "INFO:tensorflow:Assets written to: ram://044bdd32-0d82-4194-9ac2-cd9a72fdc0d3/assets\n",
      "INFO:tensorflow:Assets written to: ram://3d545f0d-6121-4a4d-992b-9d373d7b4d29/assets\n",
      "INFO:tensorflow:Assets written to: ram://f2f31933-84b5-49e4-9f7c-7cd095c81d63/assets\n",
      "Epoch 4101 -- [D loss: -0.002(R -0.106, F 0.102)] [G loss: -0.095]\n",
      "Epoch 4102 -- [D loss: -0.001(R -0.101, F 0.099)] [G loss: -0.097]\n",
      "Epoch 4103 -- [D loss: -0.005(R -0.099, F 0.090)] [G loss: -0.103]\n",
      "Epoch 4104 -- [D loss: -0.001(R -0.098, F 0.096)] [G loss: -0.103]\n",
      "Epoch 4105 -- [D loss: 0.001(R -0.097, F 0.098)] [G loss: -0.103]\n",
      "Epoch 4106 -- [D loss: -0.001(R -0.097, F 0.096)] [G loss: -0.094]\n",
      "Epoch 4107 -- [D loss: 0.002(R -0.096, F 0.099)] [G loss: -0.090]\n",
      "Epoch 4108 -- [D loss: -0.009(R -0.104, F 0.087)] [G loss: -0.088]\n",
      "Epoch 4109 -- [D loss: 0.000(R -0.089, F 0.090)] [G loss: -0.077]\n",
      "Epoch 4110 -- [D loss: -0.010(R -0.093, F 0.073)] [G loss: -0.067]\n",
      "Epoch 4111 -- [D loss: -0.011(R -0.090, F 0.068)] [G loss: -0.058]\n",
      "Epoch 4112 -- [D loss: -0.009(R -0.082, F 0.064)] [G loss: -0.057]\n",
      "Epoch 4113 -- [D loss: -0.008(R -0.090, F 0.075)] [G loss: -0.060]\n",
      "Epoch 4114 -- [D loss: -0.002(R -0.089, F 0.085)] [G loss: -0.071]\n",
      "Epoch 4115 -- [D loss: -0.000(R -0.085, F 0.085)] [G loss: -0.074]\n",
      "Epoch 4116 -- [D loss: 0.003(R -0.080, F 0.086)] [G loss: -0.076]\n",
      "Epoch 4117 -- [D loss: 0.004(R -0.074, F 0.082)] [G loss: -0.079]\n",
      "Epoch 4118 -- [D loss: -0.005(R -0.083, F 0.072)] [G loss: -0.078]\n",
      "Epoch 4119 -- [D loss: -0.005(R -0.079, F 0.070)] [G loss: -0.083]\n",
      "Epoch 4120 -- [D loss: -0.001(R -0.078, F 0.076)] [G loss: -0.080]\n",
      "Epoch 4121 -- [D loss: 0.000(R -0.075, F 0.075)] [G loss: -0.083]\n",
      "Epoch 4122 -- [D loss: 0.002(R -0.081, F 0.085)] [G loss: -0.082]\n",
      "Epoch 4123 -- [D loss: 0.006(R -0.079, F 0.091)] [G loss: -0.079]\n",
      "Epoch 4124 -- [D loss: 0.001(R -0.082, F 0.084)] [G loss: -0.073]\n",
      "Epoch 4125 -- [D loss: -0.006(R -0.086, F 0.073)] [G loss: -0.066]\n",
      "Epoch 4126 -- [D loss: -0.012(R -0.089, F 0.064)] [G loss: -0.063]\n",
      "Epoch 4127 -- [D loss: -0.019(R -0.100, F 0.061)] [G loss: -0.059]\n",
      "Epoch 4128 -- [D loss: -0.015(R -0.095, F 0.065)] [G loss: -0.062]\n",
      "Epoch 4129 -- [D loss: -0.011(R -0.102, F 0.080)] [G loss: -0.066]\n",
      "Epoch 4130 -- [D loss: -0.004(R -0.100, F 0.091)] [G loss: -0.079]\n",
      "Epoch 4131 -- [D loss: 0.003(R -0.091, F 0.097)] [G loss: -0.078]\n",
      "Epoch 4132 -- [D loss: 0.000(R -0.097, F 0.098)] [G loss: -0.081]\n",
      "Epoch 4133 -- [D loss: -0.000(R -0.094, F 0.094)] [G loss: -0.086]\n",
      "Epoch 4134 -- [D loss: 0.004(R -0.089, F 0.097)] [G loss: -0.091]\n",
      "Epoch 4135 -- [D loss: 0.002(R -0.092, F 0.097)] [G loss: -0.093]\n",
      "Epoch 4136 -- [D loss: 0.003(R -0.092, F 0.098)] [G loss: -0.094]\n",
      "Epoch 4137 -- [D loss: 0.007(R -0.086, F 0.100)] [G loss: -0.096]\n",
      "Epoch 4138 -- [D loss: -0.000(R -0.095, F 0.094)] [G loss: -0.090]\n",
      "Epoch 4139 -- [D loss: -0.002(R -0.093, F 0.088)] [G loss: -0.078]\n",
      "Epoch 4140 -- [D loss: -0.005(R -0.094, F 0.083)] [G loss: -0.066]\n",
      "Epoch 4141 -- [D loss: -0.010(R -0.092, F 0.072)] [G loss: -0.069]\n",
      "Epoch 4142 -- [D loss: -0.012(R -0.093, F 0.069)] [G loss: -0.067]\n",
      "Epoch 4143 -- [D loss: -0.016(R -0.102, F 0.069)] [G loss: -0.066]\n",
      "Epoch 4144 -- [D loss: -0.010(R -0.087, F 0.066)] [G loss: -0.064]\n",
      "Epoch 4145 -- [D loss: -0.009(R -0.090, F 0.071)] [G loss: -0.070]\n",
      "Epoch 4146 -- [D loss: -0.002(R -0.090, F 0.086)] [G loss: -0.073]\n",
      "Epoch 4147 -- [D loss: 0.001(R -0.095, F 0.098)] [G loss: -0.078]\n",
      "Epoch 4148 -- [D loss: 0.004(R -0.091, F 0.099)] [G loss: -0.079]\n",
      "Epoch 4149 -- [D loss: 0.003(R -0.088, F 0.094)] [G loss: -0.084]\n",
      "Epoch 4150 -- [D loss: 0.001(R -0.094, F 0.096)] [G loss: -0.090]\n",
      "Epoch 4151 -- [D loss: -0.001(R -0.099, F 0.098)] [G loss: -0.095]\n",
      "Epoch 4152 -- [D loss: 0.003(R -0.097, F 0.103)] [G loss: -0.097]\n",
      "Epoch 4153 -- [D loss: -0.001(R -0.097, F 0.095)] [G loss: -0.098]\n",
      "Epoch 4154 -- [D loss: -0.002(R -0.098, F 0.093)] [G loss: -0.095]\n",
      "Epoch 4155 -- [D loss: 0.003(R -0.093, F 0.100)] [G loss: -0.093]\n",
      "Epoch 4156 -- [D loss: 0.001(R -0.092, F 0.094)] [G loss: -0.086]\n",
      "Epoch 4157 -- [D loss: -0.003(R -0.092, F 0.085)] [G loss: -0.082]\n",
      "Epoch 4158 -- [D loss: -0.004(R -0.092, F 0.085)] [G loss: -0.081]\n",
      "Epoch 4159 -- [D loss: -0.008(R -0.095, F 0.078)] [G loss: -0.077]\n",
      "Epoch 4160 -- [D loss: -0.002(R -0.087, F 0.082)] [G loss: -0.077]\n",
      "Epoch 4161 -- [D loss: -0.003(R -0.089, F 0.083)] [G loss: -0.082]\n",
      "Epoch 4162 -- [D loss: -0.001(R -0.093, F 0.091)] [G loss: -0.080]\n",
      "Epoch 4163 -- [D loss: -0.006(R -0.098, F 0.086)] [G loss: -0.081]\n",
      "Epoch 4164 -- [D loss: -0.004(R -0.102, F 0.093)] [G loss: -0.080]\n",
      "Epoch 4165 -- [D loss: -0.006(R -0.101, F 0.089)] [G loss: -0.076]\n",
      "Epoch 4166 -- [D loss: -0.005(R -0.101, F 0.090)] [G loss: -0.084]\n",
      "Epoch 4167 -- [D loss: -0.002(R -0.092, F 0.088)] [G loss: -0.087]\n",
      "Epoch 4168 -- [D loss: -0.003(R -0.098, F 0.092)] [G loss: -0.087]\n",
      "Epoch 4169 -- [D loss: -0.002(R -0.101, F 0.098)] [G loss: -0.091]\n",
      "Epoch 4170 -- [D loss: -0.002(R -0.097, F 0.094)] [G loss: -0.088]\n",
      "Epoch 4171 -- [D loss: 0.000(R -0.096, F 0.097)] [G loss: -0.087]\n",
      "Epoch 4172 -- [D loss: 0.000(R -0.090, F 0.091)] [G loss: -0.082]\n",
      "Epoch 4173 -- [D loss: 0.000(R -0.089, F 0.090)] [G loss: -0.076]\n",
      "Epoch 4174 -- [D loss: -0.002(R -0.084, F 0.080)] [G loss: -0.070]\n",
      "Epoch 4175 -- [D loss: -0.003(R -0.084, F 0.077)] [G loss: -0.070]\n",
      "Epoch 4176 -- [D loss: -0.004(R -0.078, F 0.071)] [G loss: -0.071]\n",
      "Epoch 4177 -- [D loss: -0.003(R -0.071, F 0.064)] [G loss: -0.070]\n",
      "Epoch 4178 -- [D loss: -0.003(R -0.075, F 0.069)] [G loss: -0.070]\n",
      "Epoch 4179 -- [D loss: -0.001(R -0.075, F 0.072)] [G loss: -0.070]\n",
      "Epoch 4180 -- [D loss: -0.003(R -0.069, F 0.063)] [G loss: -0.064]\n",
      "Epoch 4181 -- [D loss: -0.002(R -0.076, F 0.072)] [G loss: -0.063]\n",
      "Epoch 4182 -- [D loss: -0.000(R -0.072, F 0.072)] [G loss: -0.066]\n",
      "Epoch 4183 -- [D loss: -0.001(R -0.073, F 0.072)] [G loss: -0.067]\n",
      "Epoch 4184 -- [D loss: -0.000(R -0.073, F 0.073)] [G loss: -0.064]\n",
      "Epoch 4185 -- [D loss: -0.005(R -0.083, F 0.072)] [G loss: -0.062]\n",
      "Epoch 4186 -- [D loss: -0.004(R -0.077, F 0.070)] [G loss: -0.063]\n",
      "Epoch 4187 -- [D loss: -0.005(R -0.080, F 0.070)] [G loss: -0.064]\n",
      "Epoch 4188 -- [D loss: -0.007(R -0.083, F 0.070)] [G loss: -0.067]\n",
      "Epoch 4189 -- [D loss: -0.004(R -0.083, F 0.075)] [G loss: -0.072]\n",
      "Epoch 4190 -- [D loss: -0.008(R -0.089, F 0.074)] [G loss: -0.076]\n",
      "Epoch 4191 -- [D loss: -0.011(R -0.098, F 0.077)] [G loss: -0.082]\n",
      "Epoch 4192 -- [D loss: -0.013(R -0.113, F 0.086)] [G loss: -0.100]\n",
      "Epoch 4193 -- [D loss: -0.008(R -0.114, F 0.098)] [G loss: -0.114]\n",
      "Epoch 4194 -- [D loss: -0.005(R -0.104, F 0.095)] [G loss: -0.122]\n",
      "Epoch 4195 -- [D loss: -0.002(R -0.109, F 0.105)] [G loss: -0.119]\n",
      "Epoch 4196 -- [D loss: 0.009(R -0.106, F 0.125)] [G loss: -0.116]\n",
      "Epoch 4197 -- [D loss: 0.004(R -0.102, F 0.110)] [G loss: -0.103]\n",
      "Epoch 4198 -- [D loss: 0.004(R -0.092, F 0.099)] [G loss: -0.089]\n",
      "Epoch 4199 -- [D loss: -0.004(R -0.088, F 0.081)] [G loss: -0.069]\n",
      "Epoch 4200 -- [D loss: -0.015(R -0.089, F 0.059)] [G loss: -0.052]\n",
      "INFO:tensorflow:Assets written to: ram://df59ce9e-432c-4c29-9412-7a594e35538b/assets\n",
      "INFO:tensorflow:Assets written to: ram://171a8b2b-714a-4826-9b49-c2cccb56f41e/assets\n",
      "INFO:tensorflow:Assets written to: ram://68af6339-a4e0-4a1e-9af4-512f12e94ef8/assets\n",
      "Epoch 4201 -- [D loss: -0.024(R -0.088, F 0.039)] [G loss: -0.040]\n",
      "Epoch 4202 -- [D loss: -0.024(R -0.080, F 0.032)] [G loss: -0.037]\n",
      "Epoch 4203 -- [D loss: -0.016(R -0.073, F 0.041)] [G loss: -0.045]\n",
      "Epoch 4204 -- [D loss: -0.004(R -0.071, F 0.062)] [G loss: -0.052]\n",
      "Epoch 4205 -- [D loss: -0.011(R -0.067, F 0.045)] [G loss: -0.054]\n",
      "Epoch 4206 -- [D loss: -0.002(R -0.076, F 0.072)] [G loss: -0.064]\n",
      "Epoch 4207 -- [D loss: -0.002(R -0.070, F 0.065)] [G loss: -0.068]\n",
      "Epoch 4208 -- [D loss: -0.002(R -0.069, F 0.065)] [G loss: -0.070]\n",
      "Epoch 4209 -- [D loss: 0.003(R -0.065, F 0.071)] [G loss: -0.076]\n",
      "Epoch 4210 -- [D loss: 0.010(R -0.069, F 0.089)] [G loss: -0.074]\n",
      "Epoch 4211 -- [D loss: 0.001(R -0.074, F 0.076)] [G loss: -0.079]\n",
      "Epoch 4212 -- [D loss: 0.003(R -0.080, F 0.086)] [G loss: -0.077]\n",
      "Epoch 4213 -- [D loss: 0.002(R -0.082, F 0.086)] [G loss: -0.074]\n",
      "Epoch 4214 -- [D loss: 0.001(R -0.083, F 0.085)] [G loss: -0.075]\n",
      "Epoch 4215 -- [D loss: -0.004(R -0.081, F 0.072)] [G loss: -0.074]\n",
      "Epoch 4216 -- [D loss: 0.000(R -0.086, F 0.086)] [G loss: -0.072]\n",
      "Epoch 4217 -- [D loss: -0.003(R -0.089, F 0.084)] [G loss: -0.070]\n",
      "Epoch 4218 -- [D loss: -0.007(R -0.083, F 0.070)] [G loss: -0.067]\n",
      "Epoch 4219 -- [D loss: -0.006(R -0.087, F 0.074)] [G loss: -0.063]\n",
      "Epoch 4220 -- [D loss: -0.007(R -0.085, F 0.072)] [G loss: -0.067]\n",
      "Epoch 4221 -- [D loss: -0.008(R -0.087, F 0.071)] [G loss: -0.066]\n",
      "Epoch 4222 -- [D loss: -0.007(R -0.090, F 0.075)] [G loss: -0.076]\n",
      "Epoch 4223 -- [D loss: -0.007(R -0.094, F 0.080)] [G loss: -0.081]\n",
      "Epoch 4224 -- [D loss: -0.002(R -0.090, F 0.086)] [G loss: -0.086]\n",
      "Epoch 4225 -- [D loss: 0.001(R -0.088, F 0.091)] [G loss: -0.094]\n",
      "Epoch 4226 -- [D loss: -0.003(R -0.091, F 0.085)] [G loss: -0.092]\n",
      "Epoch 4227 -- [D loss: -0.002(R -0.092, F 0.088)] [G loss: -0.092]\n",
      "Epoch 4228 -- [D loss: -0.004(R -0.090, F 0.083)] [G loss: -0.095]\n",
      "Epoch 4229 -- [D loss: -0.004(R -0.085, F 0.077)] [G loss: -0.090]\n",
      "Epoch 4230 -- [D loss: 0.001(R -0.081, F 0.082)] [G loss: -0.083]\n",
      "Epoch 4231 -- [D loss: -0.006(R -0.085, F 0.074)] [G loss: -0.078]\n",
      "Epoch 4232 -- [D loss: -0.001(R -0.074, F 0.072)] [G loss: -0.071]\n",
      "Epoch 4233 -- [D loss: -0.002(R -0.077, F 0.074)] [G loss: -0.063]\n",
      "Epoch 4234 -- [D loss: -0.004(R -0.069, F 0.060)] [G loss: -0.050]\n",
      "Epoch 4235 -- [D loss: -0.015(R -0.075, F 0.044)] [G loss: -0.040]\n",
      "Epoch 4236 -- [D loss: -0.016(R -0.071, F 0.039)] [G loss: -0.033]\n",
      "Epoch 4237 -- [D loss: -0.009(R -0.062, F 0.045)] [G loss: -0.035]\n",
      "Epoch 4238 -- [D loss: -0.010(R -0.064, F 0.044)] [G loss: -0.036]\n",
      "Epoch 4239 -- [D loss: -0.002(R -0.057, F 0.053)] [G loss: -0.040]\n",
      "Epoch 4240 -- [D loss: 0.001(R -0.059, F 0.061)] [G loss: -0.049]\n",
      "Epoch 4241 -- [D loss: 0.003(R -0.061, F 0.066)] [G loss: -0.052]\n",
      "Epoch 4242 -- [D loss: 0.001(R -0.067, F 0.068)] [G loss: -0.056]\n",
      "Epoch 4243 -- [D loss: -0.001(R -0.068, F 0.065)] [G loss: -0.055]\n",
      "Epoch 4244 -- [D loss: -0.001(R -0.064, F 0.063)] [G loss: -0.060]\n",
      "Epoch 4245 -- [D loss: -0.001(R -0.066, F 0.064)] [G loss: -0.059]\n",
      "Epoch 4246 -- [D loss: -0.003(R -0.068, F 0.062)] [G loss: -0.055]\n",
      "Epoch 4247 -- [D loss: -0.004(R -0.068, F 0.060)] [G loss: -0.050]\n",
      "Epoch 4248 -- [D loss: -0.006(R -0.071, F 0.058)] [G loss: -0.052]\n",
      "Epoch 4249 -- [D loss: -0.002(R -0.065, F 0.062)] [G loss: -0.055]\n",
      "Epoch 4250 -- [D loss: -0.006(R -0.073, F 0.062)] [G loss: -0.060]\n",
      "Epoch 4251 -- [D loss: -0.004(R -0.077, F 0.069)] [G loss: -0.063]\n",
      "Epoch 4252 -- [D loss: -0.002(R -0.075, F 0.071)] [G loss: -0.068]\n",
      "Epoch 4253 -- [D loss: -0.002(R -0.079, F 0.075)] [G loss: -0.072]\n",
      "Epoch 4254 -- [D loss: -0.004(R -0.085, F 0.077)] [G loss: -0.069]\n",
      "Epoch 4255 -- [D loss: -0.002(R -0.084, F 0.080)] [G loss: -0.069]\n",
      "Epoch 4256 -- [D loss: -0.004(R -0.085, F 0.077)] [G loss: -0.069]\n",
      "Epoch 4257 -- [D loss: -0.003(R -0.084, F 0.079)] [G loss: -0.073]\n",
      "Epoch 4258 -- [D loss: -0.000(R -0.078, F 0.077)] [G loss: -0.075]\n",
      "Epoch 4259 -- [D loss: -0.006(R -0.087, F 0.074)] [G loss: -0.068]\n",
      "Epoch 4260 -- [D loss: -0.004(R -0.085, F 0.077)] [G loss: -0.063]\n",
      "Epoch 4261 -- [D loss: -0.003(R -0.079, F 0.073)] [G loss: -0.055]\n",
      "Epoch 4262 -- [D loss: -0.005(R -0.079, F 0.070)] [G loss: -0.053]\n",
      "Epoch 4263 -- [D loss: -0.006(R -0.076, F 0.064)] [G loss: -0.054]\n",
      "Epoch 4264 -- [D loss: -0.005(R -0.073, F 0.063)] [G loss: -0.057]\n",
      "Epoch 4265 -- [D loss: -0.007(R -0.077, F 0.062)] [G loss: -0.063]\n",
      "Epoch 4266 -- [D loss: -0.007(R -0.077, F 0.063)] [G loss: -0.058]\n",
      "Epoch 4267 -- [D loss: -0.003(R -0.077, F 0.072)] [G loss: -0.058]\n",
      "Epoch 4268 -- [D loss: -0.002(R -0.070, F 0.066)] [G loss: -0.066]\n",
      "Epoch 4269 -- [D loss: -0.001(R -0.071, F 0.068)] [G loss: -0.065]\n",
      "Epoch 4270 -- [D loss: -0.002(R -0.073, F 0.068)] [G loss: -0.065]\n",
      "Epoch 4271 -- [D loss: -0.003(R -0.072, F 0.066)] [G loss: -0.070]\n",
      "Epoch 4272 -- [D loss: -0.001(R -0.072, F 0.069)] [G loss: -0.063]\n",
      "Epoch 4273 -- [D loss: -0.004(R -0.070, F 0.062)] [G loss: -0.054]\n",
      "Epoch 4274 -- [D loss: -0.005(R -0.072, F 0.063)] [G loss: -0.056]\n",
      "Epoch 4275 -- [D loss: -0.007(R -0.075, F 0.062)] [G loss: -0.054]\n",
      "Epoch 4276 -- [D loss: -0.008(R -0.078, F 0.062)] [G loss: -0.058]\n",
      "Epoch 4277 -- [D loss: -0.001(R -0.072, F 0.069)] [G loss: -0.060]\n",
      "Epoch 4278 -- [D loss: -0.007(R -0.082, F 0.067)] [G loss: -0.061]\n",
      "Epoch 4279 -- [D loss: -0.002(R -0.077, F 0.073)] [G loss: -0.065]\n",
      "Epoch 4280 -- [D loss: -0.003(R -0.083, F 0.078)] [G loss: -0.070]\n",
      "Epoch 4281 -- [D loss: -0.002(R -0.081, F 0.078)] [G loss: -0.071]\n",
      "Epoch 4282 -- [D loss: -0.003(R -0.083, F 0.077)] [G loss: -0.071]\n",
      "Epoch 4283 -- [D loss: -0.004(R -0.082, F 0.075)] [G loss: -0.068]\n",
      "Epoch 4284 -- [D loss: -0.006(R -0.078, F 0.067)] [G loss: -0.060]\n",
      "Epoch 4285 -- [D loss: -0.010(R -0.080, F 0.060)] [G loss: -0.055]\n",
      "Epoch 4286 -- [D loss: -0.012(R -0.079, F 0.056)] [G loss: -0.051]\n",
      "Epoch 4287 -- [D loss: -0.008(R -0.075, F 0.059)] [G loss: -0.048]\n",
      "Epoch 4288 -- [D loss: -0.008(R -0.075, F 0.059)] [G loss: -0.056]\n",
      "Epoch 4289 -- [D loss: -0.005(R -0.075, F 0.064)] [G loss: -0.057]\n",
      "Epoch 4290 -- [D loss: -0.000(R -0.071, F 0.070)] [G loss: -0.063]\n",
      "Epoch 4291 -- [D loss: -0.004(R -0.077, F 0.070)] [G loss: -0.066]\n",
      "Epoch 4292 -- [D loss: -0.001(R -0.071, F 0.068)] [G loss: -0.067]\n",
      "Epoch 4293 -- [D loss: -0.004(R -0.076, F 0.068)] [G loss: -0.073]\n",
      "Epoch 4294 -- [D loss: -0.001(R -0.069, F 0.068)] [G loss: -0.066]\n",
      "Epoch 4295 -- [D loss: -0.002(R -0.069, F 0.066)] [G loss: -0.062]\n",
      "Epoch 4296 -- [D loss: -0.012(R -0.077, F 0.053)] [G loss: -0.050]\n",
      "Epoch 4297 -- [D loss: -0.008(R -0.069, F 0.052)] [G loss: -0.044]\n",
      "Epoch 4298 -- [D loss: -0.011(R -0.075, F 0.053)] [G loss: -0.042]\n",
      "Epoch 4299 -- [D loss: -0.013(R -0.072, F 0.046)] [G loss: -0.045]\n",
      "Epoch 4300 -- [D loss: -0.014(R -0.073, F 0.046)] [G loss: -0.048]\n",
      "INFO:tensorflow:Assets written to: ram://3e2a1469-58f8-4397-9003-c8f2f48dfa0a/assets\n",
      "INFO:tensorflow:Assets written to: ram://e49cdad6-5904-408f-baaf-edeb6cc6c9ef/assets\n",
      "INFO:tensorflow:Assets written to: ram://682cbfd4-32ec-4fd7-9af5-2aa831b5acb1/assets\n",
      "Epoch 4301 -- [D loss: -0.016(R -0.075, F 0.042)] [G loss: -0.047]\n",
      "Epoch 4302 -- [D loss: -0.009(R -0.070, F 0.053)] [G loss: -0.046]\n",
      "Epoch 4303 -- [D loss: -0.001(R -0.075, F 0.073)] [G loss: -0.057]\n",
      "Epoch 4304 -- [D loss: 0.002(R -0.080, F 0.084)] [G loss: -0.079]\n",
      "Epoch 4305 -- [D loss: -0.003(R -0.084, F 0.078)] [G loss: -0.078]\n",
      "Epoch 4306 -- [D loss: -0.005(R -0.087, F 0.077)] [G loss: -0.073]\n",
      "Epoch 4307 -- [D loss: -0.007(R -0.087, F 0.073)] [G loss: -0.072]\n",
      "Epoch 4308 -- [D loss: -0.008(R -0.087, F 0.072)] [G loss: -0.065]\n",
      "Epoch 4309 -- [D loss: -0.004(R -0.085, F 0.077)] [G loss: -0.070]\n",
      "Epoch 4310 -- [D loss: -0.008(R -0.079, F 0.063)] [G loss: -0.059]\n",
      "Epoch 4311 -- [D loss: -0.013(R -0.083, F 0.058)] [G loss: -0.051]\n",
      "Epoch 4312 -- [D loss: -0.007(R -0.078, F 0.065)] [G loss: -0.047]\n",
      "Epoch 4313 -- [D loss: -0.003(R -0.078, F 0.072)] [G loss: -0.057]\n",
      "Epoch 4314 -- [D loss: -0.003(R -0.078, F 0.072)] [G loss: -0.060]\n",
      "Epoch 4315 -- [D loss: -0.005(R -0.075, F 0.065)] [G loss: -0.054]\n",
      "Epoch 4316 -- [D loss: -0.010(R -0.076, F 0.055)] [G loss: -0.049]\n",
      "Epoch 4317 -- [D loss: -0.011(R -0.077, F 0.055)] [G loss: -0.054]\n",
      "Epoch 4318 -- [D loss: -0.008(R -0.077, F 0.061)] [G loss: -0.057]\n",
      "Epoch 4319 -- [D loss: -0.005(R -0.075, F 0.065)] [G loss: -0.063]\n",
      "Epoch 4320 -- [D loss: -0.006(R -0.075, F 0.063)] [G loss: -0.060]\n",
      "Epoch 4321 -- [D loss: -0.006(R -0.074, F 0.062)] [G loss: -0.057]\n",
      "Epoch 4322 -- [D loss: -0.006(R -0.069, F 0.056)] [G loss: -0.050]\n",
      "Epoch 4323 -- [D loss: 0.001(R -0.063, F 0.065)] [G loss: -0.045]\n",
      "Epoch 4324 -- [D loss: -0.003(R -0.068, F 0.061)] [G loss: -0.043]\n",
      "Epoch 4325 -- [D loss: -0.001(R -0.051, F 0.050)] [G loss: -0.049]\n",
      "Epoch 4326 -- [D loss: -0.004(R -0.065, F 0.057)] [G loss: -0.057]\n",
      "Epoch 4327 -- [D loss: -0.002(R -0.066, F 0.063)] [G loss: -0.055]\n",
      "Epoch 4328 -- [D loss: -0.006(R -0.081, F 0.069)] [G loss: -0.053]\n",
      "Epoch 4329 -- [D loss: -0.004(R -0.078, F 0.070)] [G loss: -0.061]\n",
      "Epoch 4330 -- [D loss: -0.007(R -0.081, F 0.067)] [G loss: -0.058]\n",
      "Epoch 4331 -- [D loss: -0.006(R -0.074, F 0.062)] [G loss: -0.052]\n",
      "Epoch 4332 -- [D loss: -0.003(R -0.080, F 0.075)] [G loss: -0.068]\n",
      "Epoch 4333 -- [D loss: -0.002(R -0.081, F 0.078)] [G loss: -0.068]\n",
      "Epoch 4334 -- [D loss: -0.003(R -0.085, F 0.080)] [G loss: -0.069]\n",
      "Epoch 4335 -- [D loss: -0.009(R -0.084, F 0.066)] [G loss: -0.059]\n",
      "Epoch 4336 -- [D loss: -0.008(R -0.081, F 0.065)] [G loss: -0.053]\n",
      "Epoch 4337 -- [D loss: -0.012(R -0.087, F 0.064)] [G loss: -0.055]\n",
      "Epoch 4338 -- [D loss: -0.008(R -0.090, F 0.073)] [G loss: -0.072]\n",
      "Epoch 4339 -- [D loss: -0.006(R -0.085, F 0.074)] [G loss: -0.084]\n",
      "Epoch 4340 -- [D loss: -0.009(R -0.094, F 0.077)] [G loss: -0.075]\n",
      "Epoch 4341 -- [D loss: -0.010(R -0.096, F 0.077)] [G loss: -0.074]\n",
      "Epoch 4342 -- [D loss: -0.009(R -0.089, F 0.070)] [G loss: -0.066]\n",
      "Epoch 4343 -- [D loss: -0.018(R -0.087, F 0.051)] [G loss: -0.048]\n",
      "Epoch 4344 -- [D loss: -0.014(R -0.074, F 0.045)] [G loss: -0.037]\n",
      "Epoch 4345 -- [D loss: -0.018(R -0.073, F 0.037)] [G loss: -0.045]\n",
      "Epoch 4346 -- [D loss: -0.008(R -0.061, F 0.045)] [G loss: -0.036]\n",
      "Epoch 4347 -- [D loss: -0.004(R -0.059, F 0.051)] [G loss: -0.051]\n",
      "Epoch 4348 -- [D loss: -0.005(R -0.067, F 0.057)] [G loss: -0.052]\n",
      "Epoch 4349 -- [D loss: 0.004(R -0.059, F 0.068)] [G loss: -0.051]\n",
      "Epoch 4350 -- [D loss: -0.004(R -0.070, F 0.062)] [G loss: -0.055]\n",
      "Epoch 4351 -- [D loss: -0.008(R -0.075, F 0.058)] [G loss: -0.056]\n",
      "Epoch 4352 -- [D loss: -0.007(R -0.072, F 0.059)] [G loss: -0.050]\n",
      "Epoch 4353 -- [D loss: -0.010(R -0.075, F 0.056)] [G loss: -0.050]\n",
      "Epoch 4354 -- [D loss: -0.004(R -0.072, F 0.064)] [G loss: -0.046]\n",
      "Epoch 4355 -- [D loss: -0.012(R -0.071, F 0.047)] [G loss: -0.044]\n",
      "Epoch 4356 -- [D loss: -0.011(R -0.071, F 0.049)] [G loss: -0.055]\n",
      "Epoch 4357 -- [D loss: -0.012(R -0.074, F 0.051)] [G loss: -0.069]\n",
      "Epoch 4358 -- [D loss: -0.003(R -0.070, F 0.065)] [G loss: -0.055]\n",
      "Epoch 4359 -- [D loss: -0.009(R -0.075, F 0.056)] [G loss: -0.047]\n",
      "Epoch 4360 -- [D loss: -0.015(R -0.079, F 0.050)] [G loss: -0.042]\n",
      "Epoch 4361 -- [D loss: -0.012(R -0.062, F 0.039)] [G loss: -0.044]\n",
      "Epoch 4362 -- [D loss: -0.013(R -0.074, F 0.048)] [G loss: -0.052]\n",
      "Epoch 4363 -- [D loss: -0.012(R -0.066, F 0.042)] [G loss: -0.050]\n",
      "Epoch 4364 -- [D loss: -0.015(R -0.074, F 0.044)] [G loss: -0.046]\n",
      "Epoch 4365 -- [D loss: -0.008(R -0.075, F 0.058)] [G loss: -0.052]\n",
      "Epoch 4366 -- [D loss: -0.007(R -0.074, F 0.060)] [G loss: -0.063]\n",
      "Epoch 4367 -- [D loss: -0.018(R -0.093, F 0.058)] [G loss: -0.062]\n",
      "Epoch 4368 -- [D loss: -0.010(R -0.074, F 0.054)] [G loss: -0.055]\n",
      "Epoch 4369 -- [D loss: -0.021(R -0.086, F 0.045)] [G loss: -0.051]\n",
      "Epoch 4370 -- [D loss: -0.009(R -0.075, F 0.057)] [G loss: -0.060]\n",
      "Epoch 4371 -- [D loss: -0.017(R -0.087, F 0.054)] [G loss: -0.059]\n",
      "Epoch 4372 -- [D loss: -0.025(R -0.102, F 0.051)] [G loss: -0.064]\n",
      "Epoch 4373 -- [D loss: -0.001(R -0.080, F 0.078)] [G loss: -0.072]\n",
      "Epoch 4374 -- [D loss: 0.007(R -0.075, F 0.090)] [G loss: -0.084]\n",
      "Epoch 4375 -- [D loss: 0.001(R -0.083, F 0.084)] [G loss: -0.088]\n",
      "Epoch 4376 -- [D loss: -0.000(R -0.084, F 0.084)] [G loss: -0.085]\n",
      "Epoch 4377 -- [D loss: -0.005(R -0.085, F 0.075)] [G loss: -0.074]\n",
      "Epoch 4378 -- [D loss: -0.007(R -0.087, F 0.073)] [G loss: -0.063]\n",
      "Epoch 4379 -- [D loss: -0.023(R -0.093, F 0.048)] [G loss: -0.044]\n",
      "Epoch 4380 -- [D loss: -0.021(R -0.087, F 0.046)] [G loss: -0.037]\n",
      "Epoch 4381 -- [D loss: -0.026(R -0.094, F 0.041)] [G loss: -0.037]\n",
      "Epoch 4382 -- [D loss: -0.025(R -0.089, F 0.040)] [G loss: -0.042]\n",
      "Epoch 4383 -- [D loss: -0.003(R -0.077, F 0.071)] [G loss: -0.063]\n",
      "Epoch 4384 -- [D loss: -0.010(R -0.093, F 0.072)] [G loss: -0.103]\n",
      "Epoch 4385 -- [D loss: 0.001(R -0.083, F 0.084)] [G loss: -0.122]\n",
      "Epoch 4386 -- [D loss: -0.002(R -0.082, F 0.077)] [G loss: -0.115]\n",
      "Epoch 4387 -- [D loss: -0.014(R -0.076, F 0.047)] [G loss: -0.078]\n",
      "Epoch 4388 -- [D loss: -0.010(R -0.069, F 0.048)] [G loss: -0.044]\n",
      "Epoch 4389 -- [D loss: -0.012(R -0.052, F 0.027)] [G loss: -0.007]\n",
      "Epoch 4390 -- [D loss: -0.026(R -0.054, F 0.002)] [G loss: 0.002]\n",
      "Epoch 4391 -- [D loss: -0.019(R -0.073, F 0.036)] [G loss: -0.023]\n",
      "Epoch 4392 -- [D loss: -0.022(R -0.069, F 0.025)] [G loss: -0.043]\n",
      "Epoch 4393 -- [D loss: -0.031(R -0.075, F 0.014)] [G loss: -0.031]\n",
      "Epoch 4394 -- [D loss: -0.022(R -0.065, F 0.021)] [G loss: -0.031]\n",
      "Epoch 4395 -- [D loss: -0.017(R -0.081, F 0.047)] [G loss: -0.016]\n",
      "Epoch 4396 -- [D loss: -0.022(R -0.081, F 0.038)] [G loss: -0.027]\n",
      "Epoch 4397 -- [D loss: -0.005(R -0.074, F 0.064)] [G loss: -0.044]\n",
      "Epoch 4398 -- [D loss: -0.009(R -0.072, F 0.054)] [G loss: -0.056]\n",
      "Epoch 4399 -- [D loss: -0.004(R -0.064, F 0.056)] [G loss: -0.058]\n",
      "Epoch 4400 -- [D loss: -0.009(R -0.065, F 0.046)] [G loss: -0.047]\n",
      "INFO:tensorflow:Assets written to: ram://d3d6db55-ff81-4424-ba2d-ad6788bb2f58/assets\n",
      "INFO:tensorflow:Assets written to: ram://67e0322a-8b04-4cc9-bceb-df9b4858fc1c/assets\n",
      "INFO:tensorflow:Assets written to: ram://560e8c4d-a6f7-497b-a1c1-5333aac4b35b/assets\n",
      "Epoch 4401 -- [D loss: -0.010(R -0.053, F 0.033)] [G loss: -0.021]\n",
      "Epoch 4402 -- [D loss: -0.016(R -0.044, F 0.012)] [G loss: -0.010]\n",
      "Epoch 4403 -- [D loss: -0.039(R -0.063, F -0.015)] [G loss: -0.003]\n",
      "Epoch 4404 -- [D loss: -0.022(R -0.042, F -0.002)] [G loss: -0.023]\n",
      "Epoch 4405 -- [D loss: -0.009(R -0.033, F 0.015)] [G loss: -0.037]\n",
      "Epoch 4406 -- [D loss: 0.003(R -0.020, F 0.025)] [G loss: -0.047]\n",
      "Epoch 4407 -- [D loss: -0.004(R -0.041, F 0.032)] [G loss: -0.054]\n",
      "Epoch 4408 -- [D loss: 0.009(R -0.014, F 0.031)] [G loss: -0.062]\n",
      "Epoch 4409 -- [D loss: -0.007(R -0.045, F 0.031)] [G loss: -0.059]\n",
      "Epoch 4410 -- [D loss: -0.007(R -0.030, F 0.016)] [G loss: -0.056]\n",
      "Epoch 4411 -- [D loss: -0.016(R -0.048, F 0.017)] [G loss: -0.045]\n",
      "Epoch 4412 -- [D loss: -0.012(R -0.048, F 0.024)] [G loss: -0.045]\n",
      "Epoch 4413 -- [D loss: -0.017(R -0.065, F 0.032)] [G loss: -0.049]\n",
      "Epoch 4414 -- [D loss: -0.022(R -0.076, F 0.033)] [G loss: -0.043]\n",
      "Epoch 4415 -- [D loss: -0.034(R -0.088, F 0.021)] [G loss: -0.055]\n",
      "Epoch 4416 -- [D loss: -0.016(R -0.097, F 0.065)] [G loss: -0.084]\n",
      "Epoch 4417 -- [D loss: -0.035(R -0.128, F 0.058)] [G loss: -0.099]\n",
      "Epoch 4418 -- [D loss: -0.019(R -0.134, F 0.097)] [G loss: -0.124]\n",
      "Epoch 4419 -- [D loss: 0.007(R -0.121, F 0.135)] [G loss: -0.165]\n",
      "Epoch 4420 -- [D loss: 0.005(R -0.155, F 0.165)] [G loss: -0.177]\n",
      "Epoch 4421 -- [D loss: 0.003(R -0.152, F 0.157)] [G loss: -0.192]\n",
      "Epoch 4422 -- [D loss: 0.005(R -0.147, F 0.156)] [G loss: -0.186]\n",
      "Epoch 4423 -- [D loss: 0.003(R -0.149, F 0.156)] [G loss: -0.163]\n",
      "Epoch 4424 -- [D loss: -0.013(R -0.148, F 0.122)] [G loss: -0.120]\n",
      "Epoch 4425 -- [D loss: -0.020(R -0.144, F 0.103)] [G loss: -0.081]\n",
      "Epoch 4426 -- [D loss: -0.034(R -0.140, F 0.071)] [G loss: -0.059]\n",
      "Epoch 4427 -- [D loss: -0.029(R -0.103, F 0.045)] [G loss: -0.043]\n",
      "Epoch 4428 -- [D loss: -0.019(R -0.098, F 0.060)] [G loss: -0.060]\n",
      "Epoch 4429 -- [D loss: -0.021(R -0.097, F 0.054)] [G loss: -0.057]\n",
      "Epoch 4430 -- [D loss: -0.006(R -0.082, F 0.069)] [G loss: -0.060]\n",
      "Epoch 4431 -- [D loss: -0.002(R -0.068, F 0.063)] [G loss: -0.075]\n",
      "Epoch 4432 -- [D loss: -0.000(R -0.072, F 0.071)] [G loss: -0.079]\n",
      "Epoch 4433 -- [D loss: 0.018(R -0.030, F 0.066)] [G loss: -0.067]\n",
      "Epoch 4434 -- [D loss: 0.022(R -0.014, F 0.058)] [G loss: -0.060]\n",
      "Epoch 4435 -- [D loss: 0.022(R -0.018, F 0.061)] [G loss: -0.052]\n",
      "Epoch 4436 -- [D loss: 0.008(R -0.024, F 0.041)] [G loss: -0.039]\n",
      "Epoch 4437 -- [D loss: 0.011(R -0.016, F 0.037)] [G loss: -0.029]\n",
      "Epoch 4438 -- [D loss: 0.002(R -0.014, F 0.017)] [G loss: -0.010]\n",
      "Epoch 4439 -- [D loss: -0.011(R -0.029, F 0.007)] [G loss: 0.001]\n",
      "Epoch 4440 -- [D loss: -0.025(R -0.042, F -0.007)] [G loss: 0.010]\n",
      "Epoch 4441 -- [D loss: -0.035(R -0.068, F -0.003)] [G loss: 0.005]\n",
      "Epoch 4442 -- [D loss: -0.038(R -0.091, F 0.016)] [G loss: 0.000]\n",
      "Epoch 4443 -- [D loss: -0.043(R -0.096, F 0.009)] [G loss: -0.020]\n",
      "Epoch 4444 -- [D loss: -0.034(R -0.100, F 0.032)] [G loss: -0.031]\n",
      "Epoch 4445 -- [D loss: -0.024(R -0.098, F 0.051)] [G loss: -0.079]\n",
      "Epoch 4446 -- [D loss: -0.017(R -0.110, F 0.075)] [G loss: -0.109]\n",
      "Epoch 4447 -- [D loss: 0.002(R -0.116, F 0.119)] [G loss: -0.157]\n",
      "Epoch 4448 -- [D loss: -0.006(R -0.126, F 0.114)] [G loss: -0.205]\n",
      "Epoch 4449 -- [D loss: 0.011(R -0.129, F 0.151)] [G loss: -0.219]\n",
      "Epoch 4450 -- [D loss: 0.024(R -0.116, F 0.163)] [G loss: -0.217]\n",
      "Epoch 4451 -- [D loss: 0.023(R -0.112, F 0.157)] [G loss: -0.185]\n",
      "Epoch 4452 -- [D loss: 0.028(R -0.109, F 0.165)] [G loss: -0.152]\n",
      "Epoch 4453 -- [D loss: 0.014(R -0.107, F 0.135)] [G loss: -0.118]\n",
      "Epoch 4454 -- [D loss: -0.000(R -0.111, F 0.111)] [G loss: -0.084]\n",
      "Epoch 4455 -- [D loss: -0.017(R -0.124, F 0.089)] [G loss: -0.069]\n",
      "Epoch 4456 -- [D loss: -0.034(R -0.147, F 0.080)] [G loss: -0.062]\n",
      "Epoch 4457 -- [D loss: -0.048(R -0.156, F 0.061)] [G loss: -0.072]\n",
      "Epoch 4458 -- [D loss: -0.046(R -0.190, F 0.097)] [G loss: -0.091]\n",
      "Epoch 4459 -- [D loss: -0.040(R -0.185, F 0.106)] [G loss: -0.108]\n",
      "Epoch 4460 -- [D loss: -0.038(R -0.171, F 0.094)] [G loss: -0.143]\n",
      "Epoch 4461 -- [D loss: 0.019(R -0.136, F 0.174)] [G loss: -0.152]\n",
      "Epoch 4462 -- [D loss: 0.023(R -0.126, F 0.172)] [G loss: -0.153]\n",
      "Epoch 4463 -- [D loss: 0.024(R -0.131, F 0.179)] [G loss: -0.148]\n",
      "Epoch 4464 -- [D loss: 0.034(R -0.103, F 0.172)] [G loss: -0.138]\n",
      "Epoch 4465 -- [D loss: 0.010(R -0.112, F 0.132)] [G loss: -0.125]\n",
      "Epoch 4466 -- [D loss: 0.005(R -0.107, F 0.116)] [G loss: -0.105]\n",
      "Epoch 4467 -- [D loss: -0.002(R -0.115, F 0.111)] [G loss: -0.090]\n",
      "Epoch 4468 -- [D loss: -0.011(R -0.114, F 0.093)] [G loss: -0.077]\n",
      "Epoch 4469 -- [D loss: -0.015(R -0.115, F 0.085)] [G loss: -0.068]\n",
      "Epoch 4470 -- [D loss: -0.030(R -0.126, F 0.065)] [G loss: -0.070]\n",
      "Epoch 4471 -- [D loss: -0.034(R -0.127, F 0.059)] [G loss: -0.081]\n",
      "Epoch 4472 -- [D loss: -0.042(R -0.153, F 0.069)] [G loss: -0.103]\n",
      "Epoch 4473 -- [D loss: -0.024(R -0.143, F 0.096)] [G loss: -0.123]\n",
      "Epoch 4474 -- [D loss: -0.017(R -0.139, F 0.104)] [G loss: -0.137]\n",
      "Epoch 4475 -- [D loss: -0.019(R -0.145, F 0.107)] [G loss: -0.143]\n",
      "Epoch 4476 -- [D loss: -0.004(R -0.133, F 0.125)] [G loss: -0.152]\n",
      "Epoch 4477 -- [D loss: 0.016(R -0.116, F 0.149)] [G loss: -0.137]\n",
      "Epoch 4478 -- [D loss: 0.016(R -0.086, F 0.117)] [G loss: -0.102]\n",
      "Epoch 4479 -- [D loss: 0.003(R -0.085, F 0.090)] [G loss: -0.066]\n",
      "Epoch 4480 -- [D loss: -0.002(R -0.071, F 0.067)] [G loss: -0.038]\n",
      "Epoch 4481 -- [D loss: -0.018(R -0.060, F 0.025)] [G loss: -0.019]\n",
      "Epoch 4482 -- [D loss: -0.026(R -0.059, F 0.007)] [G loss: -0.006]\n",
      "Epoch 4483 -- [D loss: -0.030(R -0.046, F -0.013)] [G loss: -0.003]\n",
      "Epoch 4484 -- [D loss: -0.033(R -0.039, F -0.027)] [G loss: -0.017]\n",
      "Epoch 4485 -- [D loss: -0.030(R -0.040, F -0.020)] [G loss: -0.029]\n",
      "Epoch 4486 -- [D loss: -0.021(R -0.046, F 0.004)] [G loss: -0.039]\n",
      "Epoch 4487 -- [D loss: -0.018(R -0.037, F 0.002)] [G loss: -0.042]\n",
      "Epoch 4488 -- [D loss: -0.020(R -0.046, F 0.006)] [G loss: -0.046]\n",
      "Epoch 4489 -- [D loss: -0.012(R -0.061, F 0.038)] [G loss: -0.052]\n",
      "Epoch 4490 -- [D loss: -0.001(R -0.040, F 0.037)] [G loss: -0.058]\n",
      "Epoch 4491 -- [D loss: 0.002(R -0.053, F 0.058)] [G loss: -0.049]\n",
      "Epoch 4492 -- [D loss: 0.013(R -0.045, F 0.072)] [G loss: -0.048]\n",
      "Epoch 4493 -- [D loss: 0.016(R -0.023, F 0.056)] [G loss: -0.042]\n",
      "Epoch 4494 -- [D loss: 0.011(R -0.035, F 0.058)] [G loss: -0.034]\n",
      "Epoch 4495 -- [D loss: -0.003(R -0.049, F 0.042)] [G loss: -0.033]\n",
      "Epoch 4496 -- [D loss: -0.006(R -0.059, F 0.046)] [G loss: -0.040]\n",
      "Epoch 4497 -- [D loss: -0.017(R -0.081, F 0.046)] [G loss: -0.047]\n",
      "Epoch 4498 -- [D loss: -0.018(R -0.111, F 0.075)] [G loss: -0.060]\n",
      "Epoch 4499 -- [D loss: -0.027(R -0.133, F 0.080)] [G loss: -0.088]\n",
      "Epoch 4500 -- [D loss: -0.014(R -0.133, F 0.105)] [G loss: -0.109]\n",
      "INFO:tensorflow:Assets written to: ram://5667ef47-e9b2-4e24-9754-f61ac38f545d/assets\n",
      "INFO:tensorflow:Assets written to: ram://fa242bea-5b3d-4d31-8303-4638397b7993/assets\n",
      "INFO:tensorflow:Assets written to: ram://b627e326-8739-4022-9321-e2ff5fdb8ece/assets\n",
      "Epoch 4501 -- [D loss: -0.004(R -0.141, F 0.133)] [G loss: -0.126]\n",
      "Epoch 4502 -- [D loss: 0.021(R -0.128, F 0.170)] [G loss: -0.135]\n",
      "Epoch 4503 -- [D loss: 0.027(R -0.108, F 0.161)] [G loss: -0.137]\n",
      "Epoch 4504 -- [D loss: 0.022(R -0.114, F 0.158)] [G loss: -0.124]\n",
      "Epoch 4505 -- [D loss: 0.017(R -0.103, F 0.137)] [G loss: -0.113]\n",
      "Epoch 4506 -- [D loss: 0.011(R -0.105, F 0.128)] [G loss: -0.097]\n",
      "Epoch 4507 -- [D loss: 0.001(R -0.096, F 0.099)] [G loss: -0.082]\n",
      "Epoch 4508 -- [D loss: -0.005(R -0.096, F 0.086)] [G loss: -0.061]\n",
      "Epoch 4509 -- [D loss: -0.015(R -0.095, F 0.065)] [G loss: -0.047]\n",
      "Epoch 4510 -- [D loss: -0.019(R -0.085, F 0.047)] [G loss: -0.039]\n",
      "Epoch 4511 -- [D loss: -0.015(R -0.080, F 0.049)] [G loss: -0.036]\n",
      "Epoch 4512 -- [D loss: -0.011(R -0.083, F 0.062)] [G loss: -0.032]\n",
      "Epoch 4513 -- [D loss: -0.009(R -0.073, F 0.054)] [G loss: -0.031]\n",
      "Epoch 4514 -- [D loss: -0.001(R -0.059, F 0.058)] [G loss: -0.036]\n",
      "Epoch 4515 -- [D loss: 0.003(R -0.056, F 0.061)] [G loss: -0.043]\n",
      "Epoch 4516 -- [D loss: 0.006(R -0.050, F 0.062)] [G loss: -0.047]\n",
      "Epoch 4517 -- [D loss: 0.004(R -0.057, F 0.066)] [G loss: -0.045]\n",
      "Epoch 4518 -- [D loss: 0.007(R -0.044, F 0.058)] [G loss: -0.050]\n",
      "Epoch 4519 -- [D loss: 0.008(R -0.044, F 0.060)] [G loss: -0.052]\n",
      "Epoch 4520 -- [D loss: 0.001(R -0.054, F 0.056)] [G loss: -0.053]\n",
      "Epoch 4521 -- [D loss: 0.005(R -0.053, F 0.062)] [G loss: -0.056]\n",
      "Epoch 4522 -- [D loss: -0.001(R -0.058, F 0.056)] [G loss: -0.057]\n",
      "Epoch 4523 -- [D loss: -0.003(R -0.064, F 0.058)] [G loss: -0.055]\n",
      "Epoch 4524 -- [D loss: -0.009(R -0.067, F 0.050)] [G loss: -0.053]\n",
      "Epoch 4525 -- [D loss: -0.005(R -0.069, F 0.059)] [G loss: -0.051]\n",
      "Epoch 4526 -- [D loss: -0.005(R -0.072, F 0.062)] [G loss: -0.049]\n",
      "Epoch 4527 -- [D loss: -0.010(R -0.076, F 0.056)] [G loss: -0.046]\n",
      "Epoch 4528 -- [D loss: -0.008(R -0.063, F 0.046)] [G loss: -0.044]\n",
      "Epoch 4529 -- [D loss: -0.005(R -0.060, F 0.049)] [G loss: -0.039]\n",
      "Epoch 4530 -- [D loss: -0.007(R -0.061, F 0.046)] [G loss: -0.050]\n",
      "Epoch 4531 -- [D loss: -0.005(R -0.064, F 0.055)] [G loss: -0.057]\n",
      "Epoch 4532 -- [D loss: -0.005(R -0.066, F 0.056)] [G loss: -0.071]\n",
      "Epoch 4533 -- [D loss: -0.001(R -0.069, F 0.067)] [G loss: -0.075]\n",
      "Epoch 4534 -- [D loss: 0.004(R -0.067, F 0.074)] [G loss: -0.076]\n",
      "Epoch 4535 -- [D loss: 0.003(R -0.066, F 0.072)] [G loss: -0.076]\n",
      "Epoch 4536 -- [D loss: -0.000(R -0.067, F 0.066)] [G loss: -0.070]\n",
      "Epoch 4537 -- [D loss: 0.005(R -0.059, F 0.069)] [G loss: -0.063]\n",
      "Epoch 4538 -- [D loss: 0.003(R -0.062, F 0.067)] [G loss: -0.061]\n",
      "Epoch 4539 -- [D loss: 0.003(R -0.066, F 0.073)] [G loss: -0.062]\n",
      "Epoch 4540 -- [D loss: 0.002(R -0.069, F 0.074)] [G loss: -0.062]\n",
      "Epoch 4541 -- [D loss: -0.005(R -0.073, F 0.062)] [G loss: -0.054]\n",
      "Epoch 4542 -- [D loss: -0.007(R -0.070, F 0.056)] [G loss: -0.049]\n",
      "Epoch 4543 -- [D loss: -0.007(R -0.071, F 0.056)] [G loss: -0.047]\n",
      "Epoch 4544 -- [D loss: -0.008(R -0.064, F 0.048)] [G loss: -0.055]\n",
      "Epoch 4545 -- [D loss: -0.007(R -0.060, F 0.046)] [G loss: -0.053]\n",
      "Epoch 4546 -- [D loss: -0.010(R -0.067, F 0.047)] [G loss: -0.051]\n",
      "Epoch 4547 -- [D loss: -0.006(R -0.052, F 0.040)] [G loss: -0.045]\n",
      "Epoch 4548 -- [D loss: -0.004(R -0.051, F 0.042)] [G loss: -0.040]\n",
      "Epoch 4549 -- [D loss: -0.003(R -0.055, F 0.049)] [G loss: -0.038]\n",
      "Epoch 4550 -- [D loss: 0.000(R -0.053, F 0.054)] [G loss: -0.040]\n",
      "Epoch 4551 -- [D loss: -0.007(R -0.063, F 0.049)] [G loss: -0.043]\n",
      "Epoch 4552 -- [D loss: -0.011(R -0.070, F 0.048)] [G loss: -0.048]\n",
      "Epoch 4553 -- [D loss: -0.003(R -0.070, F 0.063)] [G loss: -0.071]\n",
      "Epoch 4554 -- [D loss: 0.001(R -0.073, F 0.074)] [G loss: -0.082]\n",
      "Epoch 4555 -- [D loss: 0.006(R -0.059, F 0.071)] [G loss: -0.090]\n",
      "Epoch 4556 -- [D loss: 0.011(R -0.058, F 0.080)] [G loss: -0.074]\n",
      "Epoch 4557 -- [D loss: 0.003(R -0.059, F 0.064)] [G loss: -0.060]\n",
      "Epoch 4558 -- [D loss: -0.001(R -0.053, F 0.052)] [G loss: -0.042]\n",
      "Epoch 4559 -- [D loss: -0.001(R -0.042, F 0.041)] [G loss: -0.030]\n",
      "Epoch 4560 -- [D loss: -0.007(R -0.039, F 0.026)] [G loss: -0.035]\n",
      "Epoch 4561 -- [D loss: -0.007(R -0.041, F 0.026)] [G loss: -0.039]\n",
      "Epoch 4562 -- [D loss: -0.010(R -0.045, F 0.024)] [G loss: -0.049]\n",
      "Epoch 4563 -- [D loss: -0.010(R -0.048, F 0.029)] [G loss: -0.057]\n",
      "Epoch 4564 -- [D loss: -0.015(R -0.059, F 0.029)] [G loss: -0.066]\n",
      "Epoch 4565 -- [D loss: -0.019(R -0.067, F 0.030)] [G loss: -0.067]\n",
      "Epoch 4566 -- [D loss: -0.014(R -0.067, F 0.038)] [G loss: -0.062]\n",
      "Epoch 4567 -- [D loss: -0.022(R -0.087, F 0.042)] [G loss: -0.051]\n",
      "Epoch 4568 -- [D loss: -0.014(R -0.082, F 0.054)] [G loss: -0.057]\n",
      "Epoch 4569 -- [D loss: -0.006(R -0.082, F 0.069)] [G loss: -0.051]\n",
      "Epoch 4570 -- [D loss: -0.005(R -0.085, F 0.074)] [G loss: -0.063]\n",
      "Epoch 4571 -- [D loss: -0.006(R -0.092, F 0.081)] [G loss: -0.079]\n",
      "Epoch 4572 -- [D loss: -0.016(R -0.092, F 0.061)] [G loss: -0.090]\n",
      "Epoch 4573 -- [D loss: -0.000(R -0.079, F 0.078)] [G loss: -0.100]\n",
      "Epoch 4574 -- [D loss: -0.014(R -0.087, F 0.059)] [G loss: -0.102]\n",
      "Epoch 4575 -- [D loss: -0.007(R -0.084, F 0.070)] [G loss: -0.099]\n",
      "Epoch 4576 -- [D loss: -0.026(R -0.099, F 0.047)] [G loss: -0.090]\n",
      "Epoch 4577 -- [D loss: -0.020(R -0.080, F 0.040)] [G loss: -0.080]\n",
      "Epoch 4578 -- [D loss: -0.018(R -0.091, F 0.055)] [G loss: -0.064]\n",
      "Epoch 4579 -- [D loss: -0.024(R -0.089, F 0.041)] [G loss: -0.055]\n",
      "Epoch 4580 -- [D loss: -0.011(R -0.091, F 0.069)] [G loss: -0.064]\n",
      "Epoch 4581 -- [D loss: 0.000(R -0.078, F 0.079)] [G loss: -0.073]\n",
      "Epoch 4582 -- [D loss: 0.004(R -0.086, F 0.094)] [G loss: -0.082]\n",
      "Epoch 4583 -- [D loss: -0.002(R -0.094, F 0.090)] [G loss: -0.089]\n",
      "Epoch 4584 -- [D loss: -0.002(R -0.101, F 0.097)] [G loss: -0.092]\n",
      "Epoch 4585 -- [D loss: -0.003(R -0.108, F 0.102)] [G loss: -0.093]\n",
      "Epoch 4586 -- [D loss: -0.004(R -0.109, F 0.101)] [G loss: -0.099]\n",
      "Epoch 4587 -- [D loss: -0.003(R -0.120, F 0.114)] [G loss: -0.104]\n",
      "Epoch 4588 -- [D loss: -0.002(R -0.114, F 0.110)] [G loss: -0.107]\n",
      "Epoch 4589 -- [D loss: -0.000(R -0.114, F 0.114)] [G loss: -0.104]\n",
      "Epoch 4590 -- [D loss: 0.001(R -0.106, F 0.108)] [G loss: -0.097]\n",
      "Epoch 4591 -- [D loss: -0.003(R -0.105, F 0.100)] [G loss: -0.090]\n",
      "Epoch 4592 -- [D loss: -0.003(R -0.094, F 0.088)] [G loss: -0.083]\n",
      "Epoch 4593 -- [D loss: -0.010(R -0.100, F 0.079)] [G loss: -0.079]\n",
      "Epoch 4594 -- [D loss: -0.009(R -0.095, F 0.077)] [G loss: -0.074]\n",
      "Epoch 4595 -- [D loss: -0.011(R -0.088, F 0.067)] [G loss: -0.080]\n",
      "Epoch 4596 -- [D loss: -0.022(R -0.108, F 0.064)] [G loss: -0.088]\n",
      "Epoch 4597 -- [D loss: -0.012(R -0.094, F 0.071)] [G loss: -0.098]\n",
      "Epoch 4598 -- [D loss: -0.018(R -0.097, F 0.062)] [G loss: -0.105]\n",
      "Epoch 4599 -- [D loss: -0.015(R -0.117, F 0.088)] [G loss: -0.113]\n",
      "Epoch 4600 -- [D loss: -0.004(R -0.103, F 0.095)] [G loss: -0.118]\n",
      "INFO:tensorflow:Assets written to: ram://49b2329e-5b19-40fc-b621-56fca6039bb6/assets\n",
      "INFO:tensorflow:Assets written to: ram://3f0b26a4-ea07-467e-908d-26e06f586be3/assets\n",
      "INFO:tensorflow:Assets written to: ram://cc6fbbf8-22b8-4c53-8890-a8538054c529/assets\n",
      "Epoch 4601 -- [D loss: 0.002(R -0.108, F 0.113)] [G loss: -0.109]\n",
      "Epoch 4602 -- [D loss: -0.001(R -0.114, F 0.112)] [G loss: -0.105]\n",
      "Epoch 4603 -- [D loss: -0.003(R -0.115, F 0.108)] [G loss: -0.106]\n",
      "Epoch 4604 -- [D loss: 0.002(R -0.118, F 0.122)] [G loss: -0.113]\n",
      "Epoch 4605 -- [D loss: -0.000(R -0.122, F 0.122)] [G loss: -0.115]\n",
      "Epoch 4606 -- [D loss: -0.005(R -0.134, F 0.123)] [G loss: -0.129]\n",
      "Epoch 4607 -- [D loss: 0.001(R -0.137, F 0.139)] [G loss: -0.150]\n",
      "Epoch 4608 -- [D loss: -0.008(R -0.158, F 0.141)] [G loss: -0.180]\n",
      "Epoch 4609 -- [D loss: -0.012(R -0.175, F 0.152)] [G loss: -0.199]\n",
      "Epoch 4610 -- [D loss: 0.011(R -0.167, F 0.189)] [G loss: -0.198]\n",
      "Epoch 4611 -- [D loss: -0.004(R -0.175, F 0.168)] [G loss: -0.160]\n",
      "Epoch 4612 -- [D loss: -0.007(R -0.146, F 0.132)] [G loss: -0.128]\n",
      "Epoch 4613 -- [D loss: 0.001(R -0.126, F 0.127)] [G loss: -0.097]\n",
      "Epoch 4614 -- [D loss: -0.002(R -0.104, F 0.100)] [G loss: -0.088]\n",
      "Epoch 4615 -- [D loss: -0.002(R -0.100, F 0.096)] [G loss: -0.073]\n",
      "Epoch 4616 -- [D loss: -0.008(R -0.089, F 0.073)] [G loss: -0.053]\n",
      "Epoch 4617 -- [D loss: -0.016(R -0.088, F 0.056)] [G loss: -0.042]\n",
      "Epoch 4618 -- [D loss: -0.018(R -0.077, F 0.040)] [G loss: -0.026]\n",
      "Epoch 4619 -- [D loss: -0.021(R -0.087, F 0.044)] [G loss: -0.023]\n",
      "Epoch 4620 -- [D loss: -0.020(R -0.085, F 0.045)] [G loss: -0.028]\n",
      "Epoch 4621 -- [D loss: -0.019(R -0.080, F 0.041)] [G loss: -0.044]\n",
      "Epoch 4622 -- [D loss: -0.014(R -0.087, F 0.058)] [G loss: -0.066]\n",
      "Epoch 4623 -- [D loss: -0.017(R -0.104, F 0.070)] [G loss: -0.086]\n",
      "Epoch 4624 -- [D loss: -0.012(R -0.116, F 0.093)] [G loss: -0.097]\n",
      "Epoch 4625 -- [D loss: -0.015(R -0.113, F 0.082)] [G loss: -0.113]\n",
      "Epoch 4626 -- [D loss: -0.009(R -0.108, F 0.089)] [G loss: -0.113]\n",
      "Epoch 4627 -- [D loss: -0.018(R -0.130, F 0.094)] [G loss: -0.116]\n",
      "Epoch 4628 -- [D loss: -0.020(R -0.124, F 0.085)] [G loss: -0.108]\n",
      "Epoch 4629 -- [D loss: 0.000(R -0.108, F 0.109)] [G loss: -0.098]\n",
      "Epoch 4630 -- [D loss: 0.015(R -0.081, F 0.112)] [G loss: -0.079]\n",
      "Epoch 4631 -- [D loss: -0.008(R -0.086, F 0.070)] [G loss: -0.062]\n",
      "Epoch 4632 -- [D loss: -0.001(R -0.067, F 0.065)] [G loss: -0.055]\n",
      "Epoch 4633 -- [D loss: -0.005(R -0.065, F 0.056)] [G loss: -0.057]\n",
      "Epoch 4634 -- [D loss: 0.002(R -0.057, F 0.062)] [G loss: -0.069]\n",
      "Epoch 4635 -- [D loss: 0.005(R -0.056, F 0.067)] [G loss: -0.071]\n",
      "Epoch 4636 -- [D loss: 0.002(R -0.067, F 0.071)] [G loss: -0.077]\n",
      "Epoch 4637 -- [D loss: 0.002(R -0.071, F 0.074)] [G loss: -0.079]\n",
      "Epoch 4638 -- [D loss: -0.000(R -0.077, F 0.076)] [G loss: -0.078]\n",
      "Epoch 4639 -- [D loss: -0.012(R -0.094, F 0.070)] [G loss: -0.088]\n",
      "Epoch 4640 -- [D loss: 0.001(R -0.099, F 0.102)] [G loss: -0.084]\n",
      "Epoch 4641 -- [D loss: -0.016(R -0.119, F 0.087)] [G loss: -0.097]\n",
      "Epoch 4642 -- [D loss: -0.008(R -0.118, F 0.102)] [G loss: -0.098]\n",
      "Epoch 4643 -- [D loss: -0.010(R -0.110, F 0.090)] [G loss: -0.104]\n",
      "Epoch 4644 -- [D loss: -0.007(R -0.116, F 0.102)] [G loss: -0.118]\n",
      "Epoch 4645 -- [D loss: -0.005(R -0.121, F 0.111)] [G loss: -0.119]\n",
      "Epoch 4646 -- [D loss: 0.005(R -0.113, F 0.124)] [G loss: -0.122]\n",
      "Epoch 4647 -- [D loss: 0.013(R -0.101, F 0.127)] [G loss: -0.123]\n",
      "Epoch 4648 -- [D loss: -0.005(R -0.125, F 0.114)] [G loss: -0.125]\n",
      "Epoch 4649 -- [D loss: -0.009(R -0.117, F 0.099)] [G loss: -0.117]\n",
      "Epoch 4650 -- [D loss: -0.008(R -0.115, F 0.100)] [G loss: -0.104]\n",
      "Epoch 4651 -- [D loss: -0.005(R -0.104, F 0.094)] [G loss: -0.087]\n",
      "Epoch 4652 -- [D loss: 0.000(R -0.086, F 0.087)] [G loss: -0.076]\n",
      "Epoch 4653 -- [D loss: 0.007(R -0.075, F 0.089)] [G loss: -0.062]\n",
      "Epoch 4654 -- [D loss: -0.001(R -0.063, F 0.061)] [G loss: -0.048]\n",
      "Epoch 4655 -- [D loss: 0.001(R -0.052, F 0.054)] [G loss: -0.039]\n",
      "Epoch 4656 -- [D loss: -0.001(R -0.057, F 0.055)] [G loss: -0.041]\n",
      "Epoch 4657 -- [D loss: 0.002(R -0.051, F 0.055)] [G loss: -0.038]\n",
      "Epoch 4658 -- [D loss: -0.003(R -0.049, F 0.043)] [G loss: -0.029]\n",
      "Epoch 4659 -- [D loss: -0.008(R -0.055, F 0.039)] [G loss: -0.020]\n",
      "Epoch 4660 -- [D loss: -0.006(R -0.049, F 0.038)] [G loss: -0.027]\n",
      "Epoch 4661 -- [D loss: -0.008(R -0.054, F 0.038)] [G loss: -0.040]\n",
      "Epoch 4662 -- [D loss: -0.008(R -0.057, F 0.041)] [G loss: -0.041]\n",
      "Epoch 4663 -- [D loss: 0.009(R -0.040, F 0.058)] [G loss: -0.044]\n",
      "Epoch 4664 -- [D loss: 0.004(R -0.036, F 0.044)] [G loss: -0.032]\n",
      "Epoch 4665 -- [D loss: 0.005(R -0.030, F 0.039)] [G loss: -0.029]\n",
      "Epoch 4666 -- [D loss: -0.006(R -0.034, F 0.022)] [G loss: -0.011]\n",
      "Epoch 4667 -- [D loss: -0.012(R -0.032, F 0.008)] [G loss: 0.004]\n",
      "Epoch 4668 -- [D loss: -0.020(R -0.032, F -0.009)] [G loss: 0.015]\n",
      "Epoch 4669 -- [D loss: -0.023(R -0.020, F -0.026)] [G loss: 0.018]\n",
      "Epoch 4670 -- [D loss: -0.034(R -0.026, F -0.043)] [G loss: 0.015]\n",
      "Epoch 4671 -- [D loss: -0.029(R -0.022, F -0.036)] [G loss: -0.008]\n",
      "Epoch 4672 -- [D loss: -0.037(R -0.032, F -0.042)] [G loss: -0.015]\n",
      "Epoch 4673 -- [D loss: -0.040(R -0.031, F -0.050)] [G loss: -0.030]\n",
      "Epoch 4674 -- [D loss: -0.037(R -0.055, F -0.018)] [G loss: -0.057]\n",
      "Epoch 4675 -- [D loss: -0.019(R -0.055, F 0.017)] [G loss: -0.094]\n",
      "Epoch 4676 -- [D loss: -0.007(R -0.074, F 0.059)] [G loss: -0.109]\n",
      "Epoch 4677 -- [D loss: 0.006(R -0.088, F 0.100)] [G loss: -0.111]\n",
      "Epoch 4678 -- [D loss: 0.020(R -0.083, F 0.124)] [G loss: -0.110]\n",
      "Epoch 4679 -- [D loss: 0.017(R -0.087, F 0.122)] [G loss: -0.111]\n",
      "Epoch 4680 -- [D loss: 0.010(R -0.091, F 0.111)] [G loss: -0.104]\n",
      "Epoch 4681 -- [D loss: 0.006(R -0.099, F 0.110)] [G loss: -0.102]\n",
      "Epoch 4682 -- [D loss: -0.002(R -0.110, F 0.106)] [G loss: -0.098]\n",
      "Epoch 4683 -- [D loss: -0.004(R -0.110, F 0.103)] [G loss: -0.093]\n",
      "Epoch 4684 -- [D loss: -0.008(R -0.118, F 0.102)] [G loss: -0.091]\n",
      "Epoch 4685 -- [D loss: -0.011(R -0.122, F 0.100)] [G loss: -0.089]\n",
      "Epoch 4686 -- [D loss: -0.014(R -0.122, F 0.094)] [G loss: -0.088]\n",
      "Epoch 4687 -- [D loss: -0.017(R -0.136, F 0.102)] [G loss: -0.096]\n",
      "Epoch 4688 -- [D loss: -0.011(R -0.130, F 0.109)] [G loss: -0.101]\n",
      "Epoch 4689 -- [D loss: 0.001(R -0.126, F 0.128)] [G loss: -0.109]\n",
      "Epoch 4690 -- [D loss: 0.003(R -0.121, F 0.128)] [G loss: -0.115]\n",
      "Epoch 4691 -- [D loss: 0.009(R -0.120, F 0.138)] [G loss: -0.119]\n",
      "Epoch 4692 -- [D loss: 0.005(R -0.121, F 0.131)] [G loss: -0.127]\n",
      "Epoch 4693 -- [D loss: 0.006(R -0.116, F 0.129)] [G loss: -0.134]\n",
      "Epoch 4694 -- [D loss: 0.004(R -0.122, F 0.130)] [G loss: -0.137]\n",
      "Epoch 4695 -- [D loss: 0.004(R -0.123, F 0.132)] [G loss: -0.143]\n",
      "Epoch 4696 -- [D loss: -0.003(R -0.124, F 0.119)] [G loss: -0.146]\n",
      "Epoch 4697 -- [D loss: 0.001(R -0.132, F 0.134)] [G loss: -0.148]\n",
      "Epoch 4698 -- [D loss: -0.000(R -0.133, F 0.133)] [G loss: -0.147]\n",
      "Epoch 4699 -- [D loss: 0.002(R -0.125, F 0.128)] [G loss: -0.141]\n",
      "Epoch 4700 -- [D loss: 0.003(R -0.120, F 0.127)] [G loss: -0.129]\n",
      "INFO:tensorflow:Assets written to: ram://4e976fed-6b25-44ce-9718-762870fc6cb8/assets\n",
      "INFO:tensorflow:Assets written to: ram://efa30806-a2d4-43ef-9024-d2948ee918e3/assets\n",
      "INFO:tensorflow:Assets written to: ram://50634eb0-d30c-4895-a178-b3716189be33/assets\n",
      "Epoch 4701 -- [D loss: 0.010(R -0.101, F 0.121)] [G loss: -0.121]\n",
      "Epoch 4702 -- [D loss: 0.003(R -0.109, F 0.115)] [G loss: -0.105]\n",
      "Epoch 4703 -- [D loss: -0.000(R -0.099, F 0.099)] [G loss: -0.088]\n",
      "Epoch 4704 -- [D loss: 0.000(R -0.085, F 0.085)] [G loss: -0.074]\n",
      "Epoch 4705 -- [D loss: -0.006(R -0.072, F 0.061)] [G loss: -0.048]\n",
      "Epoch 4706 -- [D loss: -0.012(R -0.069, F 0.045)] [G loss: -0.032]\n",
      "Epoch 4707 -- [D loss: -0.019(R -0.058, F 0.020)] [G loss: -0.031]\n",
      "Epoch 4708 -- [D loss: -0.023(R -0.050, F 0.004)] [G loss: -0.021]\n",
      "Epoch 4709 -- [D loss: -0.020(R -0.043, F 0.004)] [G loss: -0.034]\n",
      "Epoch 4710 -- [D loss: -0.019(R -0.039, F 0.002)] [G loss: -0.031]\n",
      "Epoch 4711 -- [D loss: -0.023(R -0.033, F -0.014)] [G loss: -0.037]\n",
      "Epoch 4712 -- [D loss: -0.029(R -0.034, F -0.024)] [G loss: -0.035]\n",
      "Epoch 4713 -- [D loss: -0.009(R -0.007, F -0.011)] [G loss: -0.042]\n",
      "Epoch 4714 -- [D loss: -0.005(R -0.026, F 0.016)] [G loss: -0.036]\n",
      "Epoch 4715 -- [D loss: -0.000(R -0.019, F 0.019)] [G loss: -0.032]\n",
      "Epoch 4716 -- [D loss: -0.000(R -0.020, F 0.020)] [G loss: -0.032]\n",
      "Epoch 4717 -- [D loss: 0.001(R -0.020, F 0.021)] [G loss: -0.027]\n",
      "Epoch 4718 -- [D loss: -0.002(R -0.029, F 0.026)] [G loss: -0.025]\n",
      "Epoch 4719 -- [D loss: 0.010(R -0.021, F 0.042)] [G loss: -0.038]\n",
      "Epoch 4720 -- [D loss: -0.001(R -0.036, F 0.035)] [G loss: -0.030]\n",
      "Epoch 4721 -- [D loss: -0.005(R -0.036, F 0.026)] [G loss: -0.034]\n",
      "Epoch 4722 -- [D loss: -0.014(R -0.060, F 0.031)] [G loss: -0.037]\n",
      "Epoch 4723 -- [D loss: -0.020(R -0.068, F 0.028)] [G loss: -0.036]\n",
      "Epoch 4724 -- [D loss: -0.015(R -0.070, F 0.040)] [G loss: -0.040]\n",
      "Epoch 4725 -- [D loss: -0.017(R -0.081, F 0.047)] [G loss: -0.042]\n",
      "Epoch 4726 -- [D loss: -0.007(R -0.081, F 0.067)] [G loss: -0.045]\n",
      "Epoch 4727 -- [D loss: -0.001(R -0.091, F 0.089)] [G loss: -0.059]\n",
      "Epoch 4728 -- [D loss: 0.007(R -0.093, F 0.107)] [G loss: -0.072]\n",
      "Epoch 4729 -- [D loss: 0.012(R -0.085, F 0.109)] [G loss: -0.078]\n",
      "Epoch 4730 -- [D loss: 0.003(R -0.097, F 0.103)] [G loss: -0.082]\n",
      "Epoch 4731 -- [D loss: 0.003(R -0.093, F 0.099)] [G loss: -0.083]\n",
      "Epoch 4732 -- [D loss: 0.002(R -0.099, F 0.104)] [G loss: -0.086]\n",
      "Epoch 4733 -- [D loss: -0.014(R -0.120, F 0.093)] [G loss: -0.091]\n",
      "Epoch 4734 -- [D loss: -0.010(R -0.113, F 0.094)] [G loss: -0.116]\n",
      "Epoch 4735 -- [D loss: -0.018(R -0.138, F 0.101)] [G loss: -0.138]\n",
      "Epoch 4736 -- [D loss: -0.020(R -0.154, F 0.114)] [G loss: -0.175]\n",
      "Epoch 4737 -- [D loss: -0.027(R -0.187, F 0.133)] [G loss: -0.207]\n",
      "Epoch 4738 -- [D loss: -0.006(R -0.188, F 0.176)] [G loss: -0.220]\n",
      "Epoch 4739 -- [D loss: 0.008(R -0.182, F 0.197)] [G loss: -0.211]\n",
      "Epoch 4740 -- [D loss: 0.008(R -0.150, F 0.166)] [G loss: -0.201]\n",
      "Epoch 4741 -- [D loss: 0.024(R -0.145, F 0.194)] [G loss: -0.175]\n",
      "Epoch 4742 -- [D loss: 0.019(R -0.132, F 0.170)] [G loss: -0.150]\n",
      "Epoch 4743 -- [D loss: 0.007(R -0.120, F 0.133)] [G loss: -0.122]\n",
      "Epoch 4744 -- [D loss: 0.003(R -0.100, F 0.107)] [G loss: -0.102]\n",
      "Epoch 4745 -- [D loss: -0.001(R -0.089, F 0.087)] [G loss: -0.081]\n",
      "Epoch 4746 -- [D loss: 0.001(R -0.084, F 0.086)] [G loss: -0.082]\n",
      "Epoch 4747 -- [D loss: -0.001(R -0.074, F 0.072)] [G loss: -0.066]\n",
      "Epoch 4748 -- [D loss: 0.004(R -0.055, F 0.062)] [G loss: -0.047]\n",
      "Epoch 4749 -- [D loss: -0.006(R -0.050, F 0.038)] [G loss: -0.020]\n",
      "Epoch 4750 -- [D loss: -0.016(R -0.043, F 0.011)] [G loss: 0.004]\n",
      "Epoch 4751 -- [D loss: -0.026(R -0.047, F -0.005)] [G loss: 0.023]\n",
      "Epoch 4752 -- [D loss: -0.032(R -0.034, F -0.030)] [G loss: 0.011]\n",
      "Epoch 4753 -- [D loss: -0.032(R -0.028, F -0.037)] [G loss: 0.001]\n",
      "Epoch 4754 -- [D loss: -0.060(R -0.036, F -0.083)] [G loss: -0.003]\n",
      "Epoch 4755 -- [D loss: -0.057(R -0.047, F -0.066)] [G loss: -0.010]\n",
      "Epoch 4756 -- [D loss: -0.038(R -0.036, F -0.039)] [G loss: 0.007]\n",
      "Epoch 4757 -- [D loss: -0.030(R -0.049, F -0.010)] [G loss: 0.002]\n",
      "Epoch 4758 -- [D loss: -0.003(R -0.043, F 0.037)] [G loss: -0.022]\n",
      "Epoch 4759 -- [D loss: -0.003(R -0.067, F 0.062)] [G loss: -0.033]\n",
      "Epoch 4760 -- [D loss: 0.006(R -0.066, F 0.078)] [G loss: -0.048]\n",
      "Epoch 4761 -- [D loss: -0.008(R -0.086, F 0.071)] [G loss: -0.050]\n",
      "Epoch 4762 -- [D loss: -0.015(R -0.082, F 0.053)] [G loss: -0.043]\n",
      "Epoch 4763 -- [D loss: -0.015(R -0.085, F 0.055)] [G loss: -0.039]\n",
      "Epoch 4764 -- [D loss: -0.020(R -0.099, F 0.060)] [G loss: -0.054]\n",
      "Epoch 4765 -- [D loss: -0.004(R -0.084, F 0.076)] [G loss: -0.064]\n",
      "Epoch 4766 -- [D loss: -0.005(R -0.092, F 0.082)] [G loss: -0.076]\n",
      "Epoch 4767 -- [D loss: 0.004(R -0.074, F 0.083)] [G loss: -0.082]\n",
      "Epoch 4768 -- [D loss: -0.003(R -0.081, F 0.075)] [G loss: -0.092]\n",
      "Epoch 4769 -- [D loss: 0.002(R -0.076, F 0.080)] [G loss: -0.092]\n",
      "Epoch 4770 -- [D loss: 0.006(R -0.096, F 0.109)] [G loss: -0.088]\n",
      "Epoch 4771 -- [D loss: 0.016(R -0.084, F 0.116)] [G loss: -0.097]\n",
      "Epoch 4772 -- [D loss: 0.005(R -0.098, F 0.108)] [G loss: -0.107]\n",
      "Epoch 4773 -- [D loss: 0.003(R -0.099, F 0.105)] [G loss: -0.102]\n",
      "Epoch 4774 -- [D loss: -0.003(R -0.100, F 0.095)] [G loss: -0.100]\n",
      "Epoch 4775 -- [D loss: -0.001(R -0.107, F 0.105)] [G loss: -0.094]\n",
      "Epoch 4776 -- [D loss: -0.006(R -0.108, F 0.097)] [G loss: -0.095]\n",
      "Epoch 4777 -- [D loss: -0.001(R -0.106, F 0.104)] [G loss: -0.086]\n",
      "Epoch 4778 -- [D loss: -0.006(R -0.107, F 0.094)] [G loss: -0.088]\n",
      "Epoch 4779 -- [D loss: -0.006(R -0.100, F 0.088)] [G loss: -0.091]\n",
      "Epoch 4780 -- [D loss: 0.001(R -0.098, F 0.101)] [G loss: -0.098]\n",
      "Epoch 4781 -- [D loss: 0.003(R -0.091, F 0.098)] [G loss: -0.101]\n",
      "Epoch 4782 -- [D loss: -0.003(R -0.105, F 0.100)] [G loss: -0.093]\n",
      "Epoch 4783 -- [D loss: -0.006(R -0.104, F 0.091)] [G loss: -0.089]\n",
      "Epoch 4784 -- [D loss: -0.015(R -0.108, F 0.079)] [G loss: -0.077]\n",
      "Epoch 4785 -- [D loss: -0.013(R -0.098, F 0.071)] [G loss: -0.085]\n",
      "Epoch 4786 -- [D loss: -0.010(R -0.091, F 0.070)] [G loss: -0.073]\n",
      "Epoch 4787 -- [D loss: -0.003(R -0.095, F 0.089)] [G loss: -0.082]\n",
      "Epoch 4788 -- [D loss: 0.002(R -0.090, F 0.094)] [G loss: -0.090]\n",
      "Epoch 4789 -- [D loss: -0.003(R -0.091, F 0.085)] [G loss: -0.091]\n",
      "Epoch 4790 -- [D loss: -0.000(R -0.085, F 0.085)] [G loss: -0.083]\n",
      "Epoch 4791 -- [D loss: -0.012(R -0.085, F 0.062)] [G loss: -0.068]\n",
      "Epoch 4792 -- [D loss: -0.016(R -0.077, F 0.044)] [G loss: -0.049]\n",
      "Epoch 4793 -- [D loss: -0.015(R -0.081, F 0.050)] [G loss: -0.031]\n",
      "Epoch 4794 -- [D loss: -0.013(R -0.073, F 0.047)] [G loss: -0.036]\n",
      "Epoch 4795 -- [D loss: -0.006(R -0.071, F 0.059)] [G loss: -0.046]\n",
      "Epoch 4796 -- [D loss: 0.010(R -0.051, F 0.070)] [G loss: -0.063]\n",
      "Epoch 4797 -- [D loss: 0.015(R -0.049, F 0.079)] [G loss: -0.074]\n",
      "Epoch 4798 -- [D loss: 0.009(R -0.057, F 0.075)] [G loss: -0.078]\n",
      "Epoch 4799 -- [D loss: -0.000(R -0.061, F 0.061)] [G loss: -0.056]\n",
      "Epoch 4800 -- [D loss: -0.008(R -0.062, F 0.045)] [G loss: -0.041]\n",
      "INFO:tensorflow:Assets written to: ram://048b4ce4-f54a-4bfb-aa51-47996ca29af2/assets\n",
      "INFO:tensorflow:Assets written to: ram://627a0d66-a8d3-4ace-978a-17dac34e50bf/assets\n",
      "INFO:tensorflow:Assets written to: ram://12ddcb67-3f94-4a81-acd6-1c70b5976b11/assets\n",
      "Epoch 4801 -- [D loss: -0.019(R -0.066, F 0.027)] [G loss: -0.027]\n",
      "Epoch 4802 -- [D loss: -0.015(R -0.061, F 0.030)] [G loss: -0.017]\n",
      "Epoch 4803 -- [D loss: -0.038(R -0.078, F 0.002)] [G loss: -0.024]\n",
      "Epoch 4804 -- [D loss: -0.035(R -0.076, F 0.005)] [G loss: -0.035]\n",
      "Epoch 4805 -- [D loss: -0.034(R -0.074, F 0.006)] [G loss: -0.055]\n",
      "Epoch 4806 -- [D loss: -0.031(R -0.082, F 0.019)] [G loss: -0.074]\n",
      "Epoch 4807 -- [D loss: -0.016(R -0.074, F 0.043)] [G loss: -0.069]\n",
      "Epoch 4808 -- [D loss: -0.007(R -0.067, F 0.054)] [G loss: -0.083]\n",
      "Epoch 4809 -- [D loss: -0.022(R -0.085, F 0.040)] [G loss: -0.071]\n",
      "Epoch 4810 -- [D loss: 0.005(R -0.067, F 0.077)] [G loss: -0.075]\n",
      "Epoch 4811 -- [D loss: 0.016(R -0.059, F 0.092)] [G loss: -0.070]\n",
      "Epoch 4812 -- [D loss: 0.008(R -0.059, F 0.075)] [G loss: -0.069]\n",
      "Epoch 4813 -- [D loss: 0.015(R -0.054, F 0.083)] [G loss: -0.061]\n",
      "Epoch 4814 -- [D loss: 0.011(R -0.047, F 0.069)] [G loss: -0.054]\n",
      "Epoch 4815 -- [D loss: 0.008(R -0.046, F 0.061)] [G loss: -0.050]\n",
      "Epoch 4816 -- [D loss: -0.001(R -0.054, F 0.052)] [G loss: -0.037]\n",
      "Epoch 4817 -- [D loss: -0.008(R -0.053, F 0.037)] [G loss: -0.031]\n",
      "Epoch 4818 -- [D loss: -0.023(R -0.074, F 0.028)] [G loss: -0.025]\n",
      "Epoch 4819 -- [D loss: -0.034(R -0.096, F 0.029)] [G loss: -0.044]\n",
      "Epoch 4820 -- [D loss: -0.037(R -0.108, F 0.035)] [G loss: -0.074]\n",
      "Epoch 4821 -- [D loss: -0.038(R -0.121, F 0.044)] [G loss: -0.126]\n",
      "Epoch 4822 -- [D loss: -0.031(R -0.129, F 0.066)] [G loss: -0.149]\n",
      "Epoch 4823 -- [D loss: -0.021(R -0.160, F 0.118)] [G loss: -0.189]\n",
      "Epoch 4824 -- [D loss: -0.009(R -0.161, F 0.144)] [G loss: -0.187]\n",
      "Epoch 4825 -- [D loss: 0.016(R -0.131, F 0.162)] [G loss: -0.187]\n",
      "Epoch 4826 -- [D loss: 0.010(R -0.140, F 0.160)] [G loss: -0.168]\n",
      "Epoch 4827 -- [D loss: 0.019(R -0.126, F 0.163)] [G loss: -0.147]\n",
      "Epoch 4828 -- [D loss: -0.001(R -0.105, F 0.102)] [G loss: -0.114]\n",
      "Epoch 4829 -- [D loss: 0.003(R -0.080, F 0.087)] [G loss: -0.068]\n",
      "Epoch 4830 -- [D loss: -0.009(R -0.070, F 0.053)] [G loss: -0.022]\n",
      "Epoch 4831 -- [D loss: -0.017(R -0.037, F 0.004)] [G loss: 0.004]\n",
      "Epoch 4832 -- [D loss: -0.012(R -0.006, F -0.019)] [G loss: 0.012]\n",
      "Epoch 4833 -- [D loss: -0.001(R 0.009, F -0.011)] [G loss: 0.028]\n",
      "Epoch 4834 -- [D loss: -0.016(R 0.003, F -0.036)] [G loss: 0.050]\n",
      "Epoch 4835 -- [D loss: -0.012(R 0.040, F -0.064)] [G loss: 0.072]\n",
      "Epoch 4836 -- [D loss: -0.009(R 0.049, F -0.067)] [G loss: 0.098]\n",
      "Epoch 4837 -- [D loss: 0.002(R 0.063, F -0.059)] [G loss: 0.104]\n",
      "Epoch 4838 -- [D loss: -0.015(R 0.072, F -0.103)] [G loss: 0.119]\n",
      "Epoch 4839 -- [D loss: -0.022(R 0.070, F -0.114)] [G loss: 0.120]\n",
      "Epoch 4840 -- [D loss: -0.010(R 0.099, F -0.118)] [G loss: 0.120]\n",
      "Epoch 4841 -- [D loss: 0.001(R 0.111, F -0.109)] [G loss: 0.104]\n",
      "Epoch 4842 -- [D loss: 0.002(R 0.099, F -0.096)] [G loss: 0.097]\n",
      "Epoch 4843 -- [D loss: -0.003(R 0.090, F -0.097)] [G loss: 0.091]\n",
      "Epoch 4844 -- [D loss: 0.009(R 0.102, F -0.085)] [G loss: 0.086]\n",
      "Epoch 4845 -- [D loss: 0.005(R 0.075, F -0.065)] [G loss: 0.067]\n",
      "Epoch 4846 -- [D loss: 0.009(R 0.062, F -0.043)] [G loss: 0.049]\n",
      "Epoch 4847 -- [D loss: 0.005(R 0.040, F -0.030)] [G loss: 0.028]\n",
      "Epoch 4848 -- [D loss: 0.006(R 0.032, F -0.020)] [G loss: 0.021]\n",
      "Epoch 4849 -- [D loss: 0.001(R 0.002, F 0.000)] [G loss: 0.005]\n",
      "Epoch 4850 -- [D loss: 0.001(R -0.006, F 0.008)] [G loss: -0.003]\n",
      "Epoch 4851 -- [D loss: -0.004(R -0.017, F 0.010)] [G loss: -0.007]\n",
      "Epoch 4852 -- [D loss: -0.012(R -0.039, F 0.015)] [G loss: -0.015]\n",
      "Epoch 4853 -- [D loss: -0.017(R -0.044, F 0.010)] [G loss: -0.015]\n",
      "Epoch 4854 -- [D loss: -0.014(R -0.044, F 0.016)] [G loss: -0.019]\n",
      "Epoch 4855 -- [D loss: -0.021(R -0.060, F 0.018)] [G loss: -0.015]\n",
      "Epoch 4856 -- [D loss: -0.004(R -0.036, F 0.027)] [G loss: -0.019]\n",
      "Epoch 4857 -- [D loss: -0.012(R -0.051, F 0.026)] [G loss: -0.009]\n",
      "Epoch 4858 -- [D loss: -0.011(R -0.045, F 0.024)] [G loss: -0.007]\n",
      "Epoch 4859 -- [D loss: -0.011(R -0.056, F 0.033)] [G loss: -0.009]\n",
      "Epoch 4860 -- [D loss: -0.011(R -0.058, F 0.037)] [G loss: -0.028]\n",
      "Epoch 4861 -- [D loss: -0.012(R -0.067, F 0.044)] [G loss: -0.046]\n",
      "Epoch 4862 -- [D loss: -0.008(R -0.078, F 0.062)] [G loss: -0.071]\n",
      "Epoch 4863 -- [D loss: -0.007(R -0.100, F 0.086)] [G loss: -0.102]\n",
      "Epoch 4864 -- [D loss: 0.006(R -0.096, F 0.109)] [G loss: -0.125]\n",
      "Epoch 4865 -- [D loss: -0.002(R -0.117, F 0.113)] [G loss: -0.136]\n",
      "Epoch 4866 -- [D loss: -0.004(R -0.133, F 0.125)] [G loss: -0.153]\n",
      "Epoch 4867 -- [D loss: -0.006(R -0.142, F 0.130)] [G loss: -0.171]\n",
      "Epoch 4868 -- [D loss: -0.005(R -0.154, F 0.144)] [G loss: -0.186]\n",
      "Epoch 4869 -- [D loss: -0.013(R -0.182, F 0.156)] [G loss: -0.200]\n",
      "Epoch 4870 -- [D loss: -0.007(R -0.189, F 0.175)] [G loss: -0.203]\n",
      "Epoch 4871 -- [D loss: -0.006(R -0.188, F 0.177)] [G loss: -0.191]\n",
      "Epoch 4872 -- [D loss: -0.013(R -0.197, F 0.171)] [G loss: -0.176]\n",
      "Epoch 4873 -- [D loss: -0.006(R -0.184, F 0.173)] [G loss: -0.153]\n",
      "Epoch 4874 -- [D loss: -0.019(R -0.183, F 0.145)] [G loss: -0.123]\n",
      "Epoch 4875 -- [D loss: -0.018(R -0.167, F 0.131)] [G loss: -0.110]\n",
      "Epoch 4876 -- [D loss: -0.015(R -0.141, F 0.110)] [G loss: -0.091]\n",
      "Epoch 4877 -- [D loss: -0.010(R -0.112, F 0.092)] [G loss: -0.075]\n",
      "Epoch 4878 -- [D loss: -0.011(R -0.066, F 0.045)] [G loss: -0.048]\n",
      "Epoch 4879 -- [D loss: -0.015(R -0.046, F 0.016)] [G loss: -0.037]\n",
      "Epoch 4880 -- [D loss: -0.017(R -0.029, F -0.005)] [G loss: -0.021]\n",
      "Epoch 4881 -- [D loss: -0.007(R 0.020, F -0.035)] [G loss: -0.021]\n",
      "Epoch 4882 -- [D loss: -0.012(R 0.025, F -0.049)] [G loss: -0.026]\n",
      "Epoch 4883 -- [D loss: 0.011(R 0.035, F -0.013)] [G loss: -0.026]\n",
      "Epoch 4884 -- [D loss: 0.005(R 0.016, F -0.006)] [G loss: -0.016]\n",
      "Epoch 4885 -- [D loss: 0.013(R 0.039, F -0.014)] [G loss: -0.004]\n",
      "Epoch 4886 -- [D loss: 0.012(R 0.016, F 0.007)] [G loss: 0.010]\n",
      "Epoch 4887 -- [D loss: -0.008(R -0.008, F -0.007)] [G loss: 0.022]\n",
      "Epoch 4888 -- [D loss: -0.020(R -0.046, F 0.005)] [G loss: 0.027]\n",
      "Epoch 4889 -- [D loss: -0.047(R -0.071, F -0.024)] [G loss: 0.022]\n",
      "Epoch 4890 -- [D loss: -0.064(R -0.114, F -0.013)] [G loss: -0.014]\n",
      "Epoch 4891 -- [D loss: -0.084(R -0.142, F -0.026)] [G loss: -0.054]\n",
      "Epoch 4892 -- [D loss: -0.102(R -0.190, F -0.015)] [G loss: -0.105]\n",
      "Epoch 4893 -- [D loss: -0.076(R -0.199, F 0.047)] [G loss: -0.146]\n",
      "Epoch 4894 -- [D loss: -0.043(R -0.256, F 0.171)] [G loss: -0.227]\n",
      "Epoch 4895 -- [D loss: -0.019(R -0.284, F 0.247)] [G loss: -0.296]\n",
      "Epoch 4896 -- [D loss: -0.003(R -0.278, F 0.272)] [G loss: -0.336]\n",
      "Epoch 4897 -- [D loss: 0.021(R -0.306, F 0.347)] [G loss: -0.351]\n",
      "Epoch 4898 -- [D loss: 0.017(R -0.291, F 0.324)] [G loss: -0.348]\n",
      "Epoch 4899 -- [D loss: 0.048(R -0.277, F 0.373)] [G loss: -0.315]\n",
      "Epoch 4900 -- [D loss: 0.044(R -0.251, F 0.339)] [G loss: -0.273]\n",
      "INFO:tensorflow:Assets written to: ram://ad8fce7b-8baf-47af-8860-97d673d0ad90/assets\n",
      "INFO:tensorflow:Assets written to: ram://106f30e1-0a8e-4b81-92af-7090c387925e/assets\n",
      "INFO:tensorflow:Assets written to: ram://b49e2dd7-b22f-4059-9456-e45ee0b72c98/assets\n",
      "Epoch 4901 -- [D loss: 0.018(R -0.254, F 0.291)] [G loss: -0.243]\n",
      "Epoch 4902 -- [D loss: 0.005(R -0.237, F 0.247)] [G loss: -0.217]\n",
      "Epoch 4903 -- [D loss: -0.003(R -0.205, F 0.199)] [G loss: -0.218]\n",
      "Epoch 4904 -- [D loss: -0.009(R -0.218, F 0.199)] [G loss: -0.212]\n",
      "Epoch 4905 -- [D loss: -0.011(R -0.216, F 0.193)] [G loss: -0.215]\n",
      "Epoch 4906 -- [D loss: 0.003(R -0.172, F 0.179)] [G loss: -0.197]\n",
      "Epoch 4907 -- [D loss: -0.003(R -0.185, F 0.180)] [G loss: -0.181]\n",
      "Epoch 4908 -- [D loss: 0.004(R -0.160, F 0.168)] [G loss: -0.162]\n",
      "Epoch 4909 -- [D loss: 0.003(R -0.148, F 0.155)] [G loss: -0.142]\n",
      "Epoch 4910 -- [D loss: -0.020(R -0.160, F 0.120)] [G loss: -0.100]\n",
      "Epoch 4911 -- [D loss: -0.034(R -0.165, F 0.097)] [G loss: -0.071]\n",
      "Epoch 4912 -- [D loss: -0.046(R -0.191, F 0.099)] [G loss: -0.043]\n",
      "Epoch 4913 -- [D loss: -0.055(R -0.190, F 0.081)] [G loss: -0.068]\n",
      "Epoch 4914 -- [D loss: -0.042(R -0.216, F 0.131)] [G loss: -0.116]\n",
      "Epoch 4915 -- [D loss: -0.024(R -0.205, F 0.156)] [G loss: -0.211]\n",
      "Epoch 4916 -- [D loss: 0.001(R -0.186, F 0.188)] [G loss: -0.267]\n",
      "Epoch 4917 -- [D loss: 0.042(R -0.193, F 0.277)] [G loss: -0.295]\n",
      "Epoch 4918 -- [D loss: 0.045(R -0.135, F 0.225)] [G loss: -0.295]\n",
      "Epoch 4919 -- [D loss: 0.041(R -0.133, F 0.215)] [G loss: -0.258]\n",
      "Epoch 4920 -- [D loss: 0.029(R -0.092, F 0.149)] [G loss: -0.195]\n",
      "Epoch 4921 -- [D loss: 0.051(R -0.070, F 0.172)] [G loss: -0.122]\n",
      "Epoch 4922 -- [D loss: 0.015(R -0.049, F 0.079)] [G loss: -0.042]\n",
      "Epoch 4923 -- [D loss: -0.008(R -0.032, F 0.016)] [G loss: 0.035]\n",
      "Epoch 4924 -- [D loss: -0.041(R -0.007, F -0.076)] [G loss: 0.104]\n",
      "Epoch 4925 -- [D loss: -0.072(R -0.000, F -0.144)] [G loss: 0.169]\n",
      "Epoch 4926 -- [D loss: -0.113(R 0.008, F -0.234)] [G loss: 0.224]\n",
      "Epoch 4927 -- [D loss: -0.128(R 0.033, F -0.289)] [G loss: 0.265]\n",
      "Epoch 4928 -- [D loss: -0.150(R 0.045, F -0.345)] [G loss: 0.291]\n",
      "Epoch 4929 -- [D loss: -0.149(R 0.079, F -0.377)] [G loss: 0.281]\n",
      "Epoch 4930 -- [D loss: -0.060(R 0.147, F -0.268)] [G loss: 0.242]\n",
      "Epoch 4931 -- [D loss: -0.070(R 0.142, F -0.282)] [G loss: 0.224]\n",
      "Epoch 4932 -- [D loss: -0.038(R 0.198, F -0.275)] [G loss: 0.179]\n",
      "Epoch 4933 -- [D loss: 0.035(R 0.249, F -0.178)] [G loss: 0.161]\n",
      "Epoch 4934 -- [D loss: 0.032(R 0.233, F -0.169)] [G loss: 0.112]\n",
      "Epoch 4935 -- [D loss: 0.040(R 0.167, F -0.088)] [G loss: 0.094]\n",
      "Epoch 4936 -- [D loss: 0.050(R 0.150, F -0.051)] [G loss: 0.077]\n",
      "Epoch 4937 -- [D loss: 0.030(R 0.110, F -0.050)] [G loss: 0.058]\n",
      "Epoch 4938 -- [D loss: 0.015(R 0.071, F -0.041)] [G loss: 0.051]\n",
      "Epoch 4939 -- [D loss: -0.025(R 0.025, F -0.076)] [G loss: 0.061]\n",
      "Epoch 4940 -- [D loss: -0.038(R 0.016, F -0.092)] [G loss: 0.075]\n",
      "Epoch 4941 -- [D loss: -0.066(R 0.012, F -0.144)] [G loss: 0.099]\n",
      "Epoch 4942 -- [D loss: -0.051(R 0.013, F -0.116)] [G loss: 0.123]\n",
      "Epoch 4943 -- [D loss: -0.077(R -0.019, F -0.135)] [G loss: 0.125]\n",
      "Epoch 4944 -- [D loss: -0.062(R -0.009, F -0.115)] [G loss: 0.128]\n",
      "Epoch 4945 -- [D loss: -0.061(R -0.017, F -0.105)] [G loss: 0.089]\n",
      "Epoch 4946 -- [D loss: -0.050(R -0.025, F -0.076)] [G loss: 0.066]\n",
      "Epoch 4947 -- [D loss: -0.042(R -0.040, F -0.044)] [G loss: 0.022]\n",
      "Epoch 4948 -- [D loss: -0.018(R -0.021, F -0.015)] [G loss: -0.009]\n",
      "Epoch 4949 -- [D loss: 0.017(R -0.001, F 0.034)] [G loss: -0.037]\n",
      "Epoch 4950 -- [D loss: 0.037(R 0.011, F 0.063)] [G loss: -0.052]\n",
      "Epoch 4951 -- [D loss: 0.041(R -0.014, F 0.096)] [G loss: -0.061]\n",
      "Epoch 4952 -- [D loss: 0.025(R -0.022, F 0.073)] [G loss: -0.054]\n",
      "Epoch 4953 -- [D loss: -0.000(R -0.053, F 0.052)] [G loss: -0.054]\n",
      "Epoch 4954 -- [D loss: -0.014(R -0.082, F 0.055)] [G loss: -0.061]\n",
      "Epoch 4955 -- [D loss: -0.049(R -0.149, F 0.052)] [G loss: -0.082]\n",
      "Epoch 4956 -- [D loss: -0.062(R -0.236, F 0.113)] [G loss: -0.135]\n",
      "Epoch 4957 -- [D loss: -0.049(R -0.260, F 0.162)] [G loss: -0.213]\n",
      "Epoch 4958 -- [D loss: -0.020(R -0.325, F 0.286)] [G loss: -0.294]\n",
      "Epoch 4959 -- [D loss: -0.010(R -0.311, F 0.290)] [G loss: -0.383]\n",
      "Epoch 4960 -- [D loss: 0.022(R -0.330, F 0.374)] [G loss: -0.404]\n",
      "Epoch 4961 -- [D loss: 0.041(R -0.272, F 0.354)] [G loss: -0.393]\n",
      "Epoch 4962 -- [D loss: 0.041(R -0.259, F 0.341)] [G loss: -0.352]\n",
      "Epoch 4963 -- [D loss: 0.004(R -0.283, F 0.290)] [G loss: -0.303]\n",
      "Epoch 4964 -- [D loss: -0.003(R -0.255, F 0.249)] [G loss: -0.257]\n",
      "Epoch 4965 -- [D loss: -0.037(R -0.223, F 0.148)] [G loss: -0.201]\n",
      "Epoch 4966 -- [D loss: -0.058(R -0.186, F 0.071)] [G loss: -0.179]\n",
      "Epoch 4967 -- [D loss: -0.066(R -0.180, F 0.048)] [G loss: -0.139]\n",
      "Epoch 4968 -- [D loss: -0.039(R -0.089, F 0.011)] [G loss: -0.121]\n",
      "Epoch 4969 -- [D loss: -0.102(R -0.122, F -0.081)] [G loss: -0.136]\n",
      "Epoch 4970 -- [D loss: -0.022(R -0.044, F -0.000)] [G loss: -0.109]\n",
      "Epoch 4971 -- [D loss: -0.029(R -0.062, F 0.004)] [G loss: -0.083]\n",
      "Epoch 4972 -- [D loss: 0.013(R -0.036, F 0.063)] [G loss: -0.046]\n",
      "Epoch 4973 -- [D loss: -0.009(R -0.066, F 0.048)] [G loss: -0.019]\n",
      "Epoch 4974 -- [D loss: -0.042(R -0.059, F -0.025)] [G loss: 0.003]\n",
      "Epoch 4975 -- [D loss: -0.059(R -0.042, F -0.077)] [G loss: 0.050]\n",
      "Epoch 4976 -- [D loss: -0.077(R 0.035, F -0.189)] [G loss: 0.099]\n",
      "Epoch 4977 -- [D loss: -0.087(R 0.064, F -0.238)] [G loss: 0.134]\n",
      "Epoch 4978 -- [D loss: -0.102(R 0.061, F -0.265)] [G loss: 0.156]\n",
      "Epoch 4979 -- [D loss: -0.076(R 0.109, F -0.262)] [G loss: 0.173]\n",
      "Epoch 4980 -- [D loss: -0.059(R 0.154, F -0.272)] [G loss: 0.213]\n",
      "Epoch 4981 -- [D loss: 0.002(R 0.275, F -0.271)] [G loss: 0.258]\n",
      "Epoch 4982 -- [D loss: -0.014(R 0.309, F -0.338)] [G loss: 0.320]\n",
      "Epoch 4983 -- [D loss: -0.011(R 0.389, F -0.411)] [G loss: 0.379]\n",
      "Epoch 4984 -- [D loss: -0.000(R 0.454, F -0.455)] [G loss: 0.422]\n",
      "Epoch 4985 -- [D loss: -0.030(R 0.467, F -0.526)] [G loss: 0.449]\n",
      "Epoch 4986 -- [D loss: -0.037(R 0.456, F -0.530)] [G loss: 0.471]\n",
      "Epoch 4987 -- [D loss: 0.013(R 0.497, F -0.472)] [G loss: 0.486]\n",
      "Epoch 4988 -- [D loss: 0.017(R 0.485, F -0.450)] [G loss: 0.494]\n",
      "Epoch 4989 -- [D loss: 0.020(R 0.490, F -0.450)] [G loss: 0.486]\n",
      "Epoch 4990 -- [D loss: -0.005(R 0.437, F -0.447)] [G loss: 0.479]\n",
      "Epoch 4991 -- [D loss: -0.027(R 0.391, F -0.444)] [G loss: 0.483]\n",
      "Epoch 4992 -- [D loss: 0.001(R 0.369, F -0.366)] [G loss: 0.455]\n",
      "Epoch 4993 -- [D loss: -0.011(R 0.324, F -0.345)] [G loss: 0.413]\n",
      "Epoch 4994 -- [D loss: -0.010(R 0.287, F -0.308)] [G loss: 0.373]\n",
      "Epoch 4995 -- [D loss: -0.005(R 0.254, F -0.264)] [G loss: 0.321]\n",
      "Epoch 4996 -- [D loss: -0.004(R 0.232, F -0.239)] [G loss: 0.271]\n",
      "Epoch 4997 -- [D loss: 0.009(R 0.227, F -0.209)] [G loss: 0.236]\n",
      "Epoch 4998 -- [D loss: 0.003(R 0.183, F -0.177)] [G loss: 0.198]\n",
      "Epoch 4999 -- [D loss: -0.002(R 0.151, F -0.155)] [G loss: 0.160]\n",
      "Epoch 5000 -- [D loss: 0.011(R 0.138, F -0.115)] [G loss: 0.122]\n",
      "INFO:tensorflow:Assets written to: ram://0dfa916a-4eb0-4da1-95b3-ceb84f6699ae/assets\n",
      "INFO:tensorflow:Assets written to: ram://1bcfe974-c52f-48b8-b09c-d98ece027b0b/assets\n",
      "INFO:tensorflow:Assets written to: ram://48be5649-ea9c-47c1-819e-e170e71c2654/assets\n",
      "Epoch 5001 -- [D loss: 0.019(R 0.110, F -0.072)] [G loss: 0.083]\n",
      "Epoch 5002 -- [D loss: 0.021(R 0.088, F -0.046)] [G loss: 0.049]\n",
      "Epoch 5003 -- [D loss: 0.020(R 0.060, F -0.021)] [G loss: 0.022]\n",
      "Epoch 5004 -- [D loss: 0.007(R 0.021, F -0.007)] [G loss: 0.009]\n",
      "Epoch 5005 -- [D loss: 0.009(R 0.002, F 0.015)] [G loss: -0.005]\n",
      "Epoch 5006 -- [D loss: -0.001(R -0.012, F 0.011)] [G loss: -0.005]\n",
      "Epoch 5007 -- [D loss: -0.010(R -0.038, F 0.018)] [G loss: -0.010]\n",
      "Epoch 5008 -- [D loss: -0.025(R -0.063, F 0.013)] [G loss: -0.002]\n",
      "Epoch 5009 -- [D loss: -0.033(R -0.074, F 0.008)] [G loss: -0.008]\n",
      "Epoch 5010 -- [D loss: -0.024(R -0.077, F 0.028)] [G loss: -0.017]\n",
      "Epoch 5011 -- [D loss: -0.035(R -0.108, F 0.037)] [G loss: -0.032]\n",
      "Epoch 5012 -- [D loss: -0.030(R -0.132, F 0.072)] [G loss: -0.067]\n",
      "Epoch 5013 -- [D loss: -0.020(R -0.145, F 0.106)] [G loss: -0.098]\n",
      "Epoch 5014 -- [D loss: -0.007(R -0.135, F 0.121)] [G loss: -0.150]\n",
      "Epoch 5015 -- [D loss: 0.013(R -0.133, F 0.160)] [G loss: -0.179]\n",
      "Epoch 5016 -- [D loss: 0.017(R -0.140, F 0.175)] [G loss: -0.193]\n",
      "Epoch 5017 -- [D loss: 0.018(R -0.137, F 0.174)] [G loss: -0.197]\n",
      "Epoch 5018 -- [D loss: 0.023(R -0.127, F 0.173)] [G loss: -0.178]\n",
      "Epoch 5019 -- [D loss: 0.008(R -0.132, F 0.148)] [G loss: -0.150]\n",
      "Epoch 5020 -- [D loss: 0.003(R -0.122, F 0.128)] [G loss: -0.114]\n",
      "Epoch 5021 -- [D loss: -0.007(R -0.110, F 0.096)] [G loss: -0.071]\n",
      "Epoch 5022 -- [D loss: -0.028(R -0.112, F 0.055)] [G loss: -0.023]\n",
      "Epoch 5023 -- [D loss: -0.055(R -0.130, F 0.020)] [G loss: -0.011]\n",
      "Epoch 5024 -- [D loss: -0.056(R -0.126, F 0.013)] [G loss: 0.000]\n",
      "Epoch 5025 -- [D loss: -0.042(R -0.138, F 0.055)] [G loss: -0.028]\n",
      "Epoch 5026 -- [D loss: 0.003(R -0.093, F 0.099)] [G loss: -0.064]\n",
      "Epoch 5027 -- [D loss: 0.002(R -0.105, F 0.110)] [G loss: -0.073]\n",
      "Epoch 5028 -- [D loss: 0.030(R -0.078, F 0.138)] [G loss: -0.093]\n",
      "Epoch 5029 -- [D loss: 0.023(R -0.071, F 0.118)] [G loss: -0.079]\n",
      "Epoch 5030 -- [D loss: 0.035(R -0.031, F 0.102)] [G loss: -0.072]\n",
      "Epoch 5031 -- [D loss: 0.018(R -0.036, F 0.071)] [G loss: -0.062]\n",
      "Epoch 5032 -- [D loss: 0.016(R -0.023, F 0.055)] [G loss: -0.052]\n",
      "Epoch 5033 -- [D loss: 0.010(R -0.015, F 0.035)] [G loss: -0.045]\n",
      "Epoch 5034 -- [D loss: 0.007(R -0.011, F 0.025)] [G loss: -0.026]\n",
      "Epoch 5035 -- [D loss: -0.002(R -0.021, F 0.016)] [G loss: -0.009]\n",
      "Epoch 5036 -- [D loss: -0.004(R -0.021, F 0.014)] [G loss: 0.004]\n",
      "Epoch 5037 -- [D loss: -0.017(R -0.028, F -0.007)] [G loss: 0.017]\n",
      "Epoch 5038 -- [D loss: -0.024(R -0.039, F -0.008)] [G loss: 0.018]\n",
      "Epoch 5039 -- [D loss: -0.043(R -0.058, F -0.029)] [G loss: 0.012]\n",
      "Epoch 5040 -- [D loss: -0.033(R -0.040, F -0.025)] [G loss: 0.006]\n",
      "Epoch 5041 -- [D loss: -0.019(R -0.018, F -0.019)] [G loss: -0.008]\n",
      "Epoch 5042 -- [D loss: -0.009(R -0.047, F 0.029)] [G loss: -0.043]\n",
      "Epoch 5043 -- [D loss: 0.007(R -0.039, F 0.053)] [G loss: -0.057]\n",
      "Epoch 5044 -- [D loss: 0.002(R -0.048, F 0.052)] [G loss: -0.066]\n",
      "Epoch 5045 -- [D loss: 0.027(R -0.039, F 0.092)] [G loss: -0.067]\n",
      "Epoch 5046 -- [D loss: 0.032(R -0.024, F 0.088)] [G loss: -0.053]\n",
      "Epoch 5047 -- [D loss: 0.022(R -0.029, F 0.073)] [G loss: -0.034]\n",
      "Epoch 5048 -- [D loss: 0.011(R -0.020, F 0.041)] [G loss: -0.011]\n",
      "Epoch 5049 -- [D loss: -0.008(R -0.026, F 0.010)] [G loss: 0.012]\n",
      "Epoch 5050 -- [D loss: -0.022(R -0.031, F -0.014)] [G loss: 0.029]\n",
      "Epoch 5051 -- [D loss: -0.044(R -0.065, F -0.023)] [G loss: 0.040]\n",
      "Epoch 5052 -- [D loss: -0.049(R -0.059, F -0.040)] [G loss: 0.028]\n",
      "Epoch 5053 -- [D loss: -0.029(R -0.068, F 0.011)] [G loss: -0.014]\n",
      "Epoch 5054 -- [D loss: -0.028(R -0.097, F 0.041)] [G loss: -0.092]\n",
      "Epoch 5055 -- [D loss: 0.000(R -0.129, F 0.129)] [G loss: -0.160]\n",
      "Epoch 5056 -- [D loss: 0.016(R -0.127, F 0.159)] [G loss: -0.194]\n",
      "Epoch 5057 -- [D loss: 0.055(R -0.053, F 0.163)] [G loss: -0.191]\n",
      "Epoch 5058 -- [D loss: 0.037(R -0.069, F 0.144)] [G loss: -0.156]\n",
      "Epoch 5059 -- [D loss: 0.025(R -0.050, F 0.099)] [G loss: -0.120]\n",
      "Epoch 5060 -- [D loss: 0.027(R -0.031, F 0.085)] [G loss: -0.070]\n",
      "Epoch 5061 -- [D loss: -0.004(R -0.032, F 0.024)] [G loss: -0.023]\n",
      "Epoch 5062 -- [D loss: -0.039(R -0.036, F -0.042)] [G loss: 0.028]\n",
      "Epoch 5063 -- [D loss: -0.058(R -0.025, F -0.091)] [G loss: 0.081]\n",
      "Epoch 5064 -- [D loss: -0.089(R -0.031, F -0.146)] [G loss: 0.138]\n",
      "Epoch 5065 -- [D loss: -0.132(R -0.067, F -0.196)] [G loss: 0.175]\n",
      "Epoch 5066 -- [D loss: -0.142(R -0.053, F -0.231)] [G loss: 0.149]\n",
      "Epoch 5067 -- [D loss: -0.134(R -0.027, F -0.241)] [G loss: 0.098]\n",
      "Epoch 5068 -- [D loss: -0.088(R -0.090, F -0.087)] [G loss: -0.009]\n",
      "Epoch 5069 -- [D loss: -0.014(R -0.029, F 0.002)] [G loss: -0.139]\n",
      "Epoch 5070 -- [D loss: 0.061(R -0.051, F 0.173)] [G loss: -0.221]\n",
      "Epoch 5071 -- [D loss: 0.097(R -0.074, F 0.269)] [G loss: -0.254]\n",
      "Epoch 5072 -- [D loss: 0.069(R -0.103, F 0.240)] [G loss: -0.255]\n",
      "Epoch 5073 -- [D loss: 0.068(R -0.084, F 0.221)] [G loss: -0.219]\n",
      "Epoch 5074 -- [D loss: 0.057(R -0.076, F 0.190)] [G loss: -0.184]\n",
      "Epoch 5075 -- [D loss: 0.029(R -0.095, F 0.152)] [G loss: -0.144]\n",
      "Epoch 5076 -- [D loss: 0.014(R -0.086, F 0.115)] [G loss: -0.103]\n",
      "Epoch 5077 -- [D loss: -0.003(R -0.082, F 0.077)] [G loss: -0.066]\n",
      "Epoch 5078 -- [D loss: -0.015(R -0.084, F 0.053)] [G loss: -0.034]\n",
      "Epoch 5079 -- [D loss: -0.037(R -0.111, F 0.038)] [G loss: -0.005]\n",
      "Epoch 5080 -- [D loss: -0.038(R -0.124, F 0.049)] [G loss: -0.005]\n",
      "Epoch 5081 -- [D loss: -0.040(R -0.172, F 0.091)] [G loss: -0.019]\n",
      "Epoch 5082 -- [D loss: -0.005(R -0.164, F 0.154)] [G loss: -0.060]\n",
      "Epoch 5083 -- [D loss: -0.012(R -0.166, F 0.142)] [G loss: -0.089]\n",
      "Epoch 5084 -- [D loss: 0.020(R -0.107, F 0.148)] [G loss: -0.112]\n",
      "Epoch 5085 -- [D loss: 0.037(R -0.095, F 0.169)] [G loss: -0.103]\n",
      "Epoch 5086 -- [D loss: 0.022(R -0.084, F 0.127)] [G loss: -0.089]\n",
      "Epoch 5087 -- [D loss: 0.019(R -0.056, F 0.094)] [G loss: -0.070]\n",
      "Epoch 5088 -- [D loss: 0.002(R -0.047, F 0.050)] [G loss: -0.042]\n",
      "Epoch 5089 -- [D loss: -0.011(R -0.038, F 0.016)] [G loss: -0.009]\n",
      "Epoch 5090 -- [D loss: -0.019(R -0.025, F -0.013)] [G loss: 0.016]\n",
      "Epoch 5091 -- [D loss: -0.027(R -0.029, F -0.025)] [G loss: 0.041]\n",
      "Epoch 5092 -- [D loss: -0.028(R -0.001, F -0.055)] [G loss: 0.063]\n",
      "Epoch 5093 -- [D loss: -0.031(R 0.009, F -0.071)] [G loss: 0.059]\n",
      "Epoch 5094 -- [D loss: -0.023(R 0.004, F -0.050)] [G loss: 0.062]\n",
      "Epoch 5095 -- [D loss: -0.014(R 0.027, F -0.056)] [G loss: 0.075]\n",
      "Epoch 5096 -- [D loss: 0.009(R 0.058, F -0.040)] [G loss: 0.068]\n",
      "Epoch 5097 -- [D loss: -0.001(R 0.042, F -0.044)] [G loss: 0.070]\n",
      "Epoch 5098 -- [D loss: -0.000(R 0.042, F -0.042)] [G loss: 0.056]\n",
      "Epoch 5099 -- [D loss: 0.010(R 0.047, F -0.027)] [G loss: 0.053]\n",
      "Epoch 5100 -- [D loss: 0.008(R 0.046, F -0.030)] [G loss: 0.043]\n",
      "INFO:tensorflow:Assets written to: ram://25576b93-4941-48e8-b785-76b5bfd8a170/assets\n",
      "INFO:tensorflow:Assets written to: ram://17c3fdfe-b34e-45f3-b951-553a72332c1b/assets\n",
      "INFO:tensorflow:Assets written to: ram://0eb9a589-855a-4083-a713-c86f458fe129/assets\n",
      "Epoch 5101 -- [D loss: 0.010(R 0.043, F -0.022)] [G loss: 0.040]\n",
      "Epoch 5102 -- [D loss: 0.004(R 0.037, F -0.029)] [G loss: 0.037]\n",
      "Epoch 5103 -- [D loss: 0.000(R 0.033, F -0.032)] [G loss: 0.041]\n",
      "Epoch 5104 -- [D loss: -0.001(R 0.031, F -0.033)] [G loss: 0.052]\n",
      "Epoch 5105 -- [D loss: -0.006(R 0.028, F -0.041)] [G loss: 0.054]\n",
      "Epoch 5106 -- [D loss: -0.014(R 0.023, F -0.051)] [G loss: 0.065]\n",
      "Epoch 5107 -- [D loss: -0.007(R 0.033, F -0.047)] [G loss: 0.069]\n",
      "Epoch 5108 -- [D loss: -0.013(R 0.028, F -0.054)] [G loss: 0.063]\n",
      "Epoch 5109 -- [D loss: -0.002(R 0.032, F -0.036)] [G loss: 0.055]\n",
      "Epoch 5110 -- [D loss: -0.008(R 0.017, F -0.034)] [G loss: 0.044]\n",
      "Epoch 5111 -- [D loss: -0.001(R 0.018, F -0.019)] [G loss: 0.029]\n",
      "Epoch 5112 -- [D loss: 0.005(R 0.023, F -0.013)] [G loss: 0.025]\n",
      "Epoch 5113 -- [D loss: -0.003(R 0.011, F -0.016)] [G loss: 0.024]\n",
      "Epoch 5114 -- [D loss: -0.002(R 0.011, F -0.015)] [G loss: 0.021]\n",
      "Epoch 5115 -- [D loss: -0.001(R 0.006, F -0.008)] [G loss: 0.017]\n",
      "Epoch 5116 -- [D loss: -0.008(R -0.003, F -0.012)] [G loss: 0.023]\n",
      "Epoch 5117 -- [D loss: -0.007(R -0.008, F -0.006)] [G loss: 0.016]\n",
      "Epoch 5118 -- [D loss: -0.009(R -0.013, F -0.006)] [G loss: 0.007]\n",
      "Epoch 5119 -- [D loss: -0.004(R -0.013, F 0.006)] [G loss: -0.000]\n",
      "Epoch 5120 -- [D loss: -0.002(R -0.021, F 0.016)] [G loss: -0.015]\n",
      "Epoch 5121 -- [D loss: 0.003(R -0.011, F 0.018)] [G loss: -0.023]\n",
      "Epoch 5122 -- [D loss: 0.003(R -0.024, F 0.029)] [G loss: -0.040]\n",
      "Epoch 5123 -- [D loss: 0.004(R -0.023, F 0.031)] [G loss: -0.043]\n",
      "Epoch 5124 -- [D loss: -0.000(R -0.026, F 0.026)] [G loss: -0.044]\n",
      "Epoch 5125 -- [D loss: 0.000(R -0.024, F 0.024)] [G loss: -0.035]\n",
      "Epoch 5126 -- [D loss: -0.010(R -0.031, F 0.012)] [G loss: -0.014]\n",
      "Epoch 5127 -- [D loss: -0.015(R -0.021, F -0.010)] [G loss: 0.010]\n",
      "Epoch 5128 -- [D loss: -0.018(R -0.016, F -0.021)] [G loss: 0.031]\n",
      "Epoch 5129 -- [D loss: -0.026(R -0.013, F -0.040)] [G loss: 0.053]\n",
      "Epoch 5130 -- [D loss: -0.025(R 0.012, F -0.063)] [G loss: 0.052]\n",
      "Epoch 5131 -- [D loss: -0.019(R 0.025, F -0.062)] [G loss: 0.045]\n",
      "Epoch 5132 -- [D loss: -0.030(R 0.013, F -0.073)] [G loss: 0.027]\n",
      "Epoch 5133 -- [D loss: 0.001(R 0.043, F -0.040)] [G loss: 0.012]\n",
      "Epoch 5134 -- [D loss: 0.007(R 0.023, F -0.009)] [G loss: -0.010]\n",
      "Epoch 5135 -- [D loss: 0.023(R 0.021, F 0.026)] [G loss: -0.023]\n",
      "Epoch 5136 -- [D loss: 0.015(R 0.002, F 0.029)] [G loss: -0.030]\n",
      "Epoch 5137 -- [D loss: 0.014(R -0.006, F 0.034)] [G loss: -0.033]\n",
      "Epoch 5138 -- [D loss: 0.008(R -0.013, F 0.029)] [G loss: -0.025]\n",
      "Epoch 5139 -- [D loss: 0.004(R -0.016, F 0.023)] [G loss: -0.020]\n",
      "Epoch 5140 -- [D loss: -0.003(R -0.033, F 0.027)] [G loss: -0.019]\n",
      "Epoch 5141 -- [D loss: -0.011(R -0.047, F 0.025)] [G loss: -0.016]\n",
      "Epoch 5142 -- [D loss: -0.011(R -0.072, F 0.050)] [G loss: -0.028]\n",
      "Epoch 5143 -- [D loss: -0.020(R -0.090, F 0.051)] [G loss: -0.054]\n",
      "Epoch 5144 -- [D loss: -0.020(R -0.133, F 0.093)] [G loss: -0.086]\n",
      "Epoch 5145 -- [D loss: -0.012(R -0.121, F 0.098)] [G loss: -0.117]\n",
      "Epoch 5146 -- [D loss: -0.016(R -0.158, F 0.127)] [G loss: -0.147]\n",
      "Epoch 5147 -- [D loss: -0.034(R -0.190, F 0.123)] [G loss: -0.164]\n",
      "Epoch 5148 -- [D loss: -0.013(R -0.188, F 0.163)] [G loss: -0.171]\n",
      "Epoch 5149 -- [D loss: 0.019(R -0.136, F 0.174)] [G loss: -0.151]\n",
      "Epoch 5150 -- [D loss: 0.019(R -0.118, F 0.157)] [G loss: -0.125]\n",
      "Epoch 5151 -- [D loss: 0.006(R -0.107, F 0.119)] [G loss: -0.089]\n",
      "Epoch 5152 -- [D loss: 0.009(R -0.078, F 0.096)] [G loss: -0.062]\n",
      "Epoch 5153 -- [D loss: -0.012(R -0.062, F 0.037)] [G loss: -0.043]\n",
      "Epoch 5154 -- [D loss: -0.015(R -0.050, F 0.019)] [G loss: -0.003]\n",
      "Epoch 5155 -- [D loss: -0.020(R -0.023, F -0.016)] [G loss: 0.015]\n",
      "Epoch 5156 -- [D loss: -0.025(R -0.010, F -0.040)] [G loss: 0.051]\n",
      "Epoch 5157 -- [D loss: -0.042(R 0.012, F -0.096)] [G loss: 0.065]\n",
      "Epoch 5158 -- [D loss: -0.026(R 0.042, F -0.093)] [G loss: 0.085]\n",
      "Epoch 5159 -- [D loss: -0.029(R 0.073, F -0.131)] [G loss: 0.110]\n",
      "Epoch 5160 -- [D loss: -0.012(R 0.093, F -0.116)] [G loss: 0.122]\n",
      "Epoch 5161 -- [D loss: 0.000(R 0.101, F -0.101)] [G loss: 0.111]\n",
      "Epoch 5162 -- [D loss: 0.009(R 0.105, F -0.087)] [G loss: 0.107]\n",
      "Epoch 5163 -- [D loss: 0.008(R 0.083, F -0.066)] [G loss: 0.111]\n",
      "Epoch 5164 -- [D loss: 0.015(R 0.097, F -0.067)] [G loss: 0.101]\n",
      "Epoch 5165 -- [D loss: 0.007(R 0.084, F -0.071)] [G loss: 0.080]\n",
      "Epoch 5166 -- [D loss: -0.005(R 0.053, F -0.064)] [G loss: 0.070]\n",
      "Epoch 5167 -- [D loss: 0.006(R 0.048, F -0.035)] [G loss: 0.051]\n",
      "Epoch 5168 -- [D loss: -0.001(R 0.012, F -0.013)] [G loss: 0.031]\n",
      "Epoch 5169 -- [D loss: -0.006(R -0.007, F -0.004)] [G loss: 0.006]\n",
      "Epoch 5170 -- [D loss: -0.005(R -0.033, F 0.023)] [G loss: -0.012]\n",
      "Epoch 5171 -- [D loss: -0.007(R -0.036, F 0.022)] [G loss: -0.010]\n",
      "Epoch 5172 -- [D loss: 0.001(R -0.032, F 0.034)] [G loss: -0.008]\n",
      "Epoch 5173 -- [D loss: 0.000(R -0.028, F 0.028)] [G loss: -0.005]\n",
      "Epoch 5174 -- [D loss: -0.007(R -0.036, F 0.023)] [G loss: -0.003]\n",
      "Epoch 5175 -- [D loss: -0.022(R -0.049, F 0.005)] [G loss: 0.002]\n",
      "Epoch 5176 -- [D loss: -0.010(R -0.042, F 0.021)] [G loss: 0.010]\n",
      "Epoch 5177 -- [D loss: -0.015(R -0.026, F -0.005)] [G loss: 0.010]\n",
      "Epoch 5178 -- [D loss: -0.006(R -0.013, F 0.001)] [G loss: 0.011]\n",
      "Epoch 5179 -- [D loss: -0.001(R -0.009, F 0.007)] [G loss: 0.006]\n",
      "Epoch 5180 -- [D loss: 0.000(R -0.010, F 0.010)] [G loss: 0.014]\n",
      "Epoch 5181 -- [D loss: -0.002(R -0.002, F -0.001)] [G loss: 0.016]\n",
      "Epoch 5182 -- [D loss: 0.004(R 0.012, F -0.004)] [G loss: 0.017]\n",
      "Epoch 5183 -- [D loss: -0.004(R 0.011, F -0.019)] [G loss: 0.025]\n",
      "Epoch 5184 -- [D loss: -0.007(R 0.008, F -0.021)] [G loss: 0.014]\n",
      "Epoch 5185 -- [D loss: -0.010(R 0.001, F -0.022)] [G loss: 0.002]\n",
      "Epoch 5186 -- [D loss: -0.012(R 0.004, F -0.028)] [G loss: -0.002]\n",
      "Epoch 5187 -- [D loss: -0.005(R 0.004, F -0.014)] [G loss: -0.002]\n",
      "Epoch 5188 -- [D loss: -0.004(R -0.006, F -0.002)] [G loss: 0.003]\n",
      "Epoch 5189 -- [D loss: -0.011(R -0.009, F -0.013)] [G loss: 0.018]\n",
      "Epoch 5190 -- [D loss: -0.017(R -0.006, F -0.028)] [G loss: 0.046]\n",
      "Epoch 5191 -- [D loss: -0.028(R -0.017, F -0.039)] [G loss: 0.055]\n",
      "Epoch 5192 -- [D loss: -0.037(R -0.027, F -0.046)] [G loss: 0.056]\n",
      "Epoch 5193 -- [D loss: -0.053(R -0.039, F -0.068)] [G loss: 0.027]\n",
      "Epoch 5194 -- [D loss: -0.039(R 0.001, F -0.079)] [G loss: -0.008]\n",
      "Epoch 5195 -- [D loss: -0.042(R -0.023, F -0.061)] [G loss: -0.050]\n",
      "Epoch 5196 -- [D loss: -0.023(R 0.009, F -0.055)] [G loss: -0.066]\n",
      "Epoch 5197 -- [D loss: -0.017(R -0.025, F -0.008)] [G loss: -0.089]\n",
      "Epoch 5198 -- [D loss: 0.012(R -0.025, F 0.048)] [G loss: -0.109]\n",
      "Epoch 5199 -- [D loss: 0.028(R -0.028, F 0.084)] [G loss: -0.110]\n",
      "Epoch 5200 -- [D loss: 0.027(R -0.039, F 0.092)] [G loss: -0.097]\n",
      "INFO:tensorflow:Assets written to: ram://529d3dc8-bd7c-4cb9-be90-8407792e19b8/assets\n",
      "INFO:tensorflow:Assets written to: ram://9c4bfa69-0814-4559-a6cf-da0187f8c8f3/assets\n",
      "INFO:tensorflow:Assets written to: ram://04090243-da5a-43bf-8a5e-b2ab360f345a/assets\n",
      "Epoch 5201 -- [D loss: 0.010(R -0.061, F 0.082)] [G loss: -0.075]\n",
      "Epoch 5202 -- [D loss: 0.005(R -0.057, F 0.066)] [G loss: -0.052]\n",
      "Epoch 5203 -- [D loss: -0.006(R -0.060, F 0.048)] [G loss: -0.028]\n",
      "Epoch 5204 -- [D loss: -0.024(R -0.076, F 0.027)] [G loss: -0.010]\n",
      "Epoch 5205 -- [D loss: -0.042(R -0.095, F 0.011)] [G loss: 0.007]\n",
      "Epoch 5206 -- [D loss: -0.061(R -0.118, F -0.003)] [G loss: 0.003]\n",
      "Epoch 5207 -- [D loss: -0.081(R -0.180, F 0.018)] [G loss: -0.029]\n",
      "Epoch 5208 -- [D loss: -0.060(R -0.167, F 0.047)] [G loss: -0.063]\n",
      "Epoch 5209 -- [D loss: -0.053(R -0.198, F 0.091)] [G loss: -0.124]\n",
      "Epoch 5210 -- [D loss: -0.048(R -0.226, F 0.131)] [G loss: -0.175]\n",
      "Epoch 5211 -- [D loss: -0.056(R -0.245, F 0.133)] [G loss: -0.204]\n",
      "Epoch 5212 -- [D loss: -0.016(R -0.197, F 0.166)] [G loss: -0.242]\n",
      "Epoch 5213 -- [D loss: 0.002(R -0.158, F 0.162)] [G loss: -0.253]\n",
      "Epoch 5214 -- [D loss: 0.030(R -0.141, F 0.201)] [G loss: -0.276]\n",
      "Epoch 5215 -- [D loss: 0.048(R -0.097, F 0.193)] [G loss: -0.280]\n",
      "Epoch 5216 -- [D loss: 0.047(R -0.094, F 0.188)] [G loss: -0.257]\n",
      "Epoch 5217 -- [D loss: 0.039(R -0.072, F 0.150)] [G loss: -0.233]\n",
      "Epoch 5218 -- [D loss: 0.030(R -0.062, F 0.122)] [G loss: -0.177]\n",
      "Epoch 5219 -- [D loss: 0.031(R -0.057, F 0.119)] [G loss: -0.110]\n",
      "Epoch 5220 -- [D loss: 0.013(R -0.035, F 0.061)] [G loss: -0.053]\n",
      "Epoch 5221 -- [D loss: -0.009(R -0.014, F -0.003)] [G loss: 0.018]\n",
      "Epoch 5222 -- [D loss: -0.033(R -0.009, F -0.058)] [G loss: 0.086]\n",
      "Epoch 5223 -- [D loss: -0.050(R 0.016, F -0.116)] [G loss: 0.163]\n",
      "Epoch 5224 -- [D loss: -0.093(R 0.030, F -0.217)] [G loss: 0.252]\n",
      "Epoch 5225 -- [D loss: -0.142(R 0.040, F -0.323)] [G loss: 0.328]\n",
      "Epoch 5226 -- [D loss: -0.171(R 0.056, F -0.397)] [G loss: 0.380]\n",
      "Epoch 5227 -- [D loss: -0.152(R 0.139, F -0.444)] [G loss: 0.383]\n",
      "Epoch 5228 -- [D loss: -0.143(R 0.131, F -0.417)] [G loss: 0.354]\n",
      "Epoch 5229 -- [D loss: -0.085(R 0.199, F -0.368)] [G loss: 0.307]\n",
      "Epoch 5230 -- [D loss: -0.078(R 0.147, F -0.304)] [G loss: 0.224]\n",
      "Epoch 5231 -- [D loss: 0.024(R 0.201, F -0.153)] [G loss: 0.138]\n",
      "Epoch 5232 -- [D loss: 0.048(R 0.151, F -0.054)] [G loss: 0.062]\n",
      "Epoch 5233 -- [D loss: 0.028(R 0.075, F -0.018)] [G loss: -0.016]\n",
      "Epoch 5234 -- [D loss: 0.036(R 0.063, F 0.008)] [G loss: -0.058]\n",
      "Epoch 5235 -- [D loss: 0.033(R 0.027, F 0.039)] [G loss: -0.083]\n",
      "Epoch 5236 -- [D loss: 0.040(R 0.017, F 0.064)] [G loss: -0.084]\n",
      "Epoch 5237 -- [D loss: 0.028(R -0.002, F 0.058)] [G loss: -0.081]\n",
      "Epoch 5238 -- [D loss: 0.015(R -0.013, F 0.043)] [G loss: -0.068]\n",
      "Epoch 5239 -- [D loss: -0.014(R -0.056, F 0.027)] [G loss: -0.035]\n",
      "Epoch 5240 -- [D loss: -0.043(R -0.101, F 0.015)] [G loss: -0.010]\n",
      "Epoch 5241 -- [D loss: -0.052(R -0.149, F 0.045)] [G loss: 0.002]\n",
      "Epoch 5242 -- [D loss: -0.060(R -0.196, F 0.075)] [G loss: -0.003]\n",
      "Epoch 5243 -- [D loss: -0.087(R -0.274, F 0.100)] [G loss: -0.023]\n",
      "Epoch 5244 -- [D loss: -0.070(R -0.290, F 0.150)] [G loss: -0.092]\n",
      "Epoch 5245 -- [D loss: -0.001(R -0.278, F 0.277)] [G loss: -0.162]\n",
      "Epoch 5246 -- [D loss: 0.002(R -0.279, F 0.283)] [G loss: -0.239]\n",
      "Epoch 5247 -- [D loss: 0.012(R -0.284, F 0.307)] [G loss: -0.299]\n",
      "Epoch 5248 -- [D loss: 0.031(R -0.253, F 0.314)] [G loss: -0.338]\n",
      "Epoch 5249 -- [D loss: 0.015(R -0.273, F 0.302)] [G loss: -0.361]\n",
      "Epoch 5250 -- [D loss: 0.031(R -0.222, F 0.284)] [G loss: -0.356]\n",
      "Epoch 5251 -- [D loss: 0.015(R -0.191, F 0.220)] [G loss: -0.310]\n",
      "Epoch 5252 -- [D loss: 0.033(R -0.117, F 0.183)] [G loss: -0.247]\n",
      "Epoch 5253 -- [D loss: 0.003(R -0.114, F 0.120)] [G loss: -0.189]\n",
      "Epoch 5254 -- [D loss: -0.016(R -0.106, F 0.075)] [G loss: -0.122]\n",
      "Epoch 5255 -- [D loss: -0.022(R -0.068, F 0.023)] [G loss: -0.049]\n",
      "Epoch 5256 -- [D loss: -0.027(R -0.039, F -0.016)] [G loss: -0.013]\n",
      "Epoch 5257 -- [D loss: -0.044(R -0.032, F -0.056)] [G loss: 0.042]\n",
      "Epoch 5258 -- [D loss: -0.033(R 0.027, F -0.093)] [G loss: 0.082]\n",
      "Epoch 5259 -- [D loss: -0.029(R 0.066, F -0.125)] [G loss: 0.133]\n",
      "Epoch 5260 -- [D loss: -0.026(R 0.085, F -0.137)] [G loss: 0.184]\n",
      "Epoch 5261 -- [D loss: -0.042(R 0.114, F -0.198)] [G loss: 0.204]\n",
      "Epoch 5262 -- [D loss: -0.038(R 0.122, F -0.198)] [G loss: 0.223]\n",
      "Epoch 5263 -- [D loss: -0.039(R 0.153, F -0.231)] [G loss: 0.235]\n",
      "Epoch 5264 -- [D loss: -0.036(R 0.165, F -0.237)] [G loss: 0.245]\n",
      "Epoch 5265 -- [D loss: -0.039(R 0.180, F -0.259)] [G loss: 0.257]\n",
      "Epoch 5266 -- [D loss: -0.054(R 0.181, F -0.289)] [G loss: 0.241]\n",
      "Epoch 5267 -- [D loss: -0.025(R 0.193, F -0.243)] [G loss: 0.204]\n",
      "Epoch 5268 -- [D loss: -0.007(R 0.200, F -0.214)] [G loss: 0.157]\n",
      "Epoch 5269 -- [D loss: -0.022(R 0.139, F -0.182)] [G loss: 0.115]\n",
      "Epoch 5270 -- [D loss: -0.019(R 0.112, F -0.150)] [G loss: 0.055]\n",
      "Epoch 5271 -- [D loss: -0.001(R 0.108, F -0.110)] [G loss: 0.004]\n",
      "Epoch 5272 -- [D loss: -0.002(R 0.093, F -0.098)] [G loss: -0.035]\n",
      "Epoch 5273 -- [D loss: -0.001(R 0.038, F -0.040)] [G loss: -0.064]\n",
      "Epoch 5274 -- [D loss: -0.023(R -0.006, F -0.041)] [G loss: -0.087]\n",
      "Epoch 5275 -- [D loss: -0.020(R -0.055, F 0.015)] [G loss: -0.118]\n",
      "Epoch 5276 -- [D loss: 0.008(R -0.022, F 0.038)] [G loss: -0.140]\n",
      "Epoch 5277 -- [D loss: -0.007(R -0.103, F 0.089)] [G loss: -0.176]\n",
      "Epoch 5278 -- [D loss: 0.017(R -0.106, F 0.141)] [G loss: -0.189]\n",
      "Epoch 5279 -- [D loss: -0.008(R -0.170, F 0.155)] [G loss: -0.227]\n",
      "Epoch 5280 -- [D loss: 0.004(R -0.186, F 0.194)] [G loss: -0.266]\n",
      "Epoch 5281 -- [D loss: -0.009(R -0.241, F 0.223)] [G loss: -0.288]\n",
      "Epoch 5282 -- [D loss: 0.026(R -0.229, F 0.282)] [G loss: -0.303]\n",
      "Epoch 5283 -- [D loss: 0.018(R -0.233, F 0.268)] [G loss: -0.296]\n",
      "Epoch 5284 -- [D loss: 0.013(R -0.253, F 0.279)] [G loss: -0.295]\n",
      "Epoch 5285 -- [D loss: -0.006(R -0.265, F 0.254)] [G loss: -0.299]\n",
      "Epoch 5286 -- [D loss: 0.016(R -0.243, F 0.275)] [G loss: -0.264]\n",
      "Epoch 5287 -- [D loss: 0.012(R -0.248, F 0.271)] [G loss: -0.232]\n",
      "Epoch 5288 -- [D loss: -0.013(R -0.251, F 0.225)] [G loss: -0.195]\n",
      "Epoch 5289 -- [D loss: -0.009(R -0.231, F 0.214)] [G loss: -0.170]\n",
      "Epoch 5290 -- [D loss: -0.033(R -0.244, F 0.178)] [G loss: -0.142]\n",
      "Epoch 5291 -- [D loss: -0.019(R -0.192, F 0.154)] [G loss: -0.114]\n",
      "Epoch 5292 -- [D loss: -0.007(R -0.162, F 0.148)] [G loss: -0.089]\n",
      "Epoch 5293 -- [D loss: -0.035(R -0.158, F 0.088)] [G loss: -0.072]\n",
      "Epoch 5294 -- [D loss: -0.047(R -0.142, F 0.047)] [G loss: -0.054]\n",
      "Epoch 5295 -- [D loss: -0.044(R -0.104, F 0.016)] [G loss: -0.016]\n",
      "Epoch 5296 -- [D loss: -0.032(R -0.072, F 0.007)] [G loss: 0.019]\n",
      "Epoch 5297 -- [D loss: -0.066(R -0.091, F -0.041)] [G loss: 0.029]\n",
      "Epoch 5298 -- [D loss: -0.092(R -0.055, F -0.129)] [G loss: 0.050]\n",
      "Epoch 5299 -- [D loss: -0.089(R -0.061, F -0.118)] [G loss: 0.052]\n",
      "Epoch 5300 -- [D loss: -0.040(R -0.003, F -0.077)] [G loss: 0.077]\n",
      "INFO:tensorflow:Assets written to: ram://056ef46b-7ae2-4d98-b867-46ebc39c0d4d/assets\n",
      "INFO:tensorflow:Assets written to: ram://c9c00d2d-191e-4385-86c3-1397a03357cb/assets\n",
      "INFO:tensorflow:Assets written to: ram://9374c58c-548a-4aef-a1ad-b3046c1bcb1d/assets\n",
      "Epoch 5301 -- [D loss: -0.048(R 0.025, F -0.122)] [G loss: 0.072]\n",
      "Epoch 5302 -- [D loss: -0.042(R -0.001, F -0.082)] [G loss: 0.077]\n",
      "Epoch 5303 -- [D loss: 0.010(R 0.040, F -0.020)] [G loss: 0.054]\n",
      "Epoch 5304 -- [D loss: 0.006(R 0.035, F -0.022)] [G loss: 0.034]\n",
      "Epoch 5305 -- [D loss: -0.002(R 0.033, F -0.036)] [G loss: 0.018]\n",
      "Epoch 5306 -- [D loss: 0.017(R 0.016, F 0.019)] [G loss: -0.025]\n",
      "Epoch 5307 -- [D loss: 0.035(R -0.001, F 0.070)] [G loss: -0.057]\n",
      "Epoch 5308 -- [D loss: 0.029(R -0.026, F 0.085)] [G loss: -0.058]\n",
      "Epoch 5309 -- [D loss: 0.032(R -0.047, F 0.110)] [G loss: -0.072]\n",
      "Epoch 5310 -- [D loss: 0.005(R -0.075, F 0.086)] [G loss: -0.082]\n",
      "Epoch 5311 -- [D loss: 0.009(R -0.087, F 0.104)] [G loss: -0.090]\n",
      "Epoch 5312 -- [D loss: -0.013(R -0.116, F 0.090)] [G loss: -0.094]\n",
      "Epoch 5313 -- [D loss: -0.027(R -0.147, F 0.092)] [G loss: -0.096]\n",
      "Epoch 5314 -- [D loss: -0.037(R -0.175, F 0.101)] [G loss: -0.094]\n",
      "Epoch 5315 -- [D loss: -0.039(R -0.172, F 0.094)] [G loss: -0.102]\n",
      "Epoch 5316 -- [D loss: -0.054(R -0.237, F 0.129)] [G loss: -0.115]\n",
      "Epoch 5317 -- [D loss: -0.062(R -0.238, F 0.113)] [G loss: -0.128]\n",
      "Epoch 5318 -- [D loss: -0.031(R -0.217, F 0.155)] [G loss: -0.161]\n",
      "Epoch 5319 -- [D loss: -0.046(R -0.277, F 0.186)] [G loss: -0.207]\n",
      "Epoch 5320 -- [D loss: -0.034(R -0.293, F 0.224)] [G loss: -0.235]\n",
      "Epoch 5321 -- [D loss: -0.007(R -0.229, F 0.215)] [G loss: -0.270]\n",
      "Epoch 5322 -- [D loss: 0.033(R -0.180, F 0.246)] [G loss: -0.272]\n",
      "Epoch 5323 -- [D loss: 0.007(R -0.247, F 0.261)] [G loss: -0.291]\n",
      "Epoch 5324 -- [D loss: 0.052(R -0.189, F 0.294)] [G loss: -0.272]\n",
      "Epoch 5325 -- [D loss: 0.013(R -0.171, F 0.198)] [G loss: -0.233]\n",
      "Epoch 5326 -- [D loss: 0.056(R -0.133, F 0.245)] [G loss: -0.199]\n",
      "Epoch 5327 -- [D loss: 0.043(R -0.128, F 0.214)] [G loss: -0.165]\n",
      "Epoch 5328 -- [D loss: 0.041(R -0.099, F 0.181)] [G loss: -0.132]\n",
      "Epoch 5329 -- [D loss: 0.037(R -0.091, F 0.165)] [G loss: -0.107]\n",
      "Epoch 5330 -- [D loss: 0.021(R -0.084, F 0.126)] [G loss: -0.086]\n",
      "Epoch 5331 -- [D loss: 0.006(R -0.076, F 0.088)] [G loss: -0.066]\n",
      "Epoch 5332 -- [D loss: 0.007(R -0.070, F 0.084)] [G loss: -0.051]\n",
      "Epoch 5333 -- [D loss: -0.002(R -0.061, F 0.056)] [G loss: -0.030]\n",
      "Epoch 5334 -- [D loss: -0.021(R -0.068, F 0.026)] [G loss: -0.009]\n",
      "Epoch 5335 -- [D loss: -0.026(R -0.059, F 0.008)] [G loss: 0.017]\n",
      "Epoch 5336 -- [D loss: -0.037(R -0.042, F -0.031)] [G loss: 0.041]\n",
      "Epoch 5337 -- [D loss: -0.037(R -0.053, F -0.020)] [G loss: 0.052]\n",
      "Epoch 5338 -- [D loss: -0.027(R -0.022, F -0.032)] [G loss: 0.041]\n",
      "Epoch 5339 -- [D loss: -0.016(R 0.001, F -0.032)] [G loss: 0.032]\n",
      "Epoch 5340 -- [D loss: -0.024(R -0.018, F -0.030)] [G loss: 0.040]\n",
      "Epoch 5341 -- [D loss: -0.008(R 0.001, F -0.017)] [G loss: 0.031]\n",
      "Epoch 5342 -- [D loss: 0.017(R 0.035, F -0.001)] [G loss: 0.027]\n",
      "Epoch 5343 -- [D loss: 0.002(R 0.032, F -0.028)] [G loss: 0.037]\n",
      "Epoch 5344 -- [D loss: -0.006(R 0.033, F -0.045)] [G loss: 0.031]\n",
      "Epoch 5345 -- [D loss: -0.007(R 0.056, F -0.070)] [G loss: 0.040]\n",
      "Epoch 5346 -- [D loss: 0.003(R 0.067, F -0.062)] [G loss: 0.040]\n",
      "Epoch 5347 -- [D loss: -0.003(R 0.048, F -0.053)] [G loss: 0.042]\n",
      "Epoch 5348 -- [D loss: 0.011(R 0.049, F -0.026)] [G loss: 0.036]\n",
      "Epoch 5349 -- [D loss: 0.000(R 0.026, F -0.026)] [G loss: 0.028]\n",
      "Epoch 5350 -- [D loss: 0.009(R 0.026, F -0.007)] [G loss: 0.024]\n",
      "Epoch 5351 -- [D loss: 0.009(R 0.017, F 0.001)] [G loss: 0.014]\n",
      "Epoch 5352 -- [D loss: -0.007(R -0.016, F 0.001)] [G loss: 0.012]\n",
      "Epoch 5353 -- [D loss: -0.013(R -0.028, F 0.003)] [G loss: -0.002]\n",
      "Epoch 5354 -- [D loss: -0.017(R -0.057, F 0.022)] [G loss: -0.022]\n",
      "Epoch 5355 -- [D loss: -0.033(R -0.094, F 0.028)] [G loss: -0.042]\n",
      "Epoch 5356 -- [D loss: -0.017(R -0.098, F 0.063)] [G loss: -0.066]\n",
      "Epoch 5357 -- [D loss: -0.016(R -0.095, F 0.063)] [G loss: -0.092]\n",
      "Epoch 5358 -- [D loss: -0.023(R -0.128, F 0.082)] [G loss: -0.120]\n",
      "Epoch 5359 -- [D loss: -0.041(R -0.165, F 0.084)] [G loss: -0.144]\n",
      "Epoch 5360 -- [D loss: -0.016(R -0.150, F 0.117)] [G loss: -0.159]\n",
      "Epoch 5361 -- [D loss: -0.004(R -0.147, F 0.138)] [G loss: -0.182]\n",
      "Epoch 5362 -- [D loss: -0.024(R -0.179, F 0.132)] [G loss: -0.180]\n",
      "Epoch 5363 -- [D loss: 0.014(R -0.158, F 0.186)] [G loss: -0.186]\n",
      "Epoch 5364 -- [D loss: -0.003(R -0.163, F 0.156)] [G loss: -0.180]\n",
      "Epoch 5365 -- [D loss: 0.031(R -0.125, F 0.187)] [G loss: -0.165]\n",
      "Epoch 5366 -- [D loss: 0.026(R -0.120, F 0.173)] [G loss: -0.155]\n",
      "Epoch 5367 -- [D loss: 0.018(R -0.115, F 0.152)] [G loss: -0.132]\n",
      "Epoch 5368 -- [D loss: 0.017(R -0.108, F 0.142)] [G loss: -0.121]\n",
      "Epoch 5369 -- [D loss: 0.017(R -0.094, F 0.128)] [G loss: -0.108]\n",
      "Epoch 5370 -- [D loss: 0.007(R -0.091, F 0.105)] [G loss: -0.091]\n",
      "Epoch 5371 -- [D loss: 0.005(R -0.084, F 0.093)] [G loss: -0.072]\n",
      "Epoch 5372 -- [D loss: -0.014(R -0.084, F 0.056)] [G loss: -0.043]\n",
      "Epoch 5373 -- [D loss: -0.019(R -0.078, F 0.039)] [G loss: -0.026]\n",
      "Epoch 5374 -- [D loss: -0.026(R -0.056, F 0.005)] [G loss: 0.008]\n",
      "Epoch 5375 -- [D loss: -0.035(R -0.068, F -0.002)] [G loss: 0.024]\n",
      "Epoch 5376 -- [D loss: -0.032(R -0.038, F -0.026)] [G loss: 0.033]\n",
      "Epoch 5377 -- [D loss: -0.040(R -0.002, F -0.078)] [G loss: 0.036]\n",
      "Epoch 5378 -- [D loss: -0.057(R -0.026, F -0.088)] [G loss: 0.044]\n",
      "Epoch 5379 -- [D loss: -0.066(R 0.010, F -0.141)] [G loss: 0.062]\n",
      "Epoch 5380 -- [D loss: -0.070(R 0.023, F -0.163)] [G loss: 0.066]\n",
      "Epoch 5381 -- [D loss: -0.064(R 0.028, F -0.157)] [G loss: 0.061]\n",
      "Epoch 5382 -- [D loss: -0.054(R 0.035, F -0.142)] [G loss: 0.041]\n",
      "Epoch 5383 -- [D loss: -0.048(R 0.007, F -0.103)] [G loss: 0.027]\n",
      "Epoch 5384 -- [D loss: 0.012(R 0.036, F -0.011)] [G loss: -0.015]\n",
      "Epoch 5385 -- [D loss: 0.037(R 0.050, F 0.024)] [G loss: -0.046]\n",
      "Epoch 5386 -- [D loss: 0.065(R 0.061, F 0.069)] [G loss: -0.059]\n",
      "Epoch 5387 -- [D loss: 0.044(R 0.006, F 0.082)] [G loss: -0.063]\n",
      "Epoch 5388 -- [D loss: 0.041(R -0.003, F 0.085)] [G loss: -0.064]\n",
      "Epoch 5389 -- [D loss: 0.017(R -0.039, F 0.074)] [G loss: -0.065]\n",
      "Epoch 5390 -- [D loss: 0.014(R -0.041, F 0.068)] [G loss: -0.057]\n",
      "Epoch 5391 -- [D loss: 0.001(R -0.064, F 0.065)] [G loss: -0.055]\n",
      "Epoch 5392 -- [D loss: -0.008(R -0.073, F 0.057)] [G loss: -0.048]\n",
      "Epoch 5393 -- [D loss: -0.013(R -0.080, F 0.054)] [G loss: -0.039]\n",
      "Epoch 5394 -- [D loss: -0.021(R -0.088, F 0.047)] [G loss: -0.029]\n",
      "Epoch 5395 -- [D loss: -0.021(R -0.085, F 0.042)] [G loss: -0.016]\n",
      "Epoch 5396 -- [D loss: -0.013(R -0.088, F 0.063)] [G loss: -0.023]\n",
      "Epoch 5397 -- [D loss: -0.007(R -0.095, F 0.081)] [G loss: -0.044]\n",
      "Epoch 5398 -- [D loss: -0.003(R -0.105, F 0.098)] [G loss: -0.058]\n",
      "Epoch 5399 -- [D loss: -0.003(R -0.089, F 0.084)] [G loss: -0.060]\n",
      "Epoch 5400 -- [D loss: -0.005(R -0.099, F 0.090)] [G loss: -0.065]\n",
      "INFO:tensorflow:Assets written to: ram://eae27cb0-6a7b-412a-bc03-f80d27785b23/assets\n",
      "INFO:tensorflow:Assets written to: ram://1fe62b49-8692-4157-8751-d2d44402a121/assets\n",
      "INFO:tensorflow:Assets written to: ram://747f09fa-6443-4018-9bb0-ad0bd75e1c17/assets\n",
      "Epoch 5401 -- [D loss: -0.002(R -0.087, F 0.084)] [G loss: -0.076]\n",
      "Epoch 5402 -- [D loss: 0.001(R -0.091, F 0.094)] [G loss: -0.082]\n",
      "Epoch 5403 -- [D loss: -0.017(R -0.123, F 0.088)] [G loss: -0.104]\n",
      "Epoch 5404 -- [D loss: -0.014(R -0.125, F 0.097)] [G loss: -0.129]\n",
      "Epoch 5405 -- [D loss: -0.019(R -0.132, F 0.093)] [G loss: -0.144]\n",
      "Epoch 5406 -- [D loss: -0.012(R -0.134, F 0.111)] [G loss: -0.153]\n",
      "Epoch 5407 -- [D loss: -0.002(R -0.115, F 0.111)] [G loss: -0.137]\n",
      "Epoch 5408 -- [D loss: -0.002(R -0.125, F 0.122)] [G loss: -0.126]\n",
      "Epoch 5409 -- [D loss: 0.006(R -0.115, F 0.127)] [G loss: -0.108]\n",
      "Epoch 5410 -- [D loss: 0.007(R -0.108, F 0.123)] [G loss: -0.103]\n",
      "Epoch 5411 -- [D loss: 0.007(R -0.106, F 0.121)] [G loss: -0.103]\n",
      "Epoch 5412 -- [D loss: 0.009(R -0.101, F 0.118)] [G loss: -0.091]\n",
      "Epoch 5413 -- [D loss: 0.005(R -0.093, F 0.103)] [G loss: -0.084]\n",
      "Epoch 5414 -- [D loss: -0.005(R -0.093, F 0.083)] [G loss: -0.073]\n",
      "Epoch 5415 -- [D loss: -0.003(R -0.076, F 0.071)] [G loss: -0.057]\n",
      "Epoch 5416 -- [D loss: -0.003(R -0.080, F 0.075)] [G loss: -0.050]\n",
      "Epoch 5417 -- [D loss: -0.008(R -0.071, F 0.055)] [G loss: -0.038]\n",
      "Epoch 5418 -- [D loss: 0.002(R -0.051, F 0.054)] [G loss: -0.041]\n",
      "Epoch 5419 -- [D loss: 0.004(R -0.058, F 0.066)] [G loss: -0.043]\n",
      "Epoch 5420 -- [D loss: 0.003(R -0.054, F 0.059)] [G loss: -0.046]\n",
      "Epoch 5421 -- [D loss: 0.003(R -0.053, F 0.060)] [G loss: -0.042]\n",
      "Epoch 5422 -- [D loss: -0.004(R -0.054, F 0.046)] [G loss: -0.041]\n",
      "Epoch 5423 -- [D loss: -0.002(R -0.046, F 0.042)] [G loss: -0.033]\n",
      "Epoch 5424 -- [D loss: -0.004(R -0.046, F 0.038)] [G loss: -0.028]\n",
      "Epoch 5425 -- [D loss: -0.003(R -0.043, F 0.036)] [G loss: -0.025]\n",
      "Epoch 5426 -- [D loss: -0.007(R -0.042, F 0.029)] [G loss: -0.023]\n",
      "Epoch 5427 -- [D loss: -0.007(R -0.035, F 0.021)] [G loss: -0.019]\n",
      "Epoch 5428 -- [D loss: -0.003(R -0.029, F 0.023)] [G loss: -0.014]\n",
      "Epoch 5429 -- [D loss: -0.001(R -0.017, F 0.015)] [G loss: -0.010]\n",
      "Epoch 5430 -- [D loss: -0.003(R -0.020, F 0.013)] [G loss: -0.007]\n",
      "Epoch 5431 -- [D loss: -0.003(R -0.018, F 0.013)] [G loss: -0.006]\n",
      "Epoch 5432 -- [D loss: -0.003(R -0.011, F 0.004)] [G loss: 0.002]\n",
      "Epoch 5433 -- [D loss: -0.003(R -0.014, F 0.009)] [G loss: 0.003]\n",
      "Epoch 5434 -- [D loss: -0.005(R -0.009, F 0.000)] [G loss: 0.004]\n",
      "Epoch 5435 -- [D loss: -0.002(R -0.001, F -0.003)] [G loss: 0.004]\n",
      "Epoch 5436 -- [D loss: 0.000(R -0.003, F 0.004)] [G loss: -0.000]\n",
      "Epoch 5437 -- [D loss: 0.002(R -0.007, F 0.011)] [G loss: 0.003]\n",
      "Epoch 5438 -- [D loss: -0.005(R -0.013, F 0.003)] [G loss: 0.005]\n",
      "Epoch 5439 -- [D loss: -0.007(R -0.021, F 0.007)] [G loss: 0.006]\n",
      "Epoch 5440 -- [D loss: -0.014(R -0.028, F 0.001)] [G loss: -0.004]\n",
      "Epoch 5441 -- [D loss: -0.020(R -0.047, F 0.007)] [G loss: -0.020]\n",
      "Epoch 5442 -- [D loss: -0.032(R -0.061, F -0.003)] [G loss: -0.043]\n",
      "Epoch 5443 -- [D loss: -0.038(R -0.082, F 0.005)] [G loss: -0.072]\n",
      "Epoch 5444 -- [D loss: -0.016(R -0.070, F 0.039)] [G loss: -0.101]\n",
      "Epoch 5445 -- [D loss: -0.003(R -0.074, F 0.068)] [G loss: -0.120]\n",
      "Epoch 5446 -- [D loss: 0.017(R -0.083, F 0.117)] [G loss: -0.124]\n",
      "Epoch 5447 -- [D loss: 0.041(R -0.056, F 0.137)] [G loss: -0.120]\n",
      "Epoch 5448 -- [D loss: 0.034(R -0.061, F 0.128)] [G loss: -0.108]\n",
      "Epoch 5449 -- [D loss: 0.017(R -0.069, F 0.103)] [G loss: -0.092]\n",
      "Epoch 5450 -- [D loss: 0.015(R -0.065, F 0.095)] [G loss: -0.080]\n",
      "Epoch 5451 -- [D loss: 0.009(R -0.062, F 0.080)] [G loss: -0.070]\n",
      "Epoch 5452 -- [D loss: 0.001(R -0.070, F 0.072)] [G loss: -0.063]\n",
      "Epoch 5453 -- [D loss: -0.007(R -0.082, F 0.068)] [G loss: -0.062]\n",
      "Epoch 5454 -- [D loss: -0.015(R -0.102, F 0.071)] [G loss: -0.067]\n",
      "Epoch 5455 -- [D loss: -0.031(R -0.139, F 0.078)] [G loss: -0.081]\n",
      "Epoch 5456 -- [D loss: -0.005(R -0.159, F 0.149)] [G loss: -0.110]\n",
      "Epoch 5457 -- [D loss: -0.030(R -0.189, F 0.128)] [G loss: -0.135]\n",
      "Epoch 5458 -- [D loss: -0.008(R -0.168, F 0.152)] [G loss: -0.162]\n",
      "Epoch 5459 -- [D loss: 0.025(R -0.167, F 0.218)] [G loss: -0.159]\n",
      "Epoch 5460 -- [D loss: 0.018(R -0.140, F 0.176)] [G loss: -0.160]\n",
      "Epoch 5461 -- [D loss: 0.034(R -0.125, F 0.194)] [G loss: -0.137]\n",
      "Epoch 5462 -- [D loss: 0.013(R -0.108, F 0.135)] [G loss: -0.122]\n",
      "Epoch 5463 -- [D loss: 0.013(R -0.088, F 0.114)] [G loss: -0.098]\n",
      "Epoch 5464 -- [D loss: 0.013(R -0.072, F 0.099)] [G loss: -0.081]\n",
      "Epoch 5465 -- [D loss: 0.014(R -0.064, F 0.091)] [G loss: -0.060]\n",
      "Epoch 5466 -- [D loss: 0.004(R -0.054, F 0.062)] [G loss: -0.047]\n",
      "Epoch 5467 -- [D loss: -0.000(R -0.048, F 0.048)] [G loss: -0.034]\n",
      "Epoch 5468 -- [D loss: -0.004(R -0.040, F 0.032)] [G loss: -0.019]\n",
      "Epoch 5469 -- [D loss: -0.008(R -0.033, F 0.017)] [G loss: -0.003]\n",
      "Epoch 5470 -- [D loss: -0.011(R -0.027, F 0.005)] [G loss: 0.005]\n",
      "Epoch 5471 -- [D loss: -0.016(R -0.025, F -0.006)] [G loss: 0.016]\n",
      "Epoch 5472 -- [D loss: -0.012(R -0.012, F -0.012)] [G loss: 0.016]\n",
      "Epoch 5473 -- [D loss: -0.011(R -0.012, F -0.010)] [G loss: 0.015]\n",
      "Epoch 5474 -- [D loss: -0.005(R -0.002, F -0.007)] [G loss: 0.011]\n",
      "Epoch 5475 -- [D loss: -0.007(R -0.004, F -0.010)] [G loss: 0.011]\n",
      "Epoch 5476 -- [D loss: -0.007(R 0.007, F -0.021)] [G loss: 0.014]\n",
      "Epoch 5477 -- [D loss: -0.003(R 0.018, F -0.024)] [G loss: 0.019]\n",
      "Epoch 5478 -- [D loss: -0.007(R 0.009, F -0.024)] [G loss: 0.023]\n",
      "Epoch 5479 -- [D loss: -0.001(R 0.020, F -0.021)] [G loss: 0.028]\n",
      "Epoch 5480 -- [D loss: -0.002(R 0.020, F -0.024)] [G loss: 0.034]\n",
      "Epoch 5481 -- [D loss: -0.002(R 0.026, F -0.031)] [G loss: 0.041]\n",
      "Epoch 5482 -- [D loss: -0.003(R 0.028, F -0.034)] [G loss: 0.045]\n",
      "Epoch 5483 -- [D loss: -0.005(R 0.029, F -0.040)] [G loss: 0.044]\n",
      "Epoch 5484 -- [D loss: -0.005(R 0.026, F -0.036)] [G loss: 0.044]\n",
      "Epoch 5485 -- [D loss: 0.002(R 0.036, F -0.033)] [G loss: 0.040]\n",
      "Epoch 5486 -- [D loss: -0.001(R 0.023, F -0.025)] [G loss: 0.032]\n",
      "Epoch 5487 -- [D loss: 0.008(R 0.026, F -0.011)] [G loss: 0.023]\n",
      "Epoch 5488 -- [D loss: 0.006(R 0.018, F -0.007)] [G loss: 0.015]\n",
      "Epoch 5489 -- [D loss: 0.006(R 0.007, F 0.004)] [G loss: 0.006]\n",
      "Epoch 5490 -- [D loss: 0.004(R -0.002, F 0.009)] [G loss: -0.001]\n",
      "Epoch 5491 -- [D loss: 0.002(R -0.009, F 0.014)] [G loss: -0.007]\n",
      "Epoch 5492 -- [D loss: 0.001(R -0.013, F 0.015)] [G loss: -0.007]\n",
      "Epoch 5493 -- [D loss: -0.004(R -0.025, F 0.017)] [G loss: -0.010]\n",
      "Epoch 5494 -- [D loss: -0.004(R -0.027, F 0.019)] [G loss: -0.013]\n",
      "Epoch 5495 -- [D loss: -0.005(R -0.034, F 0.024)] [G loss: -0.018]\n",
      "Epoch 5496 -- [D loss: -0.008(R -0.045, F 0.029)] [G loss: -0.029]\n",
      "Epoch 5497 -- [D loss: -0.000(R -0.040, F 0.039)] [G loss: -0.037]\n",
      "Epoch 5498 -- [D loss: -0.001(R -0.040, F 0.039)] [G loss: -0.047]\n",
      "Epoch 5499 -- [D loss: 0.005(R -0.036, F 0.045)] [G loss: -0.047]\n",
      "Epoch 5500 -- [D loss: 0.005(R -0.041, F 0.051)] [G loss: -0.046]\n",
      "INFO:tensorflow:Assets written to: ram://4e076722-daef-4a70-8a47-13ab94189adc/assets\n",
      "INFO:tensorflow:Assets written to: ram://607649b6-136e-4395-8176-71f2e1bca91b/assets\n",
      "INFO:tensorflow:Assets written to: ram://04c321fa-5bd4-44fa-8079-40c77fd09e97/assets\n",
      "Epoch 5501 -- [D loss: 0.006(R -0.041, F 0.052)] [G loss: -0.043]\n",
      "Epoch 5502 -- [D loss: 0.001(R -0.041, F 0.042)] [G loss: -0.041]\n",
      "Epoch 5503 -- [D loss: -0.003(R -0.044, F 0.039)] [G loss: -0.038]\n",
      "Epoch 5504 -- [D loss: -0.003(R -0.042, F 0.036)] [G loss: -0.037]\n",
      "Epoch 5505 -- [D loss: -0.008(R -0.045, F 0.030)] [G loss: -0.040]\n",
      "Epoch 5506 -- [D loss: -0.011(R -0.059, F 0.037)] [G loss: -0.043]\n",
      "Epoch 5507 -- [D loss: -0.002(R -0.060, F 0.056)] [G loss: -0.045]\n",
      "Epoch 5508 -- [D loss: -0.008(R -0.072, F 0.056)] [G loss: -0.056]\n",
      "Epoch 5509 -- [D loss: -0.007(R -0.071, F 0.056)] [G loss: -0.061]\n",
      "Epoch 5510 -- [D loss: -0.007(R -0.068, F 0.054)] [G loss: -0.065]\n",
      "Epoch 5511 -- [D loss: -0.006(R -0.073, F 0.060)] [G loss: -0.073]\n",
      "Epoch 5512 -- [D loss: 0.011(R -0.058, F 0.080)] [G loss: -0.075]\n",
      "Epoch 5513 -- [D loss: 0.017(R -0.044, F 0.078)] [G loss: -0.073]\n",
      "Epoch 5514 -- [D loss: 0.013(R -0.046, F 0.072)] [G loss: -0.070]\n",
      "Epoch 5515 -- [D loss: 0.006(R -0.051, F 0.063)] [G loss: -0.064]\n",
      "Epoch 5516 -- [D loss: 0.008(R -0.045, F 0.061)] [G loss: -0.053]\n",
      "Epoch 5517 -- [D loss: 0.002(R -0.048, F 0.052)] [G loss: -0.044]\n",
      "Epoch 5518 -- [D loss: -0.004(R -0.047, F 0.040)] [G loss: -0.032]\n",
      "Epoch 5519 -- [D loss: -0.005(R -0.047, F 0.037)] [G loss: -0.026]\n",
      "Epoch 5520 -- [D loss: -0.006(R -0.047, F 0.034)] [G loss: -0.017]\n",
      "Epoch 5521 -- [D loss: -0.007(R -0.042, F 0.028)] [G loss: -0.012]\n",
      "Epoch 5522 -- [D loss: -0.009(R -0.046, F 0.027)] [G loss: -0.014]\n",
      "Epoch 5523 -- [D loss: -0.007(R -0.046, F 0.032)] [G loss: -0.016]\n",
      "Epoch 5524 -- [D loss: -0.011(R -0.046, F 0.025)] [G loss: -0.023]\n",
      "Epoch 5525 -- [D loss: -0.006(R -0.045, F 0.034)] [G loss: -0.033]\n",
      "Epoch 5526 -- [D loss: -0.001(R -0.036, F 0.034)] [G loss: -0.043]\n",
      "Epoch 5527 -- [D loss: 0.001(R -0.037, F 0.040)] [G loss: -0.046]\n",
      "Epoch 5528 -- [D loss: 0.002(R -0.046, F 0.050)] [G loss: -0.053]\n",
      "Epoch 5529 -- [D loss: 0.003(R -0.047, F 0.053)] [G loss: -0.055]\n",
      "Epoch 5530 -- [D loss: -0.000(R -0.049, F 0.049)] [G loss: -0.051]\n",
      "Epoch 5531 -- [D loss: -0.001(R -0.048, F 0.046)] [G loss: -0.045]\n",
      "Epoch 5532 -- [D loss: -0.003(R -0.049, F 0.044)] [G loss: -0.041]\n",
      "Epoch 5533 -- [D loss: -0.003(R -0.043, F 0.037)] [G loss: -0.036]\n",
      "Epoch 5534 -- [D loss: -0.001(R -0.041, F 0.039)] [G loss: -0.029]\n",
      "Epoch 5535 -- [D loss: -0.002(R -0.039, F 0.036)] [G loss: -0.026]\n",
      "Epoch 5536 -- [D loss: -0.007(R -0.043, F 0.028)] [G loss: -0.023]\n",
      "Epoch 5537 -- [D loss: -0.002(R -0.037, F 0.034)] [G loss: -0.023]\n",
      "Epoch 5538 -- [D loss: -0.009(R -0.042, F 0.025)] [G loss: -0.024]\n",
      "Epoch 5539 -- [D loss: -0.004(R -0.039, F 0.032)] [G loss: -0.027]\n",
      "Epoch 5540 -- [D loss: -0.004(R -0.038, F 0.031)] [G loss: -0.026]\n",
      "Epoch 5541 -- [D loss: -0.002(R -0.040, F 0.035)] [G loss: -0.028]\n",
      "Epoch 5542 -- [D loss: -0.002(R -0.043, F 0.038)] [G loss: -0.030]\n",
      "Epoch 5543 -- [D loss: 0.001(R -0.036, F 0.038)] [G loss: -0.031]\n",
      "Epoch 5544 -- [D loss: -0.002(R -0.038, F 0.034)] [G loss: -0.031]\n",
      "Epoch 5545 -- [D loss: -0.001(R -0.038, F 0.035)] [G loss: -0.032]\n",
      "Epoch 5546 -- [D loss: -0.001(R -0.035, F 0.032)] [G loss: -0.032]\n",
      "Epoch 5547 -- [D loss: -0.001(R -0.038, F 0.035)] [G loss: -0.037]\n",
      "Epoch 5548 -- [D loss: -0.002(R -0.039, F 0.035)] [G loss: -0.037]\n",
      "Epoch 5549 -- [D loss: -0.002(R -0.042, F 0.038)] [G loss: -0.041]\n",
      "Epoch 5550 -- [D loss: 0.000(R -0.042, F 0.043)] [G loss: -0.043]\n",
      "Epoch 5551 -- [D loss: 0.001(R -0.043, F 0.046)] [G loss: -0.047]\n",
      "Epoch 5552 -- [D loss: -0.000(R -0.047, F 0.046)] [G loss: -0.047]\n",
      "Epoch 5553 -- [D loss: 0.003(R -0.046, F 0.051)] [G loss: -0.044]\n",
      "Epoch 5554 -- [D loss: -0.002(R -0.050, F 0.046)] [G loss: -0.043]\n",
      "Epoch 5555 -- [D loss: -0.000(R -0.048, F 0.048)] [G loss: -0.040]\n",
      "Epoch 5556 -- [D loss: 0.002(R -0.044, F 0.048)] [G loss: -0.038]\n",
      "Epoch 5557 -- [D loss: -0.004(R -0.044, F 0.037)] [G loss: -0.034]\n",
      "Epoch 5558 -- [D loss: -0.000(R -0.043, F 0.042)] [G loss: -0.035]\n",
      "Epoch 5559 -- [D loss: -0.002(R -0.041, F 0.036)] [G loss: -0.037]\n",
      "Epoch 5560 -- [D loss: -0.005(R -0.046, F 0.036)] [G loss: -0.038]\n",
      "Epoch 5561 -- [D loss: -0.003(R -0.040, F 0.035)] [G loss: -0.044]\n",
      "Epoch 5562 -- [D loss: 0.000(R -0.032, F 0.033)] [G loss: -0.050]\n",
      "Epoch 5563 -- [D loss: 0.002(R -0.033, F 0.036)] [G loss: -0.049]\n",
      "Epoch 5564 -- [D loss: -0.001(R -0.033, F 0.031)] [G loss: -0.045]\n",
      "Epoch 5565 -- [D loss: -0.001(R -0.030, F 0.027)] [G loss: -0.038]\n",
      "Epoch 5566 -- [D loss: -0.006(R -0.033, F 0.020)] [G loss: -0.028]\n",
      "Epoch 5567 -- [D loss: -0.006(R -0.026, F 0.013)] [G loss: -0.014]\n",
      "Epoch 5568 -- [D loss: -0.005(R -0.017, F 0.007)] [G loss: 0.001]\n",
      "Epoch 5569 -- [D loss: -0.010(R -0.016, F -0.003)] [G loss: 0.014]\n",
      "Epoch 5570 -- [D loss: -0.016(R -0.017, F -0.015)] [G loss: 0.023]\n",
      "Epoch 5571 -- [D loss: -0.021(R -0.017, F -0.025)] [G loss: 0.028]\n",
      "Epoch 5572 -- [D loss: -0.024(R -0.020, F -0.028)] [G loss: 0.028]\n",
      "Epoch 5573 -- [D loss: -0.030(R -0.018, F -0.041)] [G loss: 0.014]\n",
      "Epoch 5574 -- [D loss: -0.027(R -0.027, F -0.027)] [G loss: -0.003]\n",
      "Epoch 5575 -- [D loss: -0.021(R -0.025, F -0.017)] [G loss: -0.026]\n",
      "Epoch 5576 -- [D loss: -0.013(R -0.030, F 0.004)] [G loss: -0.049]\n",
      "Epoch 5577 -- [D loss: 0.004(R -0.024, F 0.033)] [G loss: -0.064]\n",
      "Epoch 5578 -- [D loss: 0.005(R -0.042, F 0.052)] [G loss: -0.074]\n",
      "Epoch 5579 -- [D loss: 0.008(R -0.045, F 0.060)] [G loss: -0.075]\n",
      "Epoch 5580 -- [D loss: 0.011(R -0.049, F 0.070)] [G loss: -0.074]\n",
      "Epoch 5581 -- [D loss: 0.002(R -0.059, F 0.063)] [G loss: -0.074]\n",
      "Epoch 5582 -- [D loss: 0.002(R -0.061, F 0.066)] [G loss: -0.072]\n",
      "Epoch 5583 -- [D loss: -0.002(R -0.066, F 0.062)] [G loss: -0.075]\n",
      "Epoch 5584 -- [D loss: 0.002(R -0.071, F 0.074)] [G loss: -0.072]\n",
      "Epoch 5585 -- [D loss: -0.003(R -0.078, F 0.072)] [G loss: -0.076]\n",
      "Epoch 5586 -- [D loss: -0.003(R -0.084, F 0.078)] [G loss: -0.073]\n",
      "Epoch 5587 -- [D loss: -0.007(R -0.098, F 0.084)] [G loss: -0.074]\n",
      "Epoch 5588 -- [D loss: -0.005(R -0.093, F 0.084)] [G loss: -0.080]\n",
      "Epoch 5589 -- [D loss: -0.005(R -0.102, F 0.093)] [G loss: -0.083]\n",
      "Epoch 5590 -- [D loss: -0.001(R -0.094, F 0.091)] [G loss: -0.081]\n",
      "Epoch 5591 -- [D loss: 0.012(R -0.098, F 0.121)] [G loss: -0.081]\n",
      "Epoch 5592 -- [D loss: 0.004(R -0.099, F 0.107)] [G loss: -0.078]\n",
      "Epoch 5593 -- [D loss: 0.007(R -0.083, F 0.097)] [G loss: -0.066]\n",
      "Epoch 5594 -- [D loss: -0.006(R -0.093, F 0.081)] [G loss: -0.048]\n",
      "Epoch 5595 -- [D loss: -0.007(R -0.073, F 0.059)] [G loss: -0.038]\n",
      "Epoch 5596 -- [D loss: -0.007(R -0.066, F 0.052)] [G loss: -0.035]\n",
      "Epoch 5597 -- [D loss: -0.005(R -0.059, F 0.049)] [G loss: -0.035]\n",
      "Epoch 5598 -- [D loss: -0.004(R -0.053, F 0.045)] [G loss: -0.030]\n",
      "Epoch 5599 -- [D loss: -0.004(R -0.045, F 0.037)] [G loss: -0.031]\n",
      "Epoch 5600 -- [D loss: -0.014(R -0.063, F 0.034)] [G loss: -0.042]\n",
      "INFO:tensorflow:Assets written to: ram://0dd20ebc-2a49-46b3-9bed-88adab3f4e88/assets\n",
      "INFO:tensorflow:Assets written to: ram://62bcc029-0363-4922-bec4-921da1e50c5e/assets\n",
      "INFO:tensorflow:Assets written to: ram://0191cb96-5a09-4bab-8679-ee6b139ea2c3/assets\n",
      "Epoch 5601 -- [D loss: -0.014(R -0.063, F 0.035)] [G loss: -0.055]\n",
      "Epoch 5602 -- [D loss: -0.020(R -0.080, F 0.039)] [G loss: -0.071]\n",
      "Epoch 5603 -- [D loss: -0.017(R -0.082, F 0.048)] [G loss: -0.091]\n",
      "Epoch 5604 -- [D loss: -0.022(R -0.085, F 0.041)] [G loss: -0.104]\n",
      "Epoch 5605 -- [D loss: -0.011(R -0.080, F 0.058)] [G loss: -0.109]\n",
      "Epoch 5606 -- [D loss: 0.003(R -0.081, F 0.086)] [G loss: -0.113]\n",
      "Epoch 5607 -- [D loss: 0.007(R -0.062, F 0.077)] [G loss: -0.111]\n",
      "Epoch 5608 -- [D loss: 0.010(R -0.067, F 0.087)] [G loss: -0.090]\n",
      "Epoch 5609 -- [D loss: 0.007(R -0.050, F 0.064)] [G loss: -0.062]\n",
      "Epoch 5610 -- [D loss: 0.003(R -0.037, F 0.043)] [G loss: -0.025]\n",
      "Epoch 5611 -- [D loss: -0.008(R -0.028, F 0.013)] [G loss: 0.006]\n",
      "Epoch 5612 -- [D loss: -0.021(R -0.031, F -0.012)] [G loss: 0.036]\n",
      "Epoch 5613 -- [D loss: -0.029(R -0.013, F -0.046)] [G loss: 0.058]\n",
      "Epoch 5614 -- [D loss: -0.043(R -0.017, F -0.069)] [G loss: 0.070]\n",
      "Epoch 5615 -- [D loss: -0.036(R 0.009, F -0.082)] [G loss: 0.072]\n",
      "Epoch 5616 -- [D loss: -0.041(R -0.004, F -0.078)] [G loss: 0.062]\n",
      "Epoch 5617 -- [D loss: -0.033(R -0.000, F -0.067)] [G loss: 0.032]\n",
      "Epoch 5618 -- [D loss: 0.004(R 0.017, F -0.009)] [G loss: 0.005]\n",
      "Epoch 5619 -- [D loss: 0.008(R 0.001, F 0.015)] [G loss: -0.028]\n",
      "Epoch 5620 -- [D loss: 0.022(R -0.010, F 0.054)] [G loss: -0.059]\n",
      "Epoch 5621 -- [D loss: 0.021(R -0.028, F 0.070)] [G loss: -0.077]\n",
      "Epoch 5622 -- [D loss: 0.018(R -0.046, F 0.082)] [G loss: -0.088]\n",
      "Epoch 5623 -- [D loss: 0.006(R -0.061, F 0.074)] [G loss: -0.095]\n",
      "Epoch 5624 -- [D loss: 0.002(R -0.069, F 0.073)] [G loss: -0.094]\n",
      "Epoch 5625 -- [D loss: 0.003(R -0.079, F 0.086)] [G loss: -0.095]\n",
      "Epoch 5626 -- [D loss: -0.009(R -0.100, F 0.081)] [G loss: -0.106]\n",
      "Epoch 5627 -- [D loss: -0.004(R -0.110, F 0.102)] [G loss: -0.106]\n",
      "Epoch 5628 -- [D loss: -0.010(R -0.131, F 0.110)] [G loss: -0.110]\n",
      "Epoch 5629 -- [D loss: -0.010(R -0.138, F 0.118)] [G loss: -0.115]\n",
      "Epoch 5630 -- [D loss: -0.002(R -0.143, F 0.139)] [G loss: -0.111]\n",
      "Epoch 5631 -- [D loss: -0.000(R -0.149, F 0.149)] [G loss: -0.118]\n",
      "Epoch 5632 -- [D loss: 0.008(R -0.140, F 0.156)] [G loss: -0.121]\n",
      "Epoch 5633 -- [D loss: 0.000(R -0.141, F 0.141)] [G loss: -0.123]\n",
      "Epoch 5634 -- [D loss: 0.000(R -0.139, F 0.139)] [G loss: -0.110]\n",
      "Epoch 5635 -- [D loss: 0.003(R -0.124, F 0.131)] [G loss: -0.090]\n",
      "Epoch 5636 -- [D loss: -0.005(R -0.116, F 0.106)] [G loss: -0.071]\n",
      "Epoch 5637 -- [D loss: -0.011(R -0.099, F 0.077)] [G loss: -0.048]\n",
      "Epoch 5638 -- [D loss: -0.011(R -0.085, F 0.062)] [G loss: -0.045]\n",
      "Epoch 5639 -- [D loss: -0.007(R -0.076, F 0.062)] [G loss: -0.043]\n",
      "Epoch 5640 -- [D loss: -0.001(R -0.081, F 0.078)] [G loss: -0.054]\n",
      "Epoch 5641 -- [D loss: -0.006(R -0.092, F 0.079)] [G loss: -0.062]\n",
      "Epoch 5642 -- [D loss: -0.006(R -0.089, F 0.076)] [G loss: -0.078]\n",
      "Epoch 5643 -- [D loss: -0.009(R -0.093, F 0.075)] [G loss: -0.085]\n",
      "Epoch 5644 -- [D loss: -0.009(R -0.095, F 0.076)] [G loss: -0.100]\n",
      "Epoch 5645 -- [D loss: -0.002(R -0.099, F 0.095)] [G loss: -0.112]\n",
      "Epoch 5646 -- [D loss: 0.001(R -0.093, F 0.095)] [G loss: -0.113]\n",
      "Epoch 5647 -- [D loss: 0.015(R -0.080, F 0.109)] [G loss: -0.115]\n",
      "Epoch 5648 -- [D loss: 0.002(R -0.083, F 0.087)] [G loss: -0.110]\n",
      "Epoch 5649 -- [D loss: 0.004(R -0.073, F 0.081)] [G loss: -0.097]\n",
      "Epoch 5650 -- [D loss: 0.010(R -0.063, F 0.083)] [G loss: -0.079]\n",
      "Epoch 5651 -- [D loss: 0.006(R -0.055, F 0.067)] [G loss: -0.054]\n",
      "Epoch 5652 -- [D loss: 0.000(R -0.043, F 0.043)] [G loss: -0.025]\n",
      "Epoch 5653 -- [D loss: -0.014(R -0.042, F 0.013)] [G loss: 0.005]\n",
      "Epoch 5654 -- [D loss: -0.018(R -0.028, F -0.009)] [G loss: 0.028]\n",
      "Epoch 5655 -- [D loss: -0.022(R -0.025, F -0.020)] [G loss: 0.039]\n",
      "Epoch 5656 -- [D loss: -0.018(R -0.022, F -0.014)] [G loss: 0.039]\n",
      "Epoch 5657 -- [D loss: -0.017(R -0.022, F -0.011)] [G loss: 0.034]\n",
      "Epoch 5658 -- [D loss: -0.016(R -0.023, F -0.008)] [G loss: 0.018]\n",
      "Epoch 5659 -- [D loss: -0.005(R -0.020, F 0.009)] [G loss: -0.001]\n",
      "Epoch 5660 -- [D loss: 0.006(R -0.013, F 0.025)] [G loss: -0.017]\n",
      "Epoch 5661 -- [D loss: 0.010(R -0.019, F 0.040)] [G loss: -0.032]\n",
      "Epoch 5662 -- [D loss: 0.015(R -0.020, F 0.049)] [G loss: -0.040]\n",
      "Epoch 5663 -- [D loss: 0.009(R -0.031, F 0.049)] [G loss: -0.043]\n",
      "Epoch 5664 -- [D loss: 0.007(R -0.033, F 0.046)] [G loss: -0.040]\n",
      "Epoch 5665 -- [D loss: 0.004(R -0.034, F 0.042)] [G loss: -0.038]\n",
      "Epoch 5666 -- [D loss: 0.001(R -0.034, F 0.036)] [G loss: -0.033]\n",
      "Epoch 5667 -- [D loss: -0.001(R -0.037, F 0.035)] [G loss: -0.029]\n",
      "Epoch 5668 -- [D loss: -0.004(R -0.038, F 0.029)] [G loss: -0.025]\n",
      "Epoch 5669 -- [D loss: -0.006(R -0.037, F 0.025)] [G loss: -0.018]\n",
      "Epoch 5670 -- [D loss: -0.015(R -0.047, F 0.017)] [G loss: -0.013]\n",
      "Epoch 5671 -- [D loss: -0.010(R -0.045, F 0.025)] [G loss: -0.016]\n",
      "Epoch 5672 -- [D loss: -0.010(R -0.046, F 0.027)] [G loss: -0.020]\n",
      "Epoch 5673 -- [D loss: -0.015(R -0.059, F 0.029)] [G loss: -0.027]\n",
      "Epoch 5674 -- [D loss: -0.012(R -0.064, F 0.040)] [G loss: -0.035]\n",
      "Epoch 5675 -- [D loss: -0.007(R -0.065, F 0.051)] [G loss: -0.045]\n",
      "Epoch 5676 -- [D loss: -0.000(R -0.061, F 0.061)] [G loss: -0.058]\n",
      "Epoch 5677 -- [D loss: 0.003(R -0.064, F 0.071)] [G loss: -0.070]\n",
      "Epoch 5678 -- [D loss: 0.006(R -0.063, F 0.075)] [G loss: -0.077]\n",
      "Epoch 5679 -- [D loss: 0.013(R -0.054, F 0.081)] [G loss: -0.079]\n",
      "Epoch 5680 -- [D loss: 0.013(R -0.050, F 0.076)] [G loss: -0.072]\n",
      "Epoch 5681 -- [D loss: 0.010(R -0.047, F 0.068)] [G loss: -0.061]\n",
      "Epoch 5682 -- [D loss: 0.006(R -0.042, F 0.055)] [G loss: -0.048]\n",
      "Epoch 5683 -- [D loss: 0.000(R -0.040, F 0.041)] [G loss: -0.035]\n",
      "Epoch 5684 -- [D loss: -0.002(R -0.036, F 0.032)] [G loss: -0.024]\n",
      "Epoch 5685 -- [D loss: -0.007(R -0.037, F 0.024)] [G loss: -0.013]\n",
      "Epoch 5686 -- [D loss: -0.013(R -0.037, F 0.010)] [G loss: -0.003]\n",
      "Epoch 5687 -- [D loss: -0.011(R -0.035, F 0.013)] [G loss: 0.002]\n",
      "Epoch 5688 -- [D loss: -0.015(R -0.042, F 0.012)] [G loss: -0.001]\n",
      "Epoch 5689 -- [D loss: -0.010(R -0.036, F 0.015)] [G loss: -0.006]\n",
      "Epoch 5690 -- [D loss: -0.006(R -0.035, F 0.023)] [G loss: -0.016]\n",
      "Epoch 5691 -- [D loss: -0.002(R -0.035, F 0.031)] [G loss: -0.028]\n",
      "Epoch 5692 -- [D loss: -0.000(R -0.039, F 0.039)] [G loss: -0.035]\n",
      "Epoch 5693 -- [D loss: 0.003(R -0.041, F 0.047)] [G loss: -0.039]\n",
      "Epoch 5694 -- [D loss: 0.003(R -0.042, F 0.047)] [G loss: -0.044]\n",
      "Epoch 5695 -- [D loss: 0.002(R -0.043, F 0.047)] [G loss: -0.042]\n",
      "Epoch 5696 -- [D loss: 0.002(R -0.045, F 0.049)] [G loss: -0.042]\n",
      "Epoch 5697 -- [D loss: -0.001(R -0.047, F 0.046)] [G loss: -0.039]\n",
      "Epoch 5698 -- [D loss: -0.001(R -0.046, F 0.044)] [G loss: -0.038]\n",
      "Epoch 5699 -- [D loss: -0.006(R -0.052, F 0.041)] [G loss: -0.035]\n",
      "Epoch 5700 -- [D loss: -0.005(R -0.051, F 0.041)] [G loss: -0.039]\n",
      "INFO:tensorflow:Assets written to: ram://8c3322c1-9498-4b7d-82f4-a55c612dd695/assets\n",
      "INFO:tensorflow:Assets written to: ram://2205d8ea-0c81-48b5-8653-f43b9cbc56c9/assets\n",
      "INFO:tensorflow:Assets written to: ram://61f917d6-e5d8-4480-9f66-bdfc87d7d487/assets\n",
      "Epoch 5701 -- [D loss: -0.007(R -0.057, F 0.043)] [G loss: -0.041]\n",
      "Epoch 5702 -- [D loss: -0.006(R -0.056, F 0.043)] [G loss: -0.046]\n",
      "Epoch 5703 -- [D loss: -0.002(R -0.052, F 0.048)] [G loss: -0.053]\n",
      "Epoch 5704 -- [D loss: -0.003(R -0.052, F 0.046)] [G loss: -0.060]\n",
      "Epoch 5705 -- [D loss: -0.000(R -0.048, F 0.047)] [G loss: -0.059]\n",
      "Epoch 5706 -- [D loss: 0.003(R -0.047, F 0.054)] [G loss: -0.055]\n",
      "Epoch 5707 -- [D loss: 0.003(R -0.042, F 0.048)] [G loss: -0.048]\n",
      "Epoch 5708 -- [D loss: 0.004(R -0.038, F 0.047)] [G loss: -0.036]\n",
      "Epoch 5709 -- [D loss: -0.000(R -0.035, F 0.035)] [G loss: -0.023]\n",
      "Epoch 5710 -- [D loss: -0.007(R -0.035, F 0.021)] [G loss: -0.009]\n",
      "Epoch 5711 -- [D loss: -0.010(R -0.032, F 0.012)] [G loss: -0.004]\n",
      "Epoch 5712 -- [D loss: -0.010(R -0.029, F 0.009)] [G loss: -0.003]\n",
      "Epoch 5713 -- [D loss: -0.010(R -0.025, F 0.006)] [G loss: -0.006]\n",
      "Epoch 5714 -- [D loss: -0.013(R -0.034, F 0.007)] [G loss: -0.015]\n",
      "Epoch 5715 -- [D loss: -0.015(R -0.038, F 0.008)] [G loss: -0.026]\n",
      "Epoch 5716 -- [D loss: -0.011(R -0.036, F 0.013)] [G loss: -0.038]\n",
      "Epoch 5717 -- [D loss: -0.005(R -0.039, F 0.028)] [G loss: -0.049]\n",
      "Epoch 5718 -- [D loss: 0.003(R -0.033, F 0.038)] [G loss: -0.061]\n",
      "Epoch 5719 -- [D loss: 0.006(R -0.036, F 0.048)] [G loss: -0.065]\n",
      "Epoch 5720 -- [D loss: 0.002(R -0.055, F 0.059)] [G loss: -0.065]\n",
      "Epoch 5721 -- [D loss: 0.002(R -0.055, F 0.060)] [G loss: -0.064]\n",
      "Epoch 5722 -- [D loss: -0.001(R -0.063, F 0.061)] [G loss: -0.061]\n",
      "Epoch 5723 -- [D loss: -0.004(R -0.066, F 0.058)] [G loss: -0.057]\n",
      "Epoch 5724 -- [D loss: -0.007(R -0.073, F 0.060)] [G loss: -0.057]\n",
      "Epoch 5725 -- [D loss: -0.009(R -0.078, F 0.059)] [G loss: -0.059]\n",
      "Epoch 5726 -- [D loss: -0.015(R -0.093, F 0.063)] [G loss: -0.065]\n",
      "Epoch 5727 -- [D loss: -0.015(R -0.091, F 0.062)] [G loss: -0.066]\n",
      "Epoch 5728 -- [D loss: -0.009(R -0.095, F 0.076)] [G loss: -0.076]\n",
      "Epoch 5729 -- [D loss: -0.007(R -0.093, F 0.078)] [G loss: -0.086]\n",
      "Epoch 5730 -- [D loss: -0.001(R -0.078, F 0.076)] [G loss: -0.084]\n",
      "Epoch 5731 -- [D loss: 0.001(R -0.072, F 0.074)] [G loss: -0.089]\n",
      "Epoch 5732 -- [D loss: 0.002(R -0.067, F 0.070)] [G loss: -0.092]\n",
      "Epoch 5733 -- [D loss: 0.001(R -0.065, F 0.067)] [G loss: -0.088]\n",
      "Epoch 5734 -- [D loss: 0.003(R -0.050, F 0.056)] [G loss: -0.083]\n",
      "Epoch 5735 -- [D loss: 0.002(R -0.053, F 0.057)] [G loss: -0.077]\n",
      "Epoch 5736 -- [D loss: -0.002(R -0.052, F 0.047)] [G loss: -0.067]\n",
      "Epoch 5737 -- [D loss: 0.002(R -0.043, F 0.047)] [G loss: -0.051]\n",
      "Epoch 5738 -- [D loss: -0.005(R -0.044, F 0.035)] [G loss: -0.030]\n",
      "Epoch 5739 -- [D loss: -0.005(R -0.038, F 0.027)] [G loss: -0.008]\n",
      "Epoch 5740 -- [D loss: -0.015(R -0.031, F 0.001)] [G loss: 0.017]\n",
      "Epoch 5741 -- [D loss: -0.030(R -0.028, F -0.032)] [G loss: 0.042]\n",
      "Epoch 5742 -- [D loss: -0.050(R -0.021, F -0.080)] [G loss: 0.064]\n",
      "Epoch 5743 -- [D loss: -0.069(R -0.016, F -0.122)] [G loss: 0.062]\n",
      "Epoch 5744 -- [D loss: -0.076(R 0.008, F -0.160)] [G loss: 0.048]\n",
      "Epoch 5745 -- [D loss: -0.069(R -0.000, F -0.138)] [G loss: 0.022]\n",
      "Epoch 5746 -- [D loss: -0.041(R 0.009, F -0.091)] [G loss: -0.020]\n",
      "Epoch 5747 -- [D loss: -0.011(R 0.010, F -0.031)] [G loss: -0.053]\n",
      "Epoch 5748 -- [D loss: 0.018(R 0.005, F 0.032)] [G loss: -0.073]\n",
      "Epoch 5749 -- [D loss: 0.029(R 0.004, F 0.055)] [G loss: -0.088]\n",
      "Epoch 5750 -- [D loss: 0.033(R -0.023, F 0.089)] [G loss: -0.091]\n",
      "Epoch 5751 -- [D loss: 0.027(R -0.035, F 0.088)] [G loss: -0.087]\n",
      "Epoch 5752 -- [D loss: 0.014(R -0.055, F 0.084)] [G loss: -0.080]\n",
      "Epoch 5753 -- [D loss: 0.008(R -0.062, F 0.077)] [G loss: -0.072]\n",
      "Epoch 5754 -- [D loss: 0.003(R -0.069, F 0.075)] [G loss: -0.065]\n",
      "Epoch 5755 -- [D loss: -0.003(R -0.077, F 0.072)] [G loss: -0.061]\n",
      "Epoch 5756 -- [D loss: -0.006(R -0.087, F 0.076)] [G loss: -0.059]\n",
      "Epoch 5757 -- [D loss: -0.011(R -0.098, F 0.077)] [G loss: -0.060]\n",
      "Epoch 5758 -- [D loss: -0.012(R -0.109, F 0.086)] [G loss: -0.063]\n",
      "Epoch 5759 -- [D loss: -0.009(R -0.117, F 0.098)] [G loss: -0.066]\n",
      "Epoch 5760 -- [D loss: -0.018(R -0.140, F 0.104)] [G loss: -0.077]\n",
      "Epoch 5761 -- [D loss: -0.018(R -0.134, F 0.098)] [G loss: -0.076]\n",
      "Epoch 5762 -- [D loss: -0.027(R -0.161, F 0.106)] [G loss: -0.091]\n",
      "Epoch 5763 -- [D loss: -0.034(R -0.172, F 0.104)] [G loss: -0.111]\n",
      "Epoch 5764 -- [D loss: -0.014(R -0.162, F 0.133)] [G loss: -0.137]\n",
      "Epoch 5765 -- [D loss: -0.014(R -0.178, F 0.150)] [G loss: -0.176]\n",
      "Epoch 5766 -- [D loss: 0.008(R -0.159, F 0.174)] [G loss: -0.207]\n",
      "Epoch 5767 -- [D loss: 0.000(R -0.173, F 0.174)] [G loss: -0.235]\n",
      "Epoch 5768 -- [D loss: 0.019(R -0.131, F 0.169)] [G loss: -0.240]\n",
      "Epoch 5769 -- [D loss: 0.020(R -0.132, F 0.173)] [G loss: -0.227]\n",
      "Epoch 5770 -- [D loss: 0.025(R -0.098, F 0.148)] [G loss: -0.192]\n",
      "Epoch 5771 -- [D loss: 0.022(R -0.083, F 0.128)] [G loss: -0.152]\n",
      "Epoch 5772 -- [D loss: 0.014(R -0.073, F 0.100)] [G loss: -0.104]\n",
      "Epoch 5773 -- [D loss: 0.003(R -0.060, F 0.067)] [G loss: -0.055]\n",
      "Epoch 5774 -- [D loss: -0.005(R -0.042, F 0.032)] [G loss: -0.006]\n",
      "Epoch 5775 -- [D loss: -0.017(R -0.028, F -0.005)] [G loss: 0.043]\n",
      "Epoch 5776 -- [D loss: -0.037(R -0.020, F -0.054)] [G loss: 0.093]\n",
      "Epoch 5777 -- [D loss: -0.057(R 0.001, F -0.115)] [G loss: 0.141]\n",
      "Epoch 5778 -- [D loss: -0.079(R 0.021, F -0.178)] [G loss: 0.177]\n",
      "Epoch 5779 -- [D loss: -0.097(R 0.056, F -0.250)] [G loss: 0.192]\n",
      "Epoch 5780 -- [D loss: -0.127(R 0.047, F -0.302)] [G loss: 0.165]\n",
      "Epoch 5781 -- [D loss: -0.093(R 0.074, F -0.260)] [G loss: 0.112]\n",
      "Epoch 5782 -- [D loss: -0.082(R 0.026, F -0.190)] [G loss: 0.040]\n",
      "Epoch 5783 -- [D loss: -0.028(R 0.066, F -0.122)] [G loss: -0.005]\n",
      "Epoch 5784 -- [D loss: 0.014(R 0.043, F -0.016)] [G loss: -0.051]\n",
      "Epoch 5785 -- [D loss: 0.049(R 0.023, F 0.075)] [G loss: -0.082]\n",
      "Epoch 5786 -- [D loss: 0.038(R -0.014, F 0.090)] [G loss: -0.090]\n",
      "Epoch 5787 -- [D loss: 0.020(R -0.052, F 0.091)] [G loss: -0.089]\n",
      "Epoch 5788 -- [D loss: 0.004(R -0.083, F 0.091)] [G loss: -0.084]\n",
      "Epoch 5789 -- [D loss: -0.003(R -0.096, F 0.091)] [G loss: -0.079]\n",
      "Epoch 5790 -- [D loss: -0.016(R -0.122, F 0.090)] [G loss: -0.082]\n",
      "Epoch 5791 -- [D loss: -0.022(R -0.150, F 0.106)] [G loss: -0.087]\n",
      "Epoch 5792 -- [D loss: -0.034(R -0.179, F 0.110)] [G loss: -0.105]\n",
      "Epoch 5793 -- [D loss: -0.037(R -0.212, F 0.137)] [G loss: -0.136]\n",
      "Epoch 5794 -- [D loss: -0.032(R -0.231, F 0.167)] [G loss: -0.168]\n",
      "Epoch 5795 -- [D loss: -0.027(R -0.234, F 0.179)] [G loss: -0.200]\n",
      "Epoch 5796 -- [D loss: -0.018(R -0.258, F 0.222)] [G loss: -0.220]\n",
      "Epoch 5797 -- [D loss: -0.026(R -0.253, F 0.202)] [G loss: -0.237]\n",
      "Epoch 5798 -- [D loss: 0.009(R -0.244, F 0.262)] [G loss: -0.271]\n",
      "Epoch 5799 -- [D loss: 0.018(R -0.225, F 0.260)] [G loss: -0.299]\n",
      "Epoch 5800 -- [D loss: 0.025(R -0.210, F 0.260)] [G loss: -0.301]\n",
      "INFO:tensorflow:Assets written to: ram://bbf34c82-52f6-4a5e-b0cd-3e0e31f33a0c/assets\n",
      "INFO:tensorflow:Assets written to: ram://63e5eb2f-1fc5-4b85-88b4-6fe324aec54b/assets\n",
      "INFO:tensorflow:Assets written to: ram://114079fa-c7ac-4909-8cfd-1ea3386a3617/assets\n",
      "Epoch 5801 -- [D loss: 0.021(R -0.204, F 0.246)] [G loss: -0.271]\n",
      "Epoch 5802 -- [D loss: 0.005(R -0.192, F 0.202)] [G loss: -0.234]\n",
      "Epoch 5803 -- [D loss: 0.002(R -0.162, F 0.166)] [G loss: -0.208]\n",
      "Epoch 5804 -- [D loss: 0.008(R -0.142, F 0.158)] [G loss: -0.184]\n",
      "Epoch 5805 -- [D loss: 0.003(R -0.121, F 0.127)] [G loss: -0.151]\n",
      "Epoch 5806 -- [D loss: 0.006(R -0.092, F 0.103)] [G loss: -0.089]\n",
      "Epoch 5807 -- [D loss: -0.013(R -0.082, F 0.057)] [G loss: -0.030]\n",
      "Epoch 5808 -- [D loss: -0.036(R -0.051, F -0.021)] [G loss: 0.082]\n",
      "Epoch 5809 -- [D loss: -0.073(R -0.003, F -0.143)] [G loss: 0.170]\n",
      "Epoch 5810 -- [D loss: -0.124(R 0.011, F -0.259)] [G loss: 0.259]\n",
      "Epoch 5811 -- [D loss: -0.157(R 0.105, F -0.418)] [G loss: 0.299]\n",
      "Epoch 5812 -- [D loss: -0.208(R 0.095, F -0.510)] [G loss: 0.315]\n",
      "Epoch 5813 -- [D loss: -0.180(R 0.167, F -0.527)] [G loss: 0.253]\n",
      "Epoch 5814 -- [D loss: -0.165(R 0.172, F -0.503)] [G loss: 0.163]\n",
      "Epoch 5815 -- [D loss: -0.079(R 0.228, F -0.385)] [G loss: 0.073]\n",
      "Epoch 5816 -- [D loss: 0.010(R 0.237, F -0.218)] [G loss: -0.003]\n",
      "Epoch 5817 -- [D loss: 0.085(R 0.225, F -0.055)] [G loss: -0.045]\n",
      "Epoch 5818 -- [D loss: 0.083(R 0.151, F 0.016)] [G loss: -0.056]\n",
      "Epoch 5819 -- [D loss: 0.068(R 0.089, F 0.048)] [G loss: -0.066]\n",
      "Epoch 5820 -- [D loss: 0.029(R -0.004, F 0.063)] [G loss: -0.061]\n",
      "Epoch 5821 -- [D loss: 0.002(R -0.062, F 0.066)] [G loss: -0.058]\n",
      "Epoch 5822 -- [D loss: -0.013(R -0.094, F 0.069)] [G loss: -0.054]\n",
      "Epoch 5823 -- [D loss: -0.045(R -0.170, F 0.079)] [G loss: -0.057]\n",
      "Epoch 5824 -- [D loss: -0.055(R -0.203, F 0.092)] [G loss: -0.074]\n",
      "Epoch 5825 -- [D loss: -0.061(R -0.251, F 0.129)] [G loss: -0.110]\n",
      "Epoch 5826 -- [D loss: -0.073(R -0.332, F 0.187)] [G loss: -0.166]\n",
      "Epoch 5827 -- [D loss: -0.087(R -0.438, F 0.265)] [G loss: -0.264]\n",
      "Epoch 5828 -- [D loss: -0.081(R -0.519, F 0.357)] [G loss: -0.378]\n",
      "Epoch 5829 -- [D loss: -0.060(R -0.492, F 0.372)] [G loss: -0.501]\n",
      "Epoch 5830 -- [D loss: -0.049(R -0.522, F 0.424)] [G loss: -0.626]\n",
      "Epoch 5831 -- [D loss: -0.093(R -0.663, F 0.478)] [G loss: -0.762]\n",
      "Epoch 5832 -- [D loss: -0.022(R -0.653, F 0.608)] [G loss: -0.908]\n",
      "Epoch 5833 -- [D loss: 0.074(R -0.561, F 0.709)] [G loss: -1.000]\n",
      "Epoch 5834 -- [D loss: -0.011(R -0.618, F 0.597)] [G loss: -1.006]\n",
      "Epoch 5835 -- [D loss: 0.076(R -0.522, F 0.674)] [G loss: -0.977]\n",
      "Epoch 5836 -- [D loss: 0.119(R -0.463, F 0.701)] [G loss: -0.879]\n",
      "Epoch 5837 -- [D loss: 0.072(R -0.412, F 0.556)] [G loss: -0.744]\n",
      "Epoch 5838 -- [D loss: 0.105(R -0.351, F 0.562)] [G loss: -0.588]\n",
      "Epoch 5839 -- [D loss: 0.060(R -0.283, F 0.403)] [G loss: -0.420]\n",
      "Epoch 5840 -- [D loss: 0.022(R -0.217, F 0.261)] [G loss: -0.258]\n",
      "Epoch 5841 -- [D loss: -0.005(R -0.173, F 0.164)] [G loss: -0.116]\n",
      "Epoch 5842 -- [D loss: -0.028(R -0.118, F 0.061)] [G loss: 0.012]\n",
      "Epoch 5843 -- [D loss: -0.057(R -0.087, F -0.027)] [G loss: 0.124]\n",
      "Epoch 5844 -- [D loss: -0.091(R -0.036, F -0.147)] [G loss: 0.257]\n",
      "Epoch 5845 -- [D loss: -0.137(R 0.008, F -0.282)] [G loss: 0.372]\n",
      "Epoch 5846 -- [D loss: -0.165(R 0.053, F -0.383)] [G loss: 0.505]\n",
      "Epoch 5847 -- [D loss: -0.232(R 0.137, F -0.600)] [G loss: 0.623]\n",
      "Epoch 5848 -- [D loss: -0.266(R 0.201, F -0.733)] [G loss: 0.709]\n",
      "Epoch 5849 -- [D loss: -0.328(R 0.309, F -0.965)] [G loss: 0.737]\n",
      "Epoch 5850 -- [D loss: -0.355(R 0.397, F -1.106)] [G loss: 0.712]\n",
      "Epoch 5851 -- [D loss: -0.390(R 0.398, F -1.178)] [G loss: 0.641]\n",
      "Epoch 5852 -- [D loss: -0.363(R 0.481, F -1.207)] [G loss: 0.518]\n",
      "Epoch 5853 -- [D loss: -0.239(R 0.564, F -1.043)] [G loss: 0.407]\n",
      "Epoch 5854 -- [D loss: -0.108(R 0.650, F -0.866)] [G loss: 0.273]\n",
      "Epoch 5855 -- [D loss: 0.006(R 0.681, F -0.670)] [G loss: 0.165]\n",
      "Epoch 5856 -- [D loss: 0.003(R 0.531, F -0.526)] [G loss: 0.129]\n",
      "Epoch 5857 -- [D loss: 0.043(R 0.451, F -0.365)] [G loss: 0.084]\n",
      "Epoch 5858 -- [D loss: 0.099(R 0.498, F -0.299)] [G loss: 0.073]\n",
      "Epoch 5859 -- [D loss: 0.066(R 0.314, F -0.181)] [G loss: 0.055]\n",
      "Epoch 5860 -- [D loss: 0.092(R 0.311, F -0.127)] [G loss: 0.061]\n",
      "Epoch 5861 -- [D loss: 0.009(R 0.113, F -0.095)] [G loss: 0.037]\n",
      "Epoch 5862 -- [D loss: -0.000(R 0.023, F -0.023)] [G loss: 0.013]\n",
      "Epoch 5863 -- [D loss: 0.005(R -0.001, F 0.011)] [G loss: -0.023]\n",
      "Epoch 5864 -- [D loss: -0.024(R -0.104, F 0.056)] [G loss: -0.055]\n",
      "Epoch 5865 -- [D loss: -0.020(R -0.125, F 0.086)] [G loss: -0.084]\n",
      "Epoch 5866 -- [D loss: -0.041(R -0.195, F 0.113)] [G loss: -0.142]\n",
      "Epoch 5867 -- [D loss: -0.050(R -0.274, F 0.173)] [G loss: -0.179]\n",
      "Epoch 5868 -- [D loss: -0.057(R -0.347, F 0.233)] [G loss: -0.226]\n",
      "Epoch 5869 -- [D loss: -0.068(R -0.376, F 0.240)] [G loss: -0.267]\n",
      "Epoch 5870 -- [D loss: -0.085(R -0.454, F 0.284)] [G loss: -0.296]\n",
      "Epoch 5871 -- [D loss: -0.092(R -0.523, F 0.339)] [G loss: -0.329]\n",
      "Epoch 5872 -- [D loss: -0.098(R -0.532, F 0.337)] [G loss: -0.362]\n",
      "Epoch 5873 -- [D loss: -0.081(R -0.565, F 0.403)] [G loss: -0.392]\n",
      "Epoch 5874 -- [D loss: -0.093(R -0.620, F 0.435)] [G loss: -0.437]\n",
      "Epoch 5875 -- [D loss: -0.086(R -0.636, F 0.464)] [G loss: -0.485]\n",
      "Epoch 5876 -- [D loss: -0.090(R -0.686, F 0.506)] [G loss: -0.534]\n",
      "Epoch 5877 -- [D loss: -0.119(R -0.746, F 0.509)] [G loss: -0.565]\n",
      "Epoch 5878 -- [D loss: -0.087(R -0.691, F 0.518)] [G loss: -0.600]\n",
      "Epoch 5879 -- [D loss: -0.140(R -0.772, F 0.493)] [G loss: -0.658]\n",
      "Epoch 5880 -- [D loss: -0.079(R -0.681, F 0.524)] [G loss: -0.696]\n",
      "Epoch 5881 -- [D loss: -0.016(R -0.665, F 0.634)] [G loss: -0.752]\n",
      "Epoch 5882 -- [D loss: 0.004(R -0.654, F 0.661)] [G loss: -0.770]\n",
      "Epoch 5883 -- [D loss: 0.007(R -0.603, F 0.617)] [G loss: -0.782]\n",
      "Epoch 5884 -- [D loss: 0.060(R -0.529, F 0.650)] [G loss: -0.798]\n",
      "Epoch 5885 -- [D loss: 0.067(R -0.493, F 0.627)] [G loss: -0.735]\n",
      "Epoch 5886 -- [D loss: 0.042(R -0.506, F 0.589)] [G loss: -0.714]\n",
      "Epoch 5887 -- [D loss: 0.037(R -0.459, F 0.534)] [G loss: -0.651]\n",
      "Epoch 5888 -- [D loss: 0.064(R -0.363, F 0.491)] [G loss: -0.587]\n",
      "Epoch 5889 -- [D loss: 0.089(R -0.304, F 0.482)] [G loss: -0.509]\n",
      "Epoch 5890 -- [D loss: 0.062(R -0.271, F 0.395)] [G loss: -0.427]\n",
      "Epoch 5891 -- [D loss: 0.052(R -0.226, F 0.330)] [G loss: -0.344]\n",
      "Epoch 5892 -- [D loss: 0.043(R -0.179, F 0.265)] [G loss: -0.244]\n",
      "Epoch 5893 -- [D loss: 0.038(R -0.140, F 0.217)] [G loss: -0.142]\n",
      "Epoch 5894 -- [D loss: 0.003(R -0.095, F 0.100)] [G loss: -0.037]\n",
      "Epoch 5895 -- [D loss: -0.022(R -0.039, F -0.006)] [G loss: 0.089]\n",
      "Epoch 5896 -- [D loss: -0.055(R 0.027, F -0.136)] [G loss: 0.217]\n",
      "Epoch 5897 -- [D loss: -0.078(R 0.097, F -0.253)] [G loss: 0.375]\n",
      "Epoch 5898 -- [D loss: -0.140(R 0.161, F -0.442)] [G loss: 0.531]\n",
      "Epoch 5899 -- [D loss: -0.213(R 0.219, F -0.645)] [G loss: 0.676]\n",
      "Epoch 5900 -- [D loss: -0.234(R 0.378, F -0.846)] [G loss: 0.771]\n",
      "INFO:tensorflow:Assets written to: ram://178590a8-ca44-45b6-b159-a304696b8f8b/assets\n",
      "INFO:tensorflow:Assets written to: ram://3c003265-08b4-45ba-bcae-9381a4e18915/assets\n",
      "INFO:tensorflow:Assets written to: ram://80ce7b39-c089-4ac8-9e9d-1846b88dbf82/assets\n",
      "Epoch 5901 -- [D loss: -0.244(R 0.523, F -1.010)] [G loss: 0.824]\n",
      "Epoch 5902 -- [D loss: -0.261(R 0.563, F -1.085)] [G loss: 0.829]\n",
      "Epoch 5903 -- [D loss: -0.260(R 0.671, F -1.191)] [G loss: 0.767]\n",
      "Epoch 5904 -- [D loss: -0.177(R 0.726, F -1.081)] [G loss: 0.662]\n",
      "Epoch 5905 -- [D loss: -0.102(R 0.855, F -1.059)] [G loss: 0.570]\n",
      "Epoch 5906 -- [D loss: -0.110(R 0.687, F -0.907)] [G loss: 0.432]\n",
      "Epoch 5907 -- [D loss: -0.007(R 0.704, F -0.718)] [G loss: 0.357]\n",
      "Epoch 5908 -- [D loss: 0.034(R 0.642, F -0.574)] [G loss: 0.272]\n",
      "Epoch 5909 -- [D loss: 0.071(R 0.565, F -0.423)] [G loss: 0.207]\n",
      "Epoch 5910 -- [D loss: 0.062(R 0.429, F -0.306)] [G loss: 0.168]\n",
      "Epoch 5911 -- [D loss: 0.044(R 0.319, F -0.231)] [G loss: 0.119]\n",
      "Epoch 5912 -- [D loss: 0.084(R 0.290, F -0.121)] [G loss: 0.084]\n",
      "Epoch 5913 -- [D loss: 0.060(R 0.181, F -0.061)] [G loss: 0.033]\n",
      "Epoch 5914 -- [D loss: 0.067(R 0.120, F 0.015)] [G loss: -0.007]\n",
      "Epoch 5915 -- [D loss: 0.062(R 0.061, F 0.063)] [G loss: -0.026]\n",
      "Epoch 5916 -- [D loss: 0.032(R -0.012, F 0.077)] [G loss: -0.041]\n",
      "Epoch 5917 -- [D loss: 0.014(R -0.072, F 0.100)] [G loss: -0.052]\n",
      "Epoch 5918 -- [D loss: -0.013(R -0.130, F 0.103)] [G loss: -0.054]\n",
      "Epoch 5919 -- [D loss: -0.030(R -0.150, F 0.090)] [G loss: -0.048]\n",
      "Epoch 5920 -- [D loss: -0.060(R -0.211, F 0.091)] [G loss: -0.048]\n",
      "Epoch 5921 -- [D loss: -0.078(R -0.275, F 0.120)] [G loss: -0.061]\n",
      "Epoch 5922 -- [D loss: -0.094(R -0.308, F 0.120)] [G loss: -0.087]\n",
      "Epoch 5923 -- [D loss: -0.096(R -0.393, F 0.201)] [G loss: -0.131]\n",
      "Epoch 5924 -- [D loss: -0.078(R -0.359, F 0.203)] [G loss: -0.179]\n",
      "Epoch 5925 -- [D loss: -0.095(R -0.447, F 0.256)] [G loss: -0.238]\n",
      "Epoch 5926 -- [D loss: -0.124(R -0.531, F 0.284)] [G loss: -0.324]\n",
      "Epoch 5927 -- [D loss: -0.125(R -0.626, F 0.376)] [G loss: -0.381]\n",
      "Epoch 5928 -- [D loss: -0.166(R -0.655, F 0.324)] [G loss: -0.470]\n",
      "Epoch 5929 -- [D loss: -0.184(R -0.781, F 0.412)] [G loss: -0.598]\n",
      "Epoch 5930 -- [D loss: -0.145(R -0.762, F 0.471)] [G loss: -0.744]\n",
      "Epoch 5931 -- [D loss: -0.151(R -0.818, F 0.517)] [G loss: -0.922]\n",
      "Epoch 5932 -- [D loss: -0.183(R -0.855, F 0.489)] [G loss: -1.147]\n",
      "Epoch 5933 -- [D loss: -0.116(R -0.872, F 0.641)] [G loss: -1.383]\n",
      "Epoch 5934 -- [D loss: -0.037(R -0.910, F 0.837)] [G loss: -1.498]\n",
      "Epoch 5935 -- [D loss: -0.036(R -0.869, F 0.798)] [G loss: -1.709]\n",
      "Epoch 5936 -- [D loss: 0.051(R -0.885, F 0.988)] [G loss: -1.737]\n",
      "Epoch 5937 -- [D loss: 0.065(R -0.899, F 1.030)] [G loss: -1.732]\n",
      "Epoch 5938 -- [D loss: 0.065(R -0.901, F 1.030)] [G loss: -1.654]\n",
      "Epoch 5939 -- [D loss: 0.146(R -0.801, F 1.093)] [G loss: -1.480]\n",
      "Epoch 5940 -- [D loss: 0.184(R -0.665, F 1.033)] [G loss: -1.256]\n",
      "Epoch 5941 -- [D loss: 0.157(R -0.630, F 0.943)] [G loss: -1.081]\n",
      "Epoch 5942 -- [D loss: 0.129(R -0.545, F 0.803)] [G loss: -0.909]\n",
      "Epoch 5943 -- [D loss: 0.090(R -0.505, F 0.685)] [G loss: -0.727]\n",
      "Epoch 5944 -- [D loss: 0.065(R -0.455, F 0.585)] [G loss: -0.576]\n",
      "Epoch 5945 -- [D loss: 0.060(R -0.379, F 0.498)] [G loss: -0.453]\n",
      "Epoch 5946 -- [D loss: 0.012(R -0.337, F 0.360)] [G loss: -0.318]\n",
      "Epoch 5947 -- [D loss: -0.010(R -0.303, F 0.284)] [G loss: -0.233]\n",
      "Epoch 5948 -- [D loss: -0.027(R -0.271, F 0.217)] [G loss: -0.139]\n",
      "Epoch 5949 -- [D loss: -0.067(R -0.249, F 0.115)] [G loss: -0.058]\n",
      "Epoch 5950 -- [D loss: -0.089(R -0.205, F 0.027)] [G loss: 0.048]\n",
      "Epoch 5951 -- [D loss: -0.131(R -0.158, F -0.105)] [G loss: 0.179]\n",
      "Epoch 5952 -- [D loss: -0.150(R -0.127, F -0.174)] [G loss: 0.298]\n",
      "Epoch 5953 -- [D loss: -0.246(R -0.099, F -0.393)] [G loss: 0.474]\n",
      "Epoch 5954 -- [D loss: -0.275(R 0.031, F -0.582)] [G loss: 0.675]\n",
      "Epoch 5955 -- [D loss: -0.373(R 0.119, F -0.864)] [G loss: 0.847]\n",
      "Epoch 5956 -- [D loss: -0.367(R 0.222, F -0.957)] [G loss: 1.045]\n",
      "Epoch 5957 -- [D loss: -0.476(R 0.317, F -1.270)] [G loss: 1.204]\n",
      "Epoch 5958 -- [D loss: -0.461(R 0.543, F -1.464)] [G loss: 1.267]\n",
      "Epoch 5959 -- [D loss: -0.448(R 0.780, F -1.677)] [G loss: 1.330]\n",
      "Epoch 5960 -- [D loss: -0.442(R 1.002, F -1.887)] [G loss: 1.292]\n",
      "Epoch 5961 -- [D loss: -0.460(R 1.093, F -2.013)] [G loss: 1.128]\n",
      "Epoch 5962 -- [D loss: -0.367(R 1.242, F -1.976)] [G loss: 1.022]\n",
      "Epoch 5963 -- [D loss: -0.266(R 1.420, F -1.952)] [G loss: 0.899]\n",
      "Epoch 5964 -- [D loss: -0.273(R 1.317, F -1.862)] [G loss: 0.759]\n",
      "Epoch 5965 -- [D loss: -0.158(R 1.319, F -1.634)] [G loss: 0.658]\n",
      "Epoch 5966 -- [D loss: 0.089(R 1.476, F -1.298)] [G loss: 0.597]\n",
      "Epoch 5967 -- [D loss: 0.106(R 1.214, F -1.001)] [G loss: 0.512]\n",
      "Epoch 5968 -- [D loss: 0.117(R 1.138, F -0.905)] [G loss: 0.468]\n",
      "Epoch 5969 -- [D loss: 0.204(R 1.087, F -0.680)] [G loss: 0.399]\n",
      "Epoch 5970 -- [D loss: 0.168(R 0.882, F -0.547)] [G loss: 0.327]\n",
      "Epoch 5971 -- [D loss: 0.210(R 0.810, F -0.389)] [G loss: 0.284]\n",
      "Epoch 5972 -- [D loss: 0.129(R 0.549, F -0.290)] [G loss: 0.238]\n",
      "Epoch 5973 -- [D loss: 0.160(R 0.517, F -0.196)] [G loss: 0.171]\n",
      "Epoch 5974 -- [D loss: 0.093(R 0.350, F -0.164)] [G loss: 0.148]\n",
      "Epoch 5975 -- [D loss: 0.078(R 0.249, F -0.093)] [G loss: 0.134]\n",
      "Epoch 5976 -- [D loss: 0.031(R 0.162, F -0.101)] [G loss: 0.104]\n",
      "Epoch 5977 -- [D loss: 0.018(R 0.122, F -0.086)] [G loss: 0.117]\n",
      "Epoch 5978 -- [D loss: -0.010(R 0.037, F -0.057)] [G loss: 0.121]\n",
      "Epoch 5979 -- [D loss: -0.025(R 0.032, F -0.082)] [G loss: 0.126]\n",
      "Epoch 5980 -- [D loss: -0.055(R -0.035, F -0.076)] [G loss: 0.150]\n",
      "Epoch 5981 -- [D loss: -0.067(R -0.045, F -0.089)] [G loss: 0.152]\n",
      "Epoch 5982 -- [D loss: -0.047(R -0.034, F -0.059)] [G loss: 0.146]\n",
      "Epoch 5983 -- [D loss: -0.060(R -0.061, F -0.059)] [G loss: 0.161]\n",
      "Epoch 5984 -- [D loss: -0.095(R -0.118, F -0.071)] [G loss: 0.152]\n",
      "Epoch 5985 -- [D loss: -0.087(R -0.089, F -0.085)] [G loss: 0.126]\n",
      "Epoch 5986 -- [D loss: -0.093(R -0.135, F -0.051)] [G loss: 0.130]\n",
      "Epoch 5987 -- [D loss: -0.112(R -0.183, F -0.042)] [G loss: 0.094]\n",
      "Epoch 5988 -- [D loss: -0.141(R -0.217, F -0.065)] [G loss: 0.093]\n",
      "Epoch 5989 -- [D loss: -0.150(R -0.223, F -0.078)] [G loss: 0.089]\n",
      "Epoch 5990 -- [D loss: -0.168(R -0.232, F -0.104)] [G loss: 0.069]\n",
      "Epoch 5991 -- [D loss: -0.175(R -0.290, F -0.059)] [G loss: 0.071]\n",
      "Epoch 5992 -- [D loss: -0.166(R -0.282, F -0.050)] [G loss: -0.007]\n",
      "Epoch 5993 -- [D loss: -0.152(R -0.267, F -0.038)] [G loss: -0.096]\n",
      "Epoch 5994 -- [D loss: -0.103(R -0.287, F 0.081)] [G loss: -0.224]\n",
      "Epoch 5995 -- [D loss: -0.109(R -0.385, F 0.167)] [G loss: -0.388]\n",
      "Epoch 5996 -- [D loss: -0.086(R -0.394, F 0.222)] [G loss: -0.508]\n",
      "Epoch 5997 -- [D loss: -0.054(R -0.478, F 0.369)] [G loss: -0.611]\n",
      "Epoch 5998 -- [D loss: -0.036(R -0.497, F 0.424)] [G loss: -0.680]\n",
      "Epoch 5999 -- [D loss: 0.012(R -0.482, F 0.507)] [G loss: -0.719]\n",
      "Epoch 6000 -- [D loss: 0.055(R -0.495, F 0.604)] [G loss: -0.713]\n",
      "INFO:tensorflow:Assets written to: ram://4d414cc3-654d-4f82-a2f1-11c793f3a71f/assets\n",
      "INFO:tensorflow:Assets written to: ram://14a566c6-e589-42f8-9226-b4c5b80629b9/assets\n",
      "INFO:tensorflow:Assets written to: ram://c5046efb-799e-4563-9775-d21a9cf6e8e6/assets\n",
      "INFO:tensorflow:Assets written to: ram://c1892613-0354-49df-8160-b91a3b8fe418/assets\n",
      "INFO:tensorflow:Assets written to: ram://2a8bbe03-60b1-41b7-a82a-c26deb0f2a87/assets\n",
      "INFO:tensorflow:Assets written to: ram://984ca4c3-e587-4c12-b131-b452a8a59c5a/assets\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "N_CRITIC = 5\n",
    "CLIP_THRESHOLD = 0.01\n",
    "\n",
    "wgan.train(\n",
    "    x_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    run_folder=RUN_FOLDER,\n",
    "    print_every_n_batches=PRINT_EVERY_N_BATCHES,\n",
    "    n_critic=N_CRITIC,\n",
    "    clip_threshold=CLIP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练损失可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in wgan.d_losses], color=\"black\", linewidth=0.25)\n",
    "plt.plot([x[1] for x in wgan.d_losses], color=\"green\", linewidth=0.25)\n",
    "plt.plot([x[2] for x in wgan.d_losses], color=\"red\", linewidth=0.25)\n",
    "plt.plot(wgan.g_losses, color=\"orange\", linewidth=0.25)\n",
    "\n",
    "plt.xlabel(\"epoch\", fontsize=18)\n",
    "plt.ylabel(\"loss\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成图片及对比与生成图片相似的原始图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "\n",
    "idx = np.random.randint(0, x_train.shape[0], 32)\n",
    "true_imgs = (x_train[idx] + 1) * 0.5\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15, 15))\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i, j].imshow(true_imgs[cnt])\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/real.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (r * c, wgan.z_dim))\n",
    "gen_imgs = wgan.generator.predict(noise)\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15, 15))\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i, j].imshow(np.squeeze(gen_imgs[cnt, :, :, :]))\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample.png\"))\n",
    "plt.close()\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15, 15))\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate((x_train + 1) * 0.5):\n",
    "            diff = compare_images(gen_imgs[cnt, :, :, :], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i, j].imshow(c_img)\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample_closest.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2c3f6bbb24c7fc4eda595b7be3f8dd6bbd084eb592ad3a47549926ebe803f66"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
